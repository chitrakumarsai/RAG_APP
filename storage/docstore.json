{"docstore/metadata": {"3213ff5c-8c24-4f2d-a974-af52bc835c43": {"doc_hash": "846fd4f408c6cf1f6102e2b410bd20643360c6a9c2926f43b56eb82a257da2b9"}, "b700f50c-1139-45c9-8927-43c5dc436c2c": {"doc_hash": "e78a6d6724d6126a217f552549ea47b591850804d295eae526d35e0360125da1"}, "5f87f6aa-d840-4b07-94cb-b6450e13782f": {"doc_hash": "2b59e6f23a361bde605d57609a68ff3eaa4b271aadaa8047bd01b24ce56d5953"}, "142f0ade-146a-4229-a099-b6a9f0adc1bc": {"doc_hash": "a6118eaaa16834a8add41db56350edf5989cd89a9e97991895d46846e18913a6"}, "03607783-5262-489c-a800-9624e7bfa7d4": {"doc_hash": "9fe71e79dcec919831119857de0db7e2788ee1fb4f1de61727db7047ee2dcd46"}, "ba3d7135-07f0-40b4-bb99-52fbc3688d3b": {"doc_hash": "a7f8fb9f7c460f08fbbcbeeef6e5f1b171bd02431a8c22352cc507d65c92807f"}, "908a4100-2a8c-49e2-bb19-04716070d338": {"doc_hash": "f2307130c740b37f168a019d6bbe8720e05b74e9e259e621c39c2476bebbbe70"}, "74eb1c3d-ca2f-403f-9165-ba146f98147a": {"doc_hash": "8135a0dcada4badec4b5e426c8d43ec443514622c07c3b6907de96b3410c1f28"}, "0afe5736-70b7-40e4-ae41-8c8d549d826c": {"doc_hash": "6329092bdda9089b6efd61811227a88db95e79b60e2a61f2a742a3bda8203820"}, "d73def69-ba4d-4e9e-b401-b11be4b82416": {"doc_hash": "39f6f8ee4d7fb6a3da1f0782f9db6493d1fa84f47ca911e07db81b869102808d"}, "255b6a1f-6214-44d0-b8c3-143a79e6d69f": {"doc_hash": "a49244b9c44457a7f11f4a9fd39801ede8a4362474f83d013fc28019832c4c55"}, "3f202208-b3c5-4af0-a1f6-9de0c4eca794": {"doc_hash": "2060f1ac52de6d08aea34524f3d4d5b2dd06025eff6eee8457b30e57d148e3c4"}, "516c00dc-8f35-43fd-a713-a4062b3e69d4": {"doc_hash": "f53c30a64bbe42a7c4112d24d8cffc11b84a18f4ad762d33f8ffed5b4e4274d0"}, "b015510a-98a0-44ad-a087-2dec8ab133b3": {"doc_hash": "5ca21dcefcfb6c4a468bb582646de31cbee7dc7b60fd6778960d9bfbff42f21b"}, "ac659523-7346-40d2-9bd0-b1f1af71134e": {"doc_hash": "067a1143fa97965fa3e84828be53c1d129c7625d3549a172b55e37258cd8a532"}, "e07d6102-a855-434c-a27a-fa6351667458": {"doc_hash": "150a835ce3ac1ff2b5899a889977e186540a7fa64433f147e1b1a6f7b9cd3304"}, "a0805e4c-5453-4975-afae-5a8b8e6f94f7": {"doc_hash": "c1740b7d850b9f3b4e5b2e521f07858e18081b8d453cfbe53104ef1cb62fe7cb"}, "84402524-b756-4bbe-af30-1bc6c088de1f": {"doc_hash": "166cd3ad357a26d00a89e19fc33d9fc9c30905be830dba62952ecad5b9935aee"}, "3cd33769-a765-4bb0-b415-a4fecbf9faf7": {"doc_hash": "dd653ba80b1dfbc538f44bf63d58ed70a81e2c7b856c3190896c18ff098edfd9"}, "c54cd93d-86fb-4cda-b685-45f87aef1ed0": {"doc_hash": "db3468f1774c678922225515cc4bcf189b5e687f86051d3d31415fe23ed23cda"}, "f4ccc425-43dd-4444-8d53-ebc57808c268": {"doc_hash": "49c5ffc1bfabf4a15643b792eb905d72965d80e36ef51d8bd0c4045eb542bf4d"}, "0ef40838-49a3-4387-9b5b-b629b863bc59": {"doc_hash": "2aeee0f26479f5b3cb7c8640e081aa1422a536f9b180f839a3507a96961f6844"}, "88be3ac9-e0e0-42dd-9321-be28d3d93014": {"doc_hash": "b443f63c8eb7bbacaabd0e9ccc1779d456cbdcc063992d923565c3d1b2a8e5be"}, "a81c7340-e0df-4108-90b5-2f7bf33cd219": {"doc_hash": "6699b567f0559100180610e06812907e555a6070a4b01a5d9cc2ce4ae6943b85"}, "10bc31b9-3e74-4656-9192-4fd76a336d0b": {"doc_hash": "8a9448ea3c05bf36f19a015a6d835bd063e28febd80ef0fc4c8bb9def463e08b"}, "c93fcecb-672e-4e21-a3c6-3933c291b2f0": {"doc_hash": "cdacf58561c3f90db09dcc967f0239d550cd3d8920a3dfe9c845a17d0bf6c788"}, "b566ef62-2afe-4e87-abd0-85899b9051c4": {"doc_hash": "8f18018f506928a2aacb419b009f49a5301b5959e2610c89b3214d747acb61f6"}, "11d7f8b9-9033-47b4-aad4-ecd5751a266b": {"doc_hash": "f470d97c2568128a52d2e33ac0050ad4ba6bb13eb30c9ab13ad2a21a18c3e4a0"}, "3630a184-666e-4a10-9ada-96416b58572a": {"doc_hash": "19aea4c92ac59ee2e9eea8f7439da06ed7aab9e44bdc1c8e3f8fecda80fa91e8"}, "52c3f5e3-3196-411b-a1cc-7aa8137549c2": {"doc_hash": "88660ba6f85b8e292919a90c7c0322e0e7bb8b021ac21d3eea900c4fb78736ad"}, "8193005d-6228-42ba-a51c-3fd5be310802": {"doc_hash": "dc5b5d18e6c065c822a811dbae172869c7617c619ffddc9a2256d3d9d996d4e3"}, "59d416bc-59ec-4715-81d0-a4a6e2731daf": {"doc_hash": "8c8d5752cd33d9d66d8fc31e8031200e7ab3437bc3a125042a60698835a858a8"}, "ce7aeee7-643c-4775-b071-9f78d78693a8": {"doc_hash": "b66de9012b7bfe49169339fd61767ba7f0207cef42b468e89d9765ad37469323"}, "fba2d7d4-ea40-4ab5-99bc-5cf227c352f3": {"doc_hash": "8d6cbbbe998a981e4efbf60115f6c78eed42d4faa7ebf27f461ad5cfdf162f86"}, "87348c05-dd56-419d-b3e5-d2759f1f9544": {"doc_hash": "95d25b230c1bdc086c7f21734301016d4b702ec8cf9f68f5baeedb6e42c12509"}, "bb253272-2931-4385-a6d7-fb46f508a42e": {"doc_hash": "57f4c01b7c2f0a70e8be783687a7c83db91250487b830f640c65303d6637331e"}, "0e2c83ca-206a-4eb3-83a9-95ff1305fc14": {"doc_hash": "1c06cc5c5a3129a77d3bc957c7f3fde447b3e9cee8972f4bdf05702db0fa44d2"}, "a4e87799-7d1e-4c72-a051-8cd02591474d": {"doc_hash": "c38182933376fc9a31f20bb4068d0ec3085c3a9ea3c8cd0260e19848208dee11"}, "eed7d48e-b661-422c-ba1b-fd1625f3e606": {"doc_hash": "37c6f57c5840fd35f8111775bd0c54512688c6e1941bb284edd7bd9971749fe4"}, "cbd6c2c6-300c-43a3-9474-284b4e8f0fcd": {"doc_hash": "02c3949ff6b5446bc37c1ea1658333797b664e942a49e561003d456eec5a1096"}, "268147d0-ec9e-4386-ae6a-00b0b17d496c": {"doc_hash": "4b43aeb5233337b3851714e5ebbad4c1754d5a9013f84e2f9d00c429423f639e"}, "9fc72680-8426-45e3-a91e-4bbb734c308c": {"doc_hash": "8274098914a983040d94068ffb6dcedee54a10cc7f183f277915de5a62da826f"}, "33616cbf-7045-48cb-ad07-8f4a5949ccf9": {"doc_hash": "a35ad4240d7942f0c651453f60dc7403603677029cd84fc66f60db8d92d93f21"}, "8f47c2f0-f803-4e2f-af8c-d1599f44c456": {"doc_hash": "5fc5b8b6c90201cbd10e996b70fb46fa97a18df9ce21dff017baefdca22448af"}, "155745fa-3404-4d32-8c79-ecbc77ab8797": {"doc_hash": "15921c0a1248ddf0b65a7ab40de7d3abb4e41e6e763c018ef8edd25d6d8fbbc2"}, "9b3c8654-1be7-43bb-b1b6-a69cdfafe24d": {"doc_hash": "474ccaf3a1fac460115db1f8dbe55eb697797de3f290481eba3ab1cd116efa09"}, "2f9dbfb7-a77a-4704-b997-c6d6ababc8e4": {"doc_hash": "88a845271f44270f12dcf0d08eeea7124029d4a781f69897b7fdc3356eda550f"}, "1ec3eed3-cbbd-4123-ab88-02a69dfe6b40": {"doc_hash": "015ec61d8e95c937d756b19210cea1eb069534855c826436453569c0d05ef8c1"}, "7129473f-8679-4d1a-bdf2-9ce2450a28c7": {"doc_hash": "ff152168725073ddaed0cd3d6e700adb1cdcc09e2f820c80f890c12153e94ddc"}, "7a8caf13-deac-43b9-b6cf-59ae67e088fa": {"doc_hash": "4f49643d778f72696c62993802508aa585d127db5e8accce8fd4ca146ee81a5d"}, "3124aaeb-ddb0-4e2f-aec9-a575c267029f": {"doc_hash": "73012f3bf927f9e1cb8893f2acafdaadca6dd5c83e550a755a2ae2b3517907a1"}, "9ad1b552-06a1-4bcf-b641-c17c4995b3db": {"doc_hash": "e4c2bd082b4fa51a7edeccc083c96e014d68828627a85dd02458bcf153795af9"}, "93b01571-6a44-4819-96f7-d84f3de12661": {"doc_hash": "036d60c15129df447bf6cf09030bdc5709004909eba1cee92f1bbfd00a151389"}, "960b3455-de29-40f9-bec4-fe285ff0e3a8": {"doc_hash": "b142fe561eaf701067db531ea8c5851e05a5b79bd37ffbd87b935cd648e78384"}, "cd9511fd-4575-4787-849b-d5114ca1238b": {"doc_hash": "2d991b52037b391d179015e0a26a18a758646e1a1e994bf95b4b8fa46669c656"}, "707e85d0-463c-4259-81b7-634665797bed": {"doc_hash": "aca2a1cae11275df10defab2181e55d28479d2bd7b4d5c0c29f53ad0325c3f55"}, "7af93020-9572-4c3e-a9eb-524373653695": {"doc_hash": "59b18708ee5ca1656e281bef260e614af2e0968443633131805609db63dc54fc"}, "7a201452-0449-4ee4-af26-a8050dac730a": {"doc_hash": "9ac4597f512fb50deeeb5cb4d1f0c66af4b612cb2bee6585c9df50e9adf06cc0"}, "608e44ad-b3dc-4fd5-b28d-84231d51fe6a": {"doc_hash": "2feb4747e52ab33e454594e184104de6722b7be80c6f8c8e3dd31e7c072117c4"}, "8c9287b8-2123-4df3-a65d-c0f08ec9bfea": {"doc_hash": "67fc6b6fd15db9b4f0d52722051686559da51be15ccd61fad26b49298495a9d5"}, "e1dd6a7b-de97-4fc4-b189-82d3542fe82e": {"doc_hash": "982c002d8a4bf9894c4e8dc357c8a0b764ad86a4a4141d9e91017f4bb0bad5d7"}, "d3567dbe-48fa-486b-bdd7-9e8068e1394b": {"doc_hash": "3fb9500ccc58c1aef4e2899b9d701b1d9009a3cafe4c249e2b09beff7b59fb1e"}, "e2d4a939-df28-47d2-a0a9-19e5e75878e8": {"doc_hash": "35ee99f9ab3fdccb71ff1c89a3e19f1452ce4a8200312dcad4bd230f39562283"}, "bba70202-ee19-4a9e-a90a-ce784c75e75f": {"doc_hash": "782dc83165d4be3aafb2cb71eec6b045c62539e45c11d826b987f1b08b01b5e4"}, "bf8be6ab-1925-4318-bd95-8b59cc86e06d": {"doc_hash": "2b312adef1ffb3a2ae91f78c7d7cff915aca69acf3fc8c7cca428dda3c8894d5"}, "3f9ca9a4-f53e-4604-9a81-ca6f1170d8fd": {"doc_hash": "6a8d7a8b856dedea6733b3c73fdeadcec066d1fc08c8680992c4af5777c9a2ac"}, "30132288-07bb-430b-aab5-876ee7ec5820": {"doc_hash": "6ecf69bd738bec3e941fd2aee1d6c952f890f195cb05c0c670422f5d4cb308ca"}, "0f84254f-7c00-4dad-aec8-286d2eb8b928": {"doc_hash": "055468fce763611c627364e6d9c683da95dca6d67d49d09ec96835983f963e3b"}, "358dfe1f-2289-48c4-9700-dc9410f1f9e7": {"doc_hash": "ae40492e7b0df6b9817c165e647f4b62ce04b01658929757063dc99d99c12d9b"}, "be290469-6ccf-4772-822e-cdb73f85f798": {"doc_hash": "551fd0adc2e8e8a9d8003a5df980384d83f5a9a27e8f757fc3cf47c0fc194358"}, "9104a78a-b065-431e-aed9-dcc8d5c56ef6": {"doc_hash": "b25db53e4ff2a85c12825d6e9966e82bfae60f9fb64562b3bc61c73a444673bc"}, "2494b4a7-6242-48d8-b648-ae0c0e761b08": {"doc_hash": "76c05465445d229cc51c6e5989b1c706a173627474fc44f2697dc16bbfb3af43"}, "ddc539bb-70b5-4830-bb31-ddfaeee6bb00": {"doc_hash": "d9c6f2a66f9c81a15a331779444b2e6d75beccf73047ff74552d844b845b3d51"}, "1e018e8d-7f33-45c8-a97f-0c270e86a69d": {"doc_hash": "4ed25ff0ccf0c55d2470e8e4dfb58465d0cb5c43afd0527c532a4e0b8ee13fd4"}, "5b12ffcf-f432-462b-a81f-fede63e40862": {"doc_hash": "e2d5b53c761b616c526e3c8a5f9fe1038c0865d6307cd63f4572685ad3810ff9"}, "723eca7e-9228-4bd0-9f8d-6d9d40ba18f3": {"doc_hash": "6c6d3055a13bd4b1fad864e533a65af2a098a7a6f87da1b40e5cc940078754d0"}, "8b267e18-0194-4ebe-8f97-6ff008e0ab3d": {"doc_hash": "9b6f43996108463a285df73e6151dc73e3d8476520649744aca877b4f82b4ecf"}, "de46e4c9-fbca-470d-bb91-19df4c033cac": {"doc_hash": "59e5828479f8bef4fb177361fa7f1a2b04006e8bdb983e5d0ceb5764e85800e4"}, "45d23f52-e91d-4ff2-b915-372bd68bd59a": {"doc_hash": "a9237f75efa4f442599bb9be2f65c4dfd027eb71c2cddf0cb1a5acb2b50e63a7"}, "9d8c91ec-64e7-429d-8d0f-c4285a280d7c": {"doc_hash": "08021980bba05157049b6bfeeef738fb8508bc148b4e46734e51778031cd9b7d"}, "a6946c91-28e2-4802-a826-dd8d5f9a0bd5": {"doc_hash": "4ed1941ba865b834e936dc197c47cc497e7b98d2a59691f993724b258ea255a7"}, "c32ea6cc-0e53-4775-ae62-fe94952e1e8c": {"doc_hash": "307a40460a398d2cf76120ce34285643120a65e3c1108a84f24c7255077b36ae"}, "f3eec094-2c81-49b2-af38-1405c8711455": {"doc_hash": "085bb7020aeba0d808b204f42621027231fe88d725d4254c65b20c2f4832bc74"}, "a1f06841-cabd-4417-99d8-39e9af0c7946": {"doc_hash": "c1055cd6177bd432aa3d989e1e3bdfc57eb138cbba28642dca44cd3273ef90fd"}, "353282f2-6e8c-41db-ba7c-8d2a120d9a6c": {"doc_hash": "1609141b1c2908100be6d95af1b7b5a18ad9f471c8866798313e59e3d2ee5acc"}, "81c46c2f-f5b8-488f-94b9-04c8b701e91f": {"doc_hash": "e55faabb8641cb83e032750baa8aae501d5b569bf7a5121eb7040256f41ffe71"}, "4ba529ee-24ce-4d40-a383-4abe570a17fd": {"doc_hash": "0b9484ec8dbaae1c5f467fe5cecf1262e989698dfe8357042cee468d741c40c5"}, "92837e06-1311-4cba-be99-892076ce9e63": {"doc_hash": "193ed535f53fc5a88d165b441bd9010141e5458429f68cc59e4add3617e65ed3"}, "f26af394-5cc0-4b30-83f0-20505833574c": {"doc_hash": "325edece0813e4744b3bd129e298e5c0080aa443bb55e6387f1f781af67ef161"}, "494f3bca-2271-4319-a456-0fdf6d8065ce": {"doc_hash": "e1d3c5e117841eef7f2571c31094bddc089c12a6c1b1ed40d778cb6d71b73334"}, "d3520f5f-7631-46f0-9ef7-5b6c9d3345a9": {"doc_hash": "fdaafaaf390f159c8f704410ae419de59abf5ffab78bcd9a03bde6f8b142de5a"}, "cd075503-d9cf-4bb3-9481-09583649bff6": {"doc_hash": "1d60478b4cdb8398f3bbef80762cb8e4c9e86a517943746e440091e83c0bc490"}, "16bddd60-924b-49be-ac4e-47ed1ec16c5a": {"doc_hash": "3e8da31cfa886b47364c8ec7a06779dfdc451852a3e71b6230a448ed740263d0"}, "5bb42c1b-8453-4511-a1ea-479edece2791": {"doc_hash": "88e3088c324ebf15a19680f7f902bba6b5aa434288098f536ab11f8d59419192"}, "2bfa2de4-ecc3-4695-ad6f-0263ed955b84": {"doc_hash": "b5b62108755af7143fe5c182262b960a5713c0646d16454e3f29e3cb8f73fe7f"}, "143dcd88-cbf4-4d68-87ce-219de80d9741": {"doc_hash": "e6471ccde72582bbd6ba0b8be025fccc8f42321bd508a2748e37b3ad46164e35"}, "950e1797-d9e2-406c-a9fd-336c75ad5cd3": {"doc_hash": "eb7394867921647c54747a2c71c1da17a9bd80614d6f56a52261c5db07f23fab"}, "691ba04c-059c-41f0-bef2-857f44adf8d8": {"doc_hash": "a07956677524f6593d96dd9e855c943361d2753126d4f0d2e18fa041b75eb424"}, "4ce7e8f1-985a-40a3-8dd1-892821f504a1": {"doc_hash": "17782143d18793dc1f1b583e6137aa6900e5580f2ad408b9217386b9e3cbdaca"}, "e9bca7a9-04c5-47c2-8287-8b47847248b5": {"doc_hash": "c3a3ea628c9fbe044d88409d4d42eb6fc4c71664ce95c086a1942048cdb20269"}, "a858d197-a34b-4921-ab04-b8065b850724": {"doc_hash": "e3b7c00dc45ce364fac77959e55d5d89f3a97b1d8f150c3a374d1810e5c8ab40"}, "a4111851-778f-4692-895e-a133d155d37c": {"doc_hash": "71e67c36dee0c9417969cfc23e370cc86f30d236b88cdfc4f45e5992c60208db"}, "1967f30a-098b-4cdf-a0ae-4d54a8ac90c9": {"doc_hash": "4353aad51088ee1e58af797af747b7e0111e5920f52ee7379da17d7ae8f27d69"}, "852099c6-fea0-43d7-b14a-6e336894fcb8": {"doc_hash": "571eb2cab020b6fb48c38db518805ab4128b87dddeaf254979e9c0fafb5f06e6"}, "4cef32fc-428c-47d9-ae3e-61e06e3d1729": {"doc_hash": "f762af0d26d6a10183619d3da749d2a809250ee012f26c3c575fe3d61720de79"}, "11317e73-6fbd-46f3-a5fa-da02b1275f86": {"doc_hash": "0ade7d18676f4783d52ea03cbbecb7f7ec9012cc8f0227bd7c0404958d6dec13"}, "2d3fe42c-4570-48e8-b9b7-c5203dcc2e21": {"doc_hash": "2245229c28266222a95dcb0b7f4d60e8fd39b901ede69f1eb242985f594a38ff"}, "3f6a6434-e5ff-4f29-acc3-643a67dee185": {"doc_hash": "73560bc67e481a8f4179b599a7403718bf82d3dfb81ca6bcaa8e0c486fac21b0"}, "7d9ee3fa-d4f9-4298-a82d-1ee5fdab5153": {"doc_hash": "c99c9f86b1d6c8ecb43d81deb75eddb206e6ab8ce9a809d6a160a5a3a99ed5dc"}, "674d6cf1-f41e-4203-b758-047caa4c2fd6": {"doc_hash": "6f09adecf1d4669e3e8e8b6a9d58f2d5de3b6f3524f377c3b34ebb3bf98fc53c"}, "e0c0164e-9d5d-4999-b1f9-f60343af5a1e": {"doc_hash": "d715b61caabb03e1c6e675bdd1aaaa616fa38e303199ada947f014c33011eac0"}, "5d9b0070-aa7e-46b1-bf9d-56e017d16512": {"doc_hash": "4d4a5caae9de1642c5e68bce7d45e98d7bc4cfc16e061289275aee3d27e6fe7e"}, "a5a96faa-8bbf-47db-93c2-01d2e1bce5f3": {"doc_hash": "eb39e8d8f7982d58921176ad6690bd82fc7d794cb4881faf92988da31653621d"}, "0bcaa809-efb2-4f19-a812-43f62fbcc4b6": {"doc_hash": "717afd54e5d69e68f48f78949c84855f6f7acd08e77f25d4598f2f0c038d8927"}, "014ec0a8-4bb1-46e6-a5ef-3381fd4030e6": {"doc_hash": "3fff70d90390577dd8f8c27d4adb6b9c7b899f90fb900987775e6d554d1cd45d"}, "e1a2dac7-95cc-4a92-9de2-df35ab84b71b": {"doc_hash": "5ce7ff15e01b38a9e133da7f4fa884242eccf9ba472fb1776b94f5f0311912e5"}, "92b2b6cc-f932-4a78-8138-b0af129cdaae": {"doc_hash": "54005cebf9027bcafccc537861d51fc41c83715cba69dd49c058e6373589cc42"}, "4e68365f-068c-471c-8fa6-07aeca9c570a": {"doc_hash": "3f4cc57709c3d31766bc1c4b6b84918e3d6e87732be82c30fe333982a023fd75"}, "6a06bdfb-3fe3-4b04-b4ec-9b1f1f2078ce": {"doc_hash": "9b5e4abb9b9771c58f6ef778886249560d5382f8cf81aa182ebedb4db81825eb"}, "848878d3-767e-4bd5-8f81-c6e24d94454b": {"doc_hash": "387939c28281f43cfc96f1fd60ebb0256f1072b0ddfd0536040acff036f9342a"}, "d3a2303d-f8b7-4b94-a948-e8620f8df25e": {"doc_hash": "d450bb019f95920c1148b5436ddad11e459f23b42c481c2d1fdeffb6035e8f82"}, "7b966e51-a0fb-4d86-b725-c295c01d8805": {"doc_hash": "b194558fb9feba080f527affead974b73a7eaa43abd4cac6c650599441bcdfeb"}, "f649d7cb-da8e-4430-8f01-b07785cb5b59": {"doc_hash": "eff0789d9ebe76728a637bf8eee57caa618710a4094ecb4c5d26a57b0c6e38d7"}, "47ec847a-d874-422f-9290-5a75a11ead92": {"doc_hash": "f7ffc3ce9ee947ac8ac1f0621265996751aa653852b1a4de0a92f33a3e7364b9"}, "3cd1d469-0aa5-4360-921a-6e163e88ecd3": {"doc_hash": "119cc25552d1fbff60c34cda25a5fbfbd8294b08c43e884d3b77871556bb8453"}, "943b2ac0-1402-4f8d-bc3e-d097667f2c12": {"doc_hash": "8843c50d5e35f4412fd79b1c67164ea87d488bd9005fdf849e121a17eea295fa"}, "0772d767-1d71-42e1-bd43-ec2a8be42c10": {"doc_hash": "d2861fee150d199bc55712f045fbbd5c75226244bb907e66f1c702448e701221"}, "dbcf648e-d7e7-4d21-b83b-594b1bfc3f5c": {"doc_hash": "baa66f754dd4f9376713859d2ffa28048a848ee71d1c03b7fe06f12a43dc2633"}, "343e85f1-500a-40b2-9d47-a2beacc38e58": {"doc_hash": "efd62d66a7735b1eda3160ee916524d5840926c01ea7a3291bbb4a462bd60f83"}, "c623fa36-2d98-4505-9e25-58df2db3a6ba": {"doc_hash": "2af8793f637f7fd63a5097a27420c1e3d5937c4a1ca95621cf69ce5fa3259a5c"}, "8da02310-cb83-45b9-a3d9-42cf63fe3d0b": {"doc_hash": "7ff1b2212fbf12ebf9ea8e24e271d50294521a59604ef0091eea195772a01f5d"}, "37f6d1a1-eec4-46a4-9d61-a8377fe3e77e": {"doc_hash": "254eb1dd7c6b61f85726d61c40217ebcf51f8ce1bd56d514372859f0b782dcd7"}, "ae706473-fef6-4555-b941-b301c04bb3cf": {"doc_hash": "fd5603611a7684ade274f2cf1106a7112f8fa086b0507e52fdcbe613334ae6c9"}, "1c735c43-6bf2-4679-a6ae-6c96dd34e388": {"doc_hash": "292b24b235283b17e2b6fe62049538c43f28a10c88a2be2a14f8b4e0e26999ea"}, "c980619e-9217-49e1-8fe9-366ddc34bc5d": {"doc_hash": "cc38c98ca0d291254203bc8e6be85508504b9260c946f61b44765386c0925ed4"}, "6ebac492-01b5-4265-9a44-e4f1fb18a19e": {"doc_hash": "dd98d51830fb9cccb28d5b149857c9991d69b5cd4b8632e0a39c17158e1e91b8"}, "152c7edd-f75a-40fe-a572-aae9a00deda7": {"doc_hash": "0e275d9a7463dfef3d15689037014c06c4514d458dd887e81515174b7e0ba80f"}, "440c1cdf-de46-459d-9473-49ddabfaac93": {"doc_hash": "c14a164c17040e93daa05d080209a5e2fc66eb9cfc63774d11fb73cdac5f30f5"}, "17e56c55-41f6-47b4-a1a8-6b954de62e61": {"doc_hash": "81e35952e6d93036ea515e9fb7e7a82f9fd9d3bcb51ec730aa760c90801bb1a9"}, "eb32c2d7-3c92-4b4f-8b74-b9630fcfecce": {"doc_hash": "0712caf685c4a3c05ebe3c2f66faeee64590da014c2440a5d32c68eac71e0e87"}, "e6ed7066-287c-475c-b311-ef53fa8237fb": {"doc_hash": "7634730957fa89b263528462982101c87bd454f28b8d31b21cf1d00f03ec2e0b"}, "1bb37ad9-bbac-4507-b8cc-db3520831e02": {"doc_hash": "d8a6e1ce76671e477c38eccc08d780b7355d506249d0c92cb2f01b7704f03434"}, "6efa7c17-ec93-4947-8bda-ff857bb1a138": {"doc_hash": "7641999d4666a835d5117d3fc3be92f5eaa8f86a0639ffe396b825e2da2b68c8"}, "a057ce88-4814-48ba-8a36-e0ab1ef478c1": {"doc_hash": "8a6e66a958622e2433fe9f9848991d60b879626baf8de2e265162e530ac9a6af"}, "74b7fd9d-655a-4263-9710-0d52284273b6": {"doc_hash": "1fad4ccb55e76098b7ec76ac1ac60814c8db6b69406e35b2c3a88d592ab2a889"}, "24646fbf-2a6e-492e-b019-5ed08b7f03b6": {"doc_hash": "540b7df7071b25ba75f8f9e755cf9edafc936dcbd28246a5a1f49201e25bf2a1"}, "a6e2c600-cd3a-47ad-8744-69a6e6185316": {"doc_hash": "62b0b380b2ee76088692367214f01407abc6693f005364642368a275a2afb9fd"}, "fe0b76b5-f71c-467a-8397-9a9b34d0f71a": {"doc_hash": "420432e12e5201c5604e1fec3258ff798208ba082779189f366f8f720bd3dff3"}, "5258a212-690a-4c23-8440-7e008902d260": {"doc_hash": "1b48da7fa91e1bf14c7ef76eeeb865136c6d9a945ba47fbc81ae4c19cb0269c0"}, "26761a96-e5a1-47ea-95a6-4373f37f48a1": {"doc_hash": "42bebf229e0f64c65e1e4310e1eacf67d1934761cb86578efd2d3f9e514bf385"}, "449bee29-05b6-4d00-ac43-bfc7df81cbc4": {"doc_hash": "c7b3da8acfc62c1cf3d2c88fec68821a1524e615f4a85874fd24d3fe6e4e604a"}, "9570b23a-0a7d-416f-85be-58fd624dd6f6": {"doc_hash": "3f48d53d908993657defc371cd01d65b79608d0a0df71ad90e53663432986f5f"}, "d1d7d505-320b-4596-a384-e0e1ccc66db7": {"doc_hash": "ed4a9e8bd5ae7c69ab4a8615cb6841a439dde58b81ed6975215c652820f5644e"}, "58de7747-74f4-4cc4-a446-fba876ddc04a": {"doc_hash": "f937f9001df088ed0ff0e2609dea121214845aa6d1b5aa91bc56344c1d394545"}, "485a1c3e-c2da-44f4-b9ec-ccd26efe7238": {"doc_hash": "9950eeacc2f602a332475ea8c18e1f8eec22dd5a4d7d9a9f6cb86e041d00d410"}, "ed5996f2-250e-4290-9b86-c404faf8dccc": {"doc_hash": "78f758e292af28cfc6bffb4439eb6b1d4fe1f54ffd2a71f1141ace8d933ecd98"}, "c797e5cf-5ca0-430c-9e3f-20eb20f77bc6": {"doc_hash": "5724c77d34c4348e52751e5450c5aba4a30d359e0b6df884aed99edfec5f3521"}, "ea525757-0554-4628-bc77-af600cf1060f": {"doc_hash": "4711a9a1d8e5158dc2f20eb75f77204ea6b1588e60c449a78009377f10246fbd"}, "5b2a82d7-049d-4fe9-9e15-746007572c5c": {"doc_hash": "9ce0d359d3000ed564ebaf124dfe86cc89c0b3e8ddf3fae37ac7be5c06018054"}, "9e1c6472-477c-4ddd-b8c6-dd0cb4c479cf": {"doc_hash": "36b1ef0d84df912bfdd221131854ea3b65490952a8ad83067369d55bec214a66"}, "6204f493-5854-4ec8-8c9f-7220c13a9ee3": {"doc_hash": "56f6f09b55041c3a8c5edfb2ed5fe4cfb7c18e1d386e6cae5d1545245b04df06"}, "77075225-d6d6-4ce2-9107-9213391c2e3d": {"doc_hash": "57e49952bc7649d3a780a1ac4fa8288a65d343d7d446330c5edd3b4aab530441"}, "f5742773-a6bc-43e0-940d-f1cc692c5e82": {"doc_hash": "c4a5302fef7ae9fadfc5426e41925c2299893c9801917223ba12c6d3ee5f283f"}, "be0eaefc-bde6-4b96-875b-c032380a80d3": {"doc_hash": "68e5a13b47e457e56c07a65d4a090709300b9beaf5d1905f53cf47380889521a"}, "1b341c41-8162-49b6-bb91-89080b046945": {"doc_hash": "6fa29b264336e7c6e407d26988f390be0e636a0cfc9cc6a3fda44e83122345e9"}, "18dd8080-215e-4d38-8937-b297a5dabd88": {"doc_hash": "8666cc731629d128e31e910cc1116dbd8e546042562bdae7c68990c26d3724c8"}, "f97bd38b-afa2-4c1f-b2cd-d49ed72e0c56": {"doc_hash": "93a2818d964e50c545f851750b9fbf902703fc93aebad89a52c8b0d4ff442c25"}, "83d5360b-4c21-4330-88f3-c5ef9f35e0a0": {"doc_hash": "fdca3d7f345d4e1a67d17d785a656ea89bb63a7d796625061df9284f50fbc9bf"}, "4a090aff-483e-4bbc-a9d0-2f06057c4eec": {"doc_hash": "6e47de0cd84a0c1d8c26d564af678ffb4cfb1b23838032d2ffb1ecf2b429d228"}, "6ec7cbe1-c7e6-4a25-8505-1b335d39ede5": {"doc_hash": "896c792b9ace740d673b9baa2fedfdfeb37434f4d1db188222c5a6f0c86c5a04"}, "375a6d45-5b96-4066-a609-92976da74def": {"doc_hash": "9144208dbdbcd6eae8eef221932a4dae90940888ce876262b3f1fa565c9e4382"}, "1206487c-318d-4d86-a9cd-d6639a5dcae3": {"doc_hash": "6343717c8517639493067417d93898f4b2679b6d08284a7fb3b005a81d1336d0"}, "3aff15c2-2562-4613-b2e1-a29fd648478e": {"doc_hash": "ce4ab2e12e2462a8bc1e8c0280af108e313d2cf4fdd7f6132a3edce7bf7adc35"}, "276b72d1-6bb7-4aed-b700-142bd8735d56": {"doc_hash": "20614885c76dd6482a01cfa66b613672f6a98d588f8bb2eaaca42b50b6c7fcee"}, "96d63c4e-0d89-46c8-a619-3418499348c9": {"doc_hash": "64daaa96996ccb1fe13fb23b46f120a19ed6a34cb4ddf05df6eeea890de73f10"}, "4d388dfe-1dfd-4445-b93b-e2a95a14d509": {"doc_hash": "9d5199d6533af50be139c5bd089fdddc0dc7e0b1ec6c8f6282763b93719a2d1e"}, "3c03b062-1584-4976-9197-1faf18348058": {"doc_hash": "66a8337621cb68ab41ee708993ecbf35c5ec772195a7b142a025ba69af07d2d6"}, "1a898361-f9d1-4490-9b85-8a00517d1782": {"doc_hash": "aa5870f18aa8d3f356585a42d383c3f7318c48821a3f67549a05c5d415d843b4"}, "74d0cfd6-b76f-4d8e-970e-ef68500db9dc": {"doc_hash": "7f480475866d61d52fea547824f7e3a8c6ecca9e559eb4f0893821bc39cf082a"}, "4beae257-2931-4d2c-82fd-a0e1fb7c98e2": {"doc_hash": "2df59ea3100ddc62b08135dc0e4359bdc9d6390da71793b069a1c4be3cff4c91"}, "f6e0cf90-f622-4d21-9032-76d36547960b": {"doc_hash": "735f01372a6c3f4108e201d7e403d9deece8c4ba0ae50d89541456154c9e00ac"}, "4935ca81-a397-4d14-adb2-222fd7176b32": {"doc_hash": "46ad9bd339722cbfa77f0d423fe4f99594ed38170dc51a9b2a32882e46cd5d47"}, "34891eee-e5d1-4275-8315-ade359a397c3": {"doc_hash": "9c26850cb1ff78a8d0b8bc29e59695cc7f2f36898ec1aafd1dc00910ab7de7e4"}, "4cebcabb-0c24-41f6-8a4c-ebede2fcb238": {"doc_hash": "f9bd4a1ae78a56e975e34162801051a1d931162ed1be250b1a883be9258fc31a"}, "ef54843c-ea66-4ddd-97f8-534fb50ac9d1": {"doc_hash": "282bf1a3059f3625b51e271baf5f19fd8091969b3e122f89c98881e8ecbbc733"}, "309bbfa1-ddc0-4501-9141-12672a740c34": {"doc_hash": "5e7e39e37fb5405875ae6ebf6ced1992d0ebf517a9aab50959008e91641562a0"}, "44d3029b-b91d-44e4-b396-d067e6490867": {"doc_hash": "c5d91483cb55427dde9333ea0650c5521f9608048ca785f6223e240ea330dab1"}, "3bd14228-a814-406b-a2c4-0e2b1653bfa0": {"doc_hash": "5a7e0f41e9a94f9dd24bb35641daae1fa703ba11e413b4f69376e98e9889f60a"}, "c6440385-41ca-4d63-a640-c6b60ef118a3": {"doc_hash": "ac1c079416e43c043411efebc818af27fa9f89b01fe6ae97f631c9c84a071a3d"}, "abfa6591-e1b9-49ba-86ec-d4a7353de27b": {"doc_hash": "085d8773e600f78d7aa55eb3b86514a1f97c358b0b889b5fddf8e1f548edc657"}, "88ca3a9a-c571-45ca-a2a0-2c871e74d60e": {"doc_hash": "adeb1424857576190f188394f82817af4b082c90381fc5afdc2a13c4bd04637e"}, "84e16337-50af-4ee1-85e3-7146a09029d8": {"doc_hash": "b038fe5b0438502c2b88a32df642e3df9165fc40987253d9071b326be9af6be4"}, "653a7c4b-8834-4b8c-b8d2-2dd60d663502": {"doc_hash": "b0a54dd5428f8f79486e0172322095b6ce125644ac30fc34b25705f91f194802"}, "d6f8857a-1761-4121-b2ec-1860929989cc": {"doc_hash": "693323cb5f9fadb1ec398cfff191962028dcab6a30fb7c3f0d9a6e3220623895"}, "563894cf-9067-4c75-9966-f4ac117449f7": {"doc_hash": "4a3493ed1848e8eca17a6e3459b1862a356722dc6e9871c0e762e25f7160846e"}, "35fdf474-c1b3-4c83-ba9f-bec0f96a7554": {"doc_hash": "fc8f1b1226ddb342ad63bf17ce02be8406685e2b16b78acd3195bbdcc06e0280"}, "0527a179-f47d-4bb3-85cb-a8e55b6ddea4": {"doc_hash": "9c408f8787d102d7b1416fb7bb5fa1c0a69372ab356ae031e2ea2e6cdad80d2c"}, "ae74c5b0-989e-4543-afcc-edff35ab5525": {"doc_hash": "af0bdef841c7a9b9545d7b162fbf4fdb2d1eef1a940577e543e74047ff66a87b"}, "c3107673-6add-4e2b-abf0-79ecf797b6ba": {"doc_hash": "fabd83fc00fb6071220e28c325cf5b3546f49fefebb066b87d9003db5f1ace7c"}, "18dce106-3e5e-4262-8304-99a504a69248": {"doc_hash": "c80f870f79c6ad1c0a392995956c407eb23b9b7ecc3b6a3fdf897af91937baaa"}, "9942236c-3fd4-4e84-b6db-ecf3dbe1db3c": {"doc_hash": "ad29688ebab93fd5490d80cc9fbdc926c0fc63124cd951d0940923630ddb14ea"}, "32270606-7c44-4d50-b287-0d70cc208afe": {"doc_hash": "58d76abb24fd83fd7387a7b7d22305103e3e23ebac4fa4849d0f2230422137b0"}, "453fdf1c-db20-4a2c-bf71-822e09417986": {"doc_hash": "71aac01a3fac4d596cea5656dfdea06df513e284e03fddd09c39222379011c38"}, "124fef4a-5350-4725-907a-d8d7b4ff6932": {"doc_hash": "a8d81a388686c0064d744619518ddbf69f48f327d9cf41f85d11f43ca86e5851"}, "4eb8754f-2aba-4ab0-9765-bb7277f949a4": {"doc_hash": "101d0eec19959bfe5fe573aa7018db84775e52ed9037556da28f1adb99e5bf4b"}, "f2313df1-79a0-40c5-9819-8c2f7003456f": {"doc_hash": "ddc747c93c0cc65c1745352a98e6f8d75a97bac98be753f169438123441597bb"}, "0a53e5ad-b647-446e-ad34-1deb0a7a6442": {"doc_hash": "7c4f5c079ab0f94f68fd19b73a63ce65c0350f05245e8b463da3ace3ad14ab3e"}, "ba338796-570e-4ad8-a295-c8bf1d7d3c21": {"doc_hash": "cc884a3c7b30df7a00c20d00ee59f2e50093578971061dfd01db916a64db894f"}, "949af885-3af7-4e96-8f8a-6ce50b9ff03c": {"doc_hash": "5a383fa3e9a702870d60381e9df499f345a3864dbf0b94cd1b4a4b2544da84b6"}, "133c1fa9-d6d2-4a31-8a6c-bd35e63b0acf": {"doc_hash": "1b6c7ca6df6dd759420aa56158a6a1e4fc8ce02e368696c37482aa54bbe8bdc7"}, "bbfbd202-71d6-4988-bcf6-454a96b8552a": {"doc_hash": "d91a3a72510ac520665585340dac7ed3181f9a417bc239c5f37c8f9b5f21db27"}, "8e7a0086-b83f-478a-b717-b2835be58071": {"doc_hash": "78ab9ac307b16aecc992a3f4a9e430fc418f64e8c27796f3020a52c89a2524cc"}, "228fd0bd-68c2-40be-bba0-8187b36ac2d8": {"doc_hash": "bcc456d3567c19acf0b9462d093c1509552ed2826e2dfa20856fa7f5eb4884af"}, "733c6af7-9920-4e06-9d17-bdae1ea700ef": {"doc_hash": "4d52f8d7f95fe6fd77e98c22e3d93d71d092e134948ece119e53560751a9dcab"}, "d4226151-ccac-4430-92ec-d1353b10f961": {"doc_hash": "f6642e0779ca584f3246c6ea4ffbf43676328848f7427b4b82e4a2d472172e41"}, "687a0f25-daf1-4a99-95da-bb9cefab34ee": {"doc_hash": "e90d91c385b3d74a3b23b06e5cd66f635d585029cddd75ea1301ec53d1ab89ac"}, "ec92cdee-f64f-4881-baac-03c7f83a856b": {"doc_hash": "463d7bf8b0091f1840979a3b134bdbce4e5cb371777eb32c5172fde979cce5ab"}, "3d85146d-db46-4b7b-9502-29fad17afd22": {"doc_hash": "72052baf0c2df557443f789a370e5c866ae3f8dce147d78742aa902e810a4036"}, "795d23c5-75e9-43e8-88cb-bceeae772581": {"doc_hash": "b6feda3fb258ecbea533978ebb6e7fe858344f7a0ae6a2b4527270502d2336b5"}, "a6f5d9be-66b8-45e1-9e7a-e2ffcc32b444": {"doc_hash": "82e00e52dad26643ed5a900dab340a9213ce44df25c95a16635b6c5246969b83"}, "50f1a77d-2e40-41d9-8ca7-a8e97bd07d99": {"doc_hash": "613d0f8ec60d78af8af2eeaff043911b1e5e7e6f7c8516ac7378cf6d6dff6e07"}, "a6a3de2d-4e6a-4453-9a55-0168b24bd5a5": {"doc_hash": "20b489b1a5b5fa79bf3c11688b50aa4ee28f6799b343816e6b7628e18e644965"}, "8f1f6ad8-8a20-4841-9509-a71bce32c69b": {"doc_hash": "b4dcfb2e2a4c26371d93df4d657a665f91fa80d712c08e1654aeb80c2c36f504"}, "1d1fe977-cf56-4c87-a133-7aa37b9b634f": {"doc_hash": "87563f1aafeeab034f70221ea9b7f75fefc360f365f75618a849b9da4ce2086d"}, "c882a693-aed9-4ef3-b57d-2fc07270bb57": {"doc_hash": "f05c9b765a8a278f187b629176d2889f9aabbb2c7961395515eced801cfae689"}, "f84a97ca-9388-490e-9c4e-ef6046b8231f": {"doc_hash": "e7bc34399879f95a32e09572637387c114224050ef4897c774be29d57a5b6b95"}, "01c05495-adfd-4316-b2ce-21e05a24f70b": {"doc_hash": "846fd4f408c6cf1f6102e2b410bd20643360c6a9c2926f43b56eb82a257da2b9", "ref_doc_id": "3213ff5c-8c24-4f2d-a974-af52bc835c43"}, "8aeafac7-9e2c-464a-b214-9ba2ae36fd80": {"doc_hash": "59a9830786a335e4c4f137ef3b8b1f3b5073d4b6b416bee1b143a593f6ffc03a", "ref_doc_id": "b700f50c-1139-45c9-8927-43c5dc436c2c"}, "1ebe3d61-3d0b-4cc1-94ea-993080934e8a": {"doc_hash": "a349f4a1691881cc635fdd1cac4d8a3596d3f7daa7d5a8c2e98cec3e6267d7b5", "ref_doc_id": "5f87f6aa-d840-4b07-94cb-b6450e13782f"}, "b59825bd-b723-41e7-8537-7781a9e15391": {"doc_hash": "074342b84a000c70906c822c9f2b20c4240d7034f7f4bbf5de798b50bf685866", "ref_doc_id": "142f0ade-146a-4229-a099-b6a9f0adc1bc"}, "1fa93bab-ff3d-4a36-a4e7-9675a2d0aefb": {"doc_hash": "9fe71e79dcec919831119857de0db7e2788ee1fb4f1de61727db7047ee2dcd46", "ref_doc_id": "03607783-5262-489c-a800-9624e7bfa7d4"}, "5c66ea5a-c497-4946-b957-5aed34ab4531": {"doc_hash": "7529d8d26dcba474f92c2e8665a89e77ff1880e28c702bb2de6a618f89830405", "ref_doc_id": "ba3d7135-07f0-40b4-bb99-52fbc3688d3b"}, "b989c3da-91f1-47a6-97cd-3d4a75903f75": {"doc_hash": "f2307130c740b37f168a019d6bbe8720e05b74e9e259e621c39c2476bebbbe70", "ref_doc_id": "908a4100-2a8c-49e2-bb19-04716070d338"}, "c49e5693-d851-4cb3-8d57-bd85dec7f0a2": {"doc_hash": "8135a0dcada4badec4b5e426c8d43ec443514622c07c3b6907de96b3410c1f28", "ref_doc_id": "74eb1c3d-ca2f-403f-9165-ba146f98147a"}, "73439f44-5cc3-4938-bca5-f226ef367283": {"doc_hash": "6329092bdda9089b6efd61811227a88db95e79b60e2a61f2a742a3bda8203820", "ref_doc_id": "0afe5736-70b7-40e4-ae41-8c8d549d826c"}, "664e8cbe-9ef3-4309-86ad-6935567a1b60": {"doc_hash": "09b8ace682f2d66e057720bd560243a86545694a06ed9970314fed393441f0e7", "ref_doc_id": "d73def69-ba4d-4e9e-b401-b11be4b82416"}, "ae4b564a-d66f-44db-b04c-a328009cd3d5": {"doc_hash": "a49244b9c44457a7f11f4a9fd39801ede8a4362474f83d013fc28019832c4c55", "ref_doc_id": "255b6a1f-6214-44d0-b8c3-143a79e6d69f"}, "0fa1efec-9424-4847-ad18-ad8fa899aa29": {"doc_hash": "2060f1ac52de6d08aea34524f3d4d5b2dd06025eff6eee8457b30e57d148e3c4", "ref_doc_id": "3f202208-b3c5-4af0-a1f6-9de0c4eca794"}, "03e97897-da03-48a4-8794-a80f3bacb5a1": {"doc_hash": "26763a3244414dea0c8f17acfca090647a01f0019b211234fff0a68aa403ff6b", "ref_doc_id": "516c00dc-8f35-43fd-a713-a4062b3e69d4"}, "08e0947b-5fcb-4ab5-ae52-d302872f43ec": {"doc_hash": "5ca21dcefcfb6c4a468bb582646de31cbee7dc7b60fd6778960d9bfbff42f21b", "ref_doc_id": "b015510a-98a0-44ad-a087-2dec8ab133b3"}, "f6eb5175-cfc3-458a-a5a2-e2e2a50b4cb8": {"doc_hash": "32ead2098dc77dc0cdf7fad92f29ae7195954f0fe2fa93e95728f0f6b2fc323e", "ref_doc_id": "ac659523-7346-40d2-9bd0-b1f1af71134e"}, "58038040-1eb2-4cb6-990b-75a418d07783": {"doc_hash": "150a835ce3ac1ff2b5899a889977e186540a7fa64433f147e1b1a6f7b9cd3304", "ref_doc_id": "e07d6102-a855-434c-a27a-fa6351667458"}, "0f0fe4d4-74ae-4dae-af76-2df2150979a5": {"doc_hash": "c1740b7d850b9f3b4e5b2e521f07858e18081b8d453cfbe53104ef1cb62fe7cb", "ref_doc_id": "a0805e4c-5453-4975-afae-5a8b8e6f94f7"}, "582ea820-9b83-49b3-b861-e31f24500685": {"doc_hash": "166cd3ad357a26d00a89e19fc33d9fc9c30905be830dba62952ecad5b9935aee", "ref_doc_id": "84402524-b756-4bbe-af30-1bc6c088de1f"}, "b069d57d-86d2-4070-aa8e-b6e1d788622c": {"doc_hash": "dd653ba80b1dfbc538f44bf63d58ed70a81e2c7b856c3190896c18ff098edfd9", "ref_doc_id": "3cd33769-a765-4bb0-b415-a4fecbf9faf7"}, "ae1e9bc8-44a3-4210-996d-0a6b0d1f4459": {"doc_hash": "db3468f1774c678922225515cc4bcf189b5e687f86051d3d31415fe23ed23cda", "ref_doc_id": "c54cd93d-86fb-4cda-b685-45f87aef1ed0"}, "dd968119-91dd-496e-beab-48eedfc44612": {"doc_hash": "02d711faf911847586adb955b275702377a46574e532893578342f487a7c3101", "ref_doc_id": "f4ccc425-43dd-4444-8d53-ebc57808c268"}, "bdd1deb3-38d8-4356-a2bf-fcf12e4d6ca2": {"doc_hash": "2aeee0f26479f5b3cb7c8640e081aa1422a536f9b180f839a3507a96961f6844", "ref_doc_id": "0ef40838-49a3-4387-9b5b-b629b863bc59"}, "006973cd-936c-44b3-8cc3-b2ad1a3aa1ba": {"doc_hash": "13a64f75da0724d7c5836e3a5950fd0de65f3de5bd8841d27cbaf5d572a21b49", "ref_doc_id": "88be3ac9-e0e0-42dd-9321-be28d3d93014"}, "bbd40ded-1082-4e46-85e2-c899938debb1": {"doc_hash": "6699b567f0559100180610e06812907e555a6070a4b01a5d9cc2ce4ae6943b85", "ref_doc_id": "a81c7340-e0df-4108-90b5-2f7bf33cd219"}, "711091c8-7551-4ef6-8796-910f1d7b8d7a": {"doc_hash": "8a9448ea3c05bf36f19a015a6d835bd063e28febd80ef0fc4c8bb9def463e08b", "ref_doc_id": "10bc31b9-3e74-4656-9192-4fd76a336d0b"}, "f9eaf67c-26b5-43b9-89a8-d130743afbf9": {"doc_hash": "cdacf58561c3f90db09dcc967f0239d550cd3d8920a3dfe9c845a17d0bf6c788", "ref_doc_id": "c93fcecb-672e-4e21-a3c6-3933c291b2f0"}, "7920b910-679c-4333-89e8-497f857726df": {"doc_hash": "8f18018f506928a2aacb419b009f49a5301b5959e2610c89b3214d747acb61f6", "ref_doc_id": "b566ef62-2afe-4e87-abd0-85899b9051c4"}, "60610e1f-b039-4b9c-b8f1-7f7ef79c1b28": {"doc_hash": "f470d97c2568128a52d2e33ac0050ad4ba6bb13eb30c9ab13ad2a21a18c3e4a0", "ref_doc_id": "11d7f8b9-9033-47b4-aad4-ecd5751a266b"}, "f9c39f70-cd3b-43d6-89cf-db214ffc7838": {"doc_hash": "19aea4c92ac59ee2e9eea8f7439da06ed7aab9e44bdc1c8e3f8fecda80fa91e8", "ref_doc_id": "3630a184-666e-4a10-9ada-96416b58572a"}, "b5da0c19-7530-4809-ba60-0f340ab78674": {"doc_hash": "88660ba6f85b8e292919a90c7c0322e0e7bb8b021ac21d3eea900c4fb78736ad", "ref_doc_id": "52c3f5e3-3196-411b-a1cc-7aa8137549c2"}, "db7bee45-925c-4103-a72b-c6f6c7093253": {"doc_hash": "dc5b5d18e6c065c822a811dbae172869c7617c619ffddc9a2256d3d9d996d4e3", "ref_doc_id": "8193005d-6228-42ba-a51c-3fd5be310802"}, "d24dae32-74a5-4c98-9831-f8751b5c079e": {"doc_hash": "8c8d5752cd33d9d66d8fc31e8031200e7ab3437bc3a125042a60698835a858a8", "ref_doc_id": "59d416bc-59ec-4715-81d0-a4a6e2731daf"}, "4e835b84-892f-490e-af73-a7f4475cf64b": {"doc_hash": "b66de9012b7bfe49169339fd61767ba7f0207cef42b468e89d9765ad37469323", "ref_doc_id": "ce7aeee7-643c-4775-b071-9f78d78693a8"}, "a08c638c-23a9-4e05-a7ca-ce99eeb66994": {"doc_hash": "1b24d5298a0aee60d6275d4f5d62a5dfb1f42a7dd6c62bd5353b49e3f41d7595", "ref_doc_id": "fba2d7d4-ea40-4ab5-99bc-5cf227c352f3"}, "55f3fff1-41f8-4fe7-ac45-92d575a7469a": {"doc_hash": "d5e8247316d7622af95056416a92a64d0c0abcf114a80f0c1649b3020f3e7314", "ref_doc_id": "87348c05-dd56-419d-b3e5-d2759f1f9544"}, "b3c82c8d-78bf-4280-b0ca-ce5f7a385060": {"doc_hash": "3c9ea45078803eb566e8ccdb0f15d268ee692bf01dbf2468cd814143fd6976e1", "ref_doc_id": "bb253272-2931-4385-a6d7-fb46f508a42e"}, "2bc27c9d-608f-442e-b2ee-2d64444e3c24": {"doc_hash": "1c06cc5c5a3129a77d3bc957c7f3fde447b3e9cee8972f4bdf05702db0fa44d2", "ref_doc_id": "0e2c83ca-206a-4eb3-83a9-95ff1305fc14"}, "65ff2806-b724-451f-a5a0-812362ee79d9": {"doc_hash": "c38182933376fc9a31f20bb4068d0ec3085c3a9ea3c8cd0260e19848208dee11", "ref_doc_id": "a4e87799-7d1e-4c72-a051-8cd02591474d"}, "799acb1a-88dd-46b0-816c-d028b16ce76b": {"doc_hash": "37c6f57c5840fd35f8111775bd0c54512688c6e1941bb284edd7bd9971749fe4", "ref_doc_id": "eed7d48e-b661-422c-ba1b-fd1625f3e606"}, "44fbd4dd-c6c9-410e-b96e-66d63ac62be9": {"doc_hash": "02c3949ff6b5446bc37c1ea1658333797b664e942a49e561003d456eec5a1096", "ref_doc_id": "cbd6c2c6-300c-43a3-9474-284b4e8f0fcd"}, "570fda88-9932-4ad4-9684-6ff3896eb9bc": {"doc_hash": "4b43aeb5233337b3851714e5ebbad4c1754d5a9013f84e2f9d00c429423f639e", "ref_doc_id": "268147d0-ec9e-4386-ae6a-00b0b17d496c"}, "d9f0af45-b744-4007-aeee-98eead94cd35": {"doc_hash": "8274098914a983040d94068ffb6dcedee54a10cc7f183f277915de5a62da826f", "ref_doc_id": "9fc72680-8426-45e3-a91e-4bbb734c308c"}, "2b826e2b-bbbb-4393-808a-e6c57d66dbc3": {"doc_hash": "a35ad4240d7942f0c651453f60dc7403603677029cd84fc66f60db8d92d93f21", "ref_doc_id": "33616cbf-7045-48cb-ad07-8f4a5949ccf9"}, "85d707b4-493c-4959-bb30-c47a37540424": {"doc_hash": "5fc5b8b6c90201cbd10e996b70fb46fa97a18df9ce21dff017baefdca22448af", "ref_doc_id": "8f47c2f0-f803-4e2f-af8c-d1599f44c456"}, "5bce91c1-ad4a-4750-aa75-4a40014b88d7": {"doc_hash": "15921c0a1248ddf0b65a7ab40de7d3abb4e41e6e763c018ef8edd25d6d8fbbc2", "ref_doc_id": "155745fa-3404-4d32-8c79-ecbc77ab8797"}, "4bcf327f-1b76-419c-8d60-f0370e332dcd": {"doc_hash": "474ccaf3a1fac460115db1f8dbe55eb697797de3f290481eba3ab1cd116efa09", "ref_doc_id": "9b3c8654-1be7-43bb-b1b6-a69cdfafe24d"}, "a7e0d2dc-c095-4e72-b26d-c9b4d7abf43b": {"doc_hash": "88a845271f44270f12dcf0d08eeea7124029d4a781f69897b7fdc3356eda550f", "ref_doc_id": "2f9dbfb7-a77a-4704-b997-c6d6ababc8e4"}, "1b89c9e5-8cd9-480e-b49e-a7171c91f4ab": {"doc_hash": "015ec61d8e95c937d756b19210cea1eb069534855c826436453569c0d05ef8c1", "ref_doc_id": "1ec3eed3-cbbd-4123-ab88-02a69dfe6b40"}, "2b0fea0d-63e0-4931-bba9-bfc3e5f73b22": {"doc_hash": "22425c8452bc3cd22ed648a61e6a7f1e8795c123484513fb325e1e0b0d107c82", "ref_doc_id": "7129473f-8679-4d1a-bdf2-9ce2450a28c7"}, "8edd0f1f-4431-4ea4-aeb6-2d114a5f098a": {"doc_hash": "4f49643d778f72696c62993802508aa585d127db5e8accce8fd4ca146ee81a5d", "ref_doc_id": "7a8caf13-deac-43b9-b6cf-59ae67e088fa"}, "a0734d7d-9b46-43ce-884a-5377f07af948": {"doc_hash": "73012f3bf927f9e1cb8893f2acafdaadca6dd5c83e550a755a2ae2b3517907a1", "ref_doc_id": "3124aaeb-ddb0-4e2f-aec9-a575c267029f"}, "e6bf13d4-8d19-44a2-ad6a-36e4f5aa3e0b": {"doc_hash": "02d8137d69c90035be45d6f031178beb1cba6bdfeb50fb61219978dfa4dbae6b", "ref_doc_id": "9ad1b552-06a1-4bcf-b641-c17c4995b3db"}, "649bbc92-dc02-40a6-aa85-aac0aef9de61": {"doc_hash": "92e4225d224d06fc1f42a5d8036c52fffbed36a1ce7ed623049bb22dd0f3dd82", "ref_doc_id": "93b01571-6a44-4819-96f7-d84f3de12661"}, "2630ac98-8b4a-4cf4-9752-f9296f4dad22": {"doc_hash": "b142fe561eaf701067db531ea8c5851e05a5b79bd37ffbd87b935cd648e78384", "ref_doc_id": "960b3455-de29-40f9-bec4-fe285ff0e3a8"}, "1b158531-5e1c-4084-b0bd-9c0046a5c9e8": {"doc_hash": "46be5b533d8b9e132e5634d5af2c5c4ca296be5416031205c4425eee0a697dab", "ref_doc_id": "cd9511fd-4575-4787-849b-d5114ca1238b"}, "24953547-4889-4cb7-8ab1-85f7cb1b9faf": {"doc_hash": "aca2a1cae11275df10defab2181e55d28479d2bd7b4d5c0c29f53ad0325c3f55", "ref_doc_id": "707e85d0-463c-4259-81b7-634665797bed"}, "4fe8a12d-74c8-42a5-9c77-c3bb49b30cd4": {"doc_hash": "59b18708ee5ca1656e281bef260e614af2e0968443633131805609db63dc54fc", "ref_doc_id": "7af93020-9572-4c3e-a9eb-524373653695"}, "e8e704d1-0ec2-45ed-bcb2-e2909ef7b71a": {"doc_hash": "9ac4597f512fb50deeeb5cb4d1f0c66af4b612cb2bee6585c9df50e9adf06cc0", "ref_doc_id": "7a201452-0449-4ee4-af26-a8050dac730a"}, "090b31c6-2494-484c-a962-ee006cc21ffb": {"doc_hash": "2feb4747e52ab33e454594e184104de6722b7be80c6f8c8e3dd31e7c072117c4", "ref_doc_id": "608e44ad-b3dc-4fd5-b28d-84231d51fe6a"}, "ed2479c3-543c-475a-9b60-a0f2874bdf9a": {"doc_hash": "9509aaf8d0fb165f7de9f369a3b906961c47c83f7e5918d0762aa2c395fdfe63", "ref_doc_id": "8c9287b8-2123-4df3-a65d-c0f08ec9bfea"}, "66e8f045-9da8-4b46-9274-894d73311c35": {"doc_hash": "7e1bf32a67fae1174bbe649805180e8b5d0a1ef8bfecfc66dabc5fae4f910d9c", "ref_doc_id": "e1dd6a7b-de97-4fc4-b189-82d3542fe82e"}, "e3a8a419-759f-4fb1-b7b2-583c11a7cd3c": {"doc_hash": "3fb9500ccc58c1aef4e2899b9d701b1d9009a3cafe4c249e2b09beff7b59fb1e", "ref_doc_id": "d3567dbe-48fa-486b-bdd7-9e8068e1394b"}, "c420230c-42e4-4ebc-ba2e-613da876a762": {"doc_hash": "35ee99f9ab3fdccb71ff1c89a3e19f1452ce4a8200312dcad4bd230f39562283", "ref_doc_id": "e2d4a939-df28-47d2-a0a9-19e5e75878e8"}, "e10f41c0-d908-4d5d-88e7-85a320b9b893": {"doc_hash": "782dc83165d4be3aafb2cb71eec6b045c62539e45c11d826b987f1b08b01b5e4", "ref_doc_id": "bba70202-ee19-4a9e-a90a-ce784c75e75f"}, "4c4e489c-de2c-4721-9b92-48206b8a92a4": {"doc_hash": "2b312adef1ffb3a2ae91f78c7d7cff915aca69acf3fc8c7cca428dda3c8894d5", "ref_doc_id": "bf8be6ab-1925-4318-bd95-8b59cc86e06d"}, "080e6c27-223d-4020-95f1-e426c23eb52e": {"doc_hash": "6a8d7a8b856dedea6733b3c73fdeadcec066d1fc08c8680992c4af5777c9a2ac", "ref_doc_id": "3f9ca9a4-f53e-4604-9a81-ca6f1170d8fd"}, "5dbe7476-03cd-4c71-91e5-3e74625ffbb2": {"doc_hash": "6ecf69bd738bec3e941fd2aee1d6c952f890f195cb05c0c670422f5d4cb308ca", "ref_doc_id": "30132288-07bb-430b-aab5-876ee7ec5820"}, "1c5f693d-0707-4c34-85b2-9c0cdb28ae98": {"doc_hash": "055468fce763611c627364e6d9c683da95dca6d67d49d09ec96835983f963e3b", "ref_doc_id": "0f84254f-7c00-4dad-aec8-286d2eb8b928"}, "fa0b5bdb-ed2f-40a2-b2f3-0bcdc38a28de": {"doc_hash": "ae40492e7b0df6b9817c165e647f4b62ce04b01658929757063dc99d99c12d9b", "ref_doc_id": "358dfe1f-2289-48c4-9700-dc9410f1f9e7"}, "1a7a29a4-3324-4a81-8b64-2f60bdc44dca": {"doc_hash": "6978dd3c50d66097b9d2e61497ca9ddaa69c904ac16c108400b5b29f8f65904a", "ref_doc_id": "be290469-6ccf-4772-822e-cdb73f85f798"}, "b6859c2a-1eb0-40ca-b2b4-6d4aa51adcc5": {"doc_hash": "93afb586b69c121b0c505d224dd1a45eaa76cacd30505f62e8da82501184b90f", "ref_doc_id": "9104a78a-b065-431e-aed9-dcc8d5c56ef6"}, "73f351ee-347f-4fe0-81dd-e29889cac465": {"doc_hash": "76c05465445d229cc51c6e5989b1c706a173627474fc44f2697dc16bbfb3af43", "ref_doc_id": "2494b4a7-6242-48d8-b648-ae0c0e761b08"}, "bd9f3cdc-c05b-4433-ab7f-4af5f9ea5d5d": {"doc_hash": "d9c6f2a66f9c81a15a331779444b2e6d75beccf73047ff74552d844b845b3d51", "ref_doc_id": "ddc539bb-70b5-4830-bb31-ddfaeee6bb00"}, "d76b5cc0-fc89-4323-a48b-b0cd49b7ae72": {"doc_hash": "4ed25ff0ccf0c55d2470e8e4dfb58465d0cb5c43afd0527c532a4e0b8ee13fd4", "ref_doc_id": "1e018e8d-7f33-45c8-a97f-0c270e86a69d"}, "3db29c44-d8fe-4791-864c-21d55ffdf44c": {"doc_hash": "e2d5b53c761b616c526e3c8a5f9fe1038c0865d6307cd63f4572685ad3810ff9", "ref_doc_id": "5b12ffcf-f432-462b-a81f-fede63e40862"}, "f3b8882e-8254-4d71-89fd-75062b41a559": {"doc_hash": "6c6d3055a13bd4b1fad864e533a65af2a098a7a6f87da1b40e5cc940078754d0", "ref_doc_id": "723eca7e-9228-4bd0-9f8d-6d9d40ba18f3"}, "631815f3-6f55-4ff3-a987-c7025719bd13": {"doc_hash": "9b6f43996108463a285df73e6151dc73e3d8476520649744aca877b4f82b4ecf", "ref_doc_id": "8b267e18-0194-4ebe-8f97-6ff008e0ab3d"}, "debff26c-0158-41e1-a3f2-c0e189690213": {"doc_hash": "f2eb6c33b9ee62c82a5893c6967724308ef29efe88bf5ac8cfcaae05bbb35972", "ref_doc_id": "de46e4c9-fbca-470d-bb91-19df4c033cac"}, "88370bfd-88a4-4ff9-94e7-6f69da65932b": {"doc_hash": "a9237f75efa4f442599bb9be2f65c4dfd027eb71c2cddf0cb1a5acb2b50e63a7", "ref_doc_id": "45d23f52-e91d-4ff2-b915-372bd68bd59a"}, "e0c48c32-d613-4722-b2b4-0808f821788e": {"doc_hash": "08021980bba05157049b6bfeeef738fb8508bc148b4e46734e51778031cd9b7d", "ref_doc_id": "9d8c91ec-64e7-429d-8d0f-c4285a280d7c"}, "ae104ce2-6e4a-4c55-ab7e-24a9d31e074e": {"doc_hash": "4ed1941ba865b834e936dc197c47cc497e7b98d2a59691f993724b258ea255a7", "ref_doc_id": "a6946c91-28e2-4802-a826-dd8d5f9a0bd5"}, "0ab177ab-0e2d-425f-93f1-b176a6854972": {"doc_hash": "3322cf44e1899fdcb3701126ac3f22802993b64bbd25e28825f5a9850fba9a3b", "ref_doc_id": "c32ea6cc-0e53-4775-ae62-fe94952e1e8c"}, "4a007407-e225-47bf-aba1-2d39c8722779": {"doc_hash": "227df784205210e92cce8772fc3fa8e31e87764f8cbb8444735c64ea74e12679", "ref_doc_id": "f3eec094-2c81-49b2-af38-1405c8711455"}, "e380fc18-9380-45d3-87e8-a6596a2dd173": {"doc_hash": "785e6fa35495e5176c99117a55a60ec83223de1a1ed1dc271fab6e19998b712f", "ref_doc_id": "a1f06841-cabd-4417-99d8-39e9af0c7946"}, "ee076983-e37e-4007-889b-4da07f01b33c": {"doc_hash": "1609141b1c2908100be6d95af1b7b5a18ad9f471c8866798313e59e3d2ee5acc", "ref_doc_id": "353282f2-6e8c-41db-ba7c-8d2a120d9a6c"}, "d7f5b0f3-f113-489c-8325-61d624761d96": {"doc_hash": "8324f4f434339db5adbc37a9610cfbb4323472f3c29ec03ab8c0e708099c3d33", "ref_doc_id": "81c46c2f-f5b8-488f-94b9-04c8b701e91f"}, "928f7407-bcb2-419c-a06e-2dd430273c12": {"doc_hash": "0b9484ec8dbaae1c5f467fe5cecf1262e989698dfe8357042cee468d741c40c5", "ref_doc_id": "4ba529ee-24ce-4d40-a383-4abe570a17fd"}, "1ab090f7-ad53-45ea-b23b-40e876d583cd": {"doc_hash": "193ed535f53fc5a88d165b441bd9010141e5458429f68cc59e4add3617e65ed3", "ref_doc_id": "92837e06-1311-4cba-be99-892076ce9e63"}, "f5619b14-2502-43d4-a51d-d9cbd49540f8": {"doc_hash": "325edece0813e4744b3bd129e298e5c0080aa443bb55e6387f1f781af67ef161", "ref_doc_id": "f26af394-5cc0-4b30-83f0-20505833574c"}, "976ececb-a1f9-42e8-aae4-3aec9990b821": {"doc_hash": "e1d3c5e117841eef7f2571c31094bddc089c12a6c1b1ed40d778cb6d71b73334", "ref_doc_id": "494f3bca-2271-4319-a456-0fdf6d8065ce"}, "cf14914a-fff7-412e-8393-809dc5fafc35": {"doc_hash": "ade34f021d7c5004b3ada25bfb677a313d41b9ebdd9b5e599133e0da01cf6427", "ref_doc_id": "d3520f5f-7631-46f0-9ef7-5b6c9d3345a9"}, "fe64ef1c-efba-4215-80d5-deb91c59771c": {"doc_hash": "d09b416f22b95970de5f685ea8b504239069064269eb0b7e9c96e3f4490b8d1e", "ref_doc_id": "cd075503-d9cf-4bb3-9481-09583649bff6"}, "2f882c53-92f7-48ac-85d6-b0995d56540b": {"doc_hash": "3e8da31cfa886b47364c8ec7a06779dfdc451852a3e71b6230a448ed740263d0", "ref_doc_id": "16bddd60-924b-49be-ac4e-47ed1ec16c5a"}, "78d46af4-260e-4f29-a892-ca71e980f634": {"doc_hash": "88e3088c324ebf15a19680f7f902bba6b5aa434288098f536ab11f8d59419192", "ref_doc_id": "5bb42c1b-8453-4511-a1ea-479edece2791"}, "1c179165-43e4-4912-a59e-60f74cecf229": {"doc_hash": "7f2f420dda4fa13cd34d663b325dd9bf933f94c4452c471958e23e33ee177469", "ref_doc_id": "2bfa2de4-ecc3-4695-ad6f-0263ed955b84"}, "04eb4a04-bd62-452e-8177-b224c82ecbf3": {"doc_hash": "e6471ccde72582bbd6ba0b8be025fccc8f42321bd508a2748e37b3ad46164e35", "ref_doc_id": "143dcd88-cbf4-4d68-87ce-219de80d9741"}, "a54640b2-1f16-4f9f-8242-35f2c617dbc9": {"doc_hash": "eb7394867921647c54747a2c71c1da17a9bd80614d6f56a52261c5db07f23fab", "ref_doc_id": "950e1797-d9e2-406c-a9fd-336c75ad5cd3"}, "99f31f3f-c413-44d0-a886-a4d2496e01b3": {"doc_hash": "a07956677524f6593d96dd9e855c943361d2753126d4f0d2e18fa041b75eb424", "ref_doc_id": "691ba04c-059c-41f0-bef2-857f44adf8d8"}, "ab692d28-8b81-4925-8edc-4f8b0de8d685": {"doc_hash": "17782143d18793dc1f1b583e6137aa6900e5580f2ad408b9217386b9e3cbdaca", "ref_doc_id": "4ce7e8f1-985a-40a3-8dd1-892821f504a1"}, "2d4163dd-dbba-4057-82eb-b34cfc879fa8": {"doc_hash": "c3a3ea628c9fbe044d88409d4d42eb6fc4c71664ce95c086a1942048cdb20269", "ref_doc_id": "e9bca7a9-04c5-47c2-8287-8b47847248b5"}, "67f7504a-949f-4f0f-b6bf-c26743aa5840": {"doc_hash": "05ad73d772d07352b086fa64a7e0a5ccbdc478b8512493c6402acc6bea671e24", "ref_doc_id": "a858d197-a34b-4921-ab04-b8065b850724"}, "74ab4b74-a611-472d-9cb6-4900cbde2238": {"doc_hash": "71e67c36dee0c9417969cfc23e370cc86f30d236b88cdfc4f45e5992c60208db", "ref_doc_id": "a4111851-778f-4692-895e-a133d155d37c"}, "60b90252-bf56-4632-8a14-93a4f5da636b": {"doc_hash": "4353aad51088ee1e58af797af747b7e0111e5920f52ee7379da17d7ae8f27d69", "ref_doc_id": "1967f30a-098b-4cdf-a0ae-4d54a8ac90c9"}, "159a5968-49b6-4e7c-a4ae-5787380c9568": {"doc_hash": "571eb2cab020b6fb48c38db518805ab4128b87dddeaf254979e9c0fafb5f06e6", "ref_doc_id": "852099c6-fea0-43d7-b14a-6e336894fcb8"}, "aa13aa1b-d84c-4f4f-ae84-7a3c5fe1da2b": {"doc_hash": "f762af0d26d6a10183619d3da749d2a809250ee012f26c3c575fe3d61720de79", "ref_doc_id": "4cef32fc-428c-47d9-ae3e-61e06e3d1729"}, "4fa0f180-fb53-4b27-a505-517d28e90be8": {"doc_hash": "0ade7d18676f4783d52ea03cbbecb7f7ec9012cc8f0227bd7c0404958d6dec13", "ref_doc_id": "11317e73-6fbd-46f3-a5fa-da02b1275f86"}, "bcd27c76-2798-4930-a81b-935decd072d9": {"doc_hash": "40a501bfd7c581d886482caa2c4eaa37d37053a32f12d852387530a8ee03172b", "ref_doc_id": "2d3fe42c-4570-48e8-b9b7-c5203dcc2e21"}, "94c7d40f-86d9-411c-b875-61b5889256b8": {"doc_hash": "27b335b38f0e72efade02808f527a65d8d8d9c0884f95a75db3edb9b78aff2f6", "ref_doc_id": "3f6a6434-e5ff-4f29-acc3-643a67dee185"}, "f5475c96-3faf-4689-8172-c7aaad81bb56": {"doc_hash": "f50284bf0ed110fdd0e31e1524dbdbf8799801e392e478014137d73573864e1a", "ref_doc_id": "7d9ee3fa-d4f9-4298-a82d-1ee5fdab5153"}, "e6371bc5-f3cb-4919-952f-f4c84a1e33b4": {"doc_hash": "6f09adecf1d4669e3e8e8b6a9d58f2d5de3b6f3524f377c3b34ebb3bf98fc53c", "ref_doc_id": "674d6cf1-f41e-4203-b758-047caa4c2fd6"}, "174feabd-3013-4cc3-a6ad-01c1144c5630": {"doc_hash": "d715b61caabb03e1c6e675bdd1aaaa616fa38e303199ada947f014c33011eac0", "ref_doc_id": "e0c0164e-9d5d-4999-b1f9-f60343af5a1e"}, "af78b862-d67c-4924-9dbf-2d0e8aa5c49a": {"doc_hash": "4dde1a904f83403590bcaf1f4b9a8059d04da9a687ffd06db32d49e5edc5f46a", "ref_doc_id": "5d9b0070-aa7e-46b1-bf9d-56e017d16512"}, "323febd0-76a1-4912-a1f3-f1c5584f168c": {"doc_hash": "eb39e8d8f7982d58921176ad6690bd82fc7d794cb4881faf92988da31653621d", "ref_doc_id": "a5a96faa-8bbf-47db-93c2-01d2e1bce5f3"}, "af435f87-179f-4c96-bd8d-952c3ec12b6f": {"doc_hash": "717afd54e5d69e68f48f78949c84855f6f7acd08e77f25d4598f2f0c038d8927", "ref_doc_id": "0bcaa809-efb2-4f19-a812-43f62fbcc4b6"}, "f930600d-145b-4d00-9ad7-410e427becd9": {"doc_hash": "3fff70d90390577dd8f8c27d4adb6b9c7b899f90fb900987775e6d554d1cd45d", "ref_doc_id": "014ec0a8-4bb1-46e6-a5ef-3381fd4030e6"}, "89ecb132-9ff1-4375-b187-c16d48599f6f": {"doc_hash": "5ce7ff15e01b38a9e133da7f4fa884242eccf9ba472fb1776b94f5f0311912e5", "ref_doc_id": "e1a2dac7-95cc-4a92-9de2-df35ab84b71b"}, "085549ec-de43-4a7e-a24b-31e80ba97577": {"doc_hash": "2b3dab428d33da6cfae4e51fc20ca4aa853c0b39d2053fa3f09415d6c93e0844", "ref_doc_id": "92b2b6cc-f932-4a78-8138-b0af129cdaae"}, "24bef584-e2e9-4e62-99ec-f3ef82a17555": {"doc_hash": "37739a1a742c98d04ebc01e8f368af05aeae1568b0acddd84dd4283ada705987", "ref_doc_id": "4e68365f-068c-471c-8fa6-07aeca9c570a"}, "2f062d25-af44-481e-9560-24681269fadc": {"doc_hash": "9b5e4abb9b9771c58f6ef778886249560d5382f8cf81aa182ebedb4db81825eb", "ref_doc_id": "6a06bdfb-3fe3-4b04-b4ec-9b1f1f2078ce"}, "1f05b534-502c-4805-a7c2-b229dc6888a1": {"doc_hash": "46b5b5c6146b59308d39cad42c6b8b6e6c92ae7d787d4441039c268d0760a9c2", "ref_doc_id": "848878d3-767e-4bd5-8f81-c6e24d94454b"}, "7eb01d40-6090-4f66-8428-c962e9b9e438": {"doc_hash": "d450bb019f95920c1148b5436ddad11e459f23b42c481c2d1fdeffb6035e8f82", "ref_doc_id": "d3a2303d-f8b7-4b94-a948-e8620f8df25e"}, "81f6823d-ffd1-4dd0-be23-269209cff20d": {"doc_hash": "b194558fb9feba080f527affead974b73a7eaa43abd4cac6c650599441bcdfeb", "ref_doc_id": "7b966e51-a0fb-4d86-b725-c295c01d8805"}, "b7b25335-3fac-43e5-932d-d2b3eddf3ffe": {"doc_hash": "eff0789d9ebe76728a637bf8eee57caa618710a4094ecb4c5d26a57b0c6e38d7", "ref_doc_id": "f649d7cb-da8e-4430-8f01-b07785cb5b59"}, "d4dbde06-721c-47e0-8351-ddde51925f92": {"doc_hash": "eaf75e866bb455d737b483c540eb6b0b16c152246b6049de6ae45201a8bff3d1", "ref_doc_id": "47ec847a-d874-422f-9290-5a75a11ead92"}, "bf8782af-c80f-4cff-8189-80e6df5d311a": {"doc_hash": "119cc25552d1fbff60c34cda25a5fbfbd8294b08c43e884d3b77871556bb8453", "ref_doc_id": "3cd1d469-0aa5-4360-921a-6e163e88ecd3"}, "b5349a12-718a-468e-aca0-40d4da55262b": {"doc_hash": "8843c50d5e35f4412fd79b1c67164ea87d488bd9005fdf849e121a17eea295fa", "ref_doc_id": "943b2ac0-1402-4f8d-bc3e-d097667f2c12"}, "ec2e131b-f548-4d2d-b377-57ccd972b590": {"doc_hash": "d2861fee150d199bc55712f045fbbd5c75226244bb907e66f1c702448e701221", "ref_doc_id": "0772d767-1d71-42e1-bd43-ec2a8be42c10"}, "26829735-c188-489e-8fdf-7611e06d40eb": {"doc_hash": "9a9c0287ae8ca35d0706e1d1f51d7567393a487b5fc30cd8573a95c24a48aab9", "ref_doc_id": "dbcf648e-d7e7-4d21-b83b-594b1bfc3f5c"}, "f3603433-f187-4fcf-a983-387e6ef35919": {"doc_hash": "4d715172a79fb456e4073dac0657370ca1a2f2962f557926166fbf58d3aeead5", "ref_doc_id": "343e85f1-500a-40b2-9d47-a2beacc38e58"}, "31423d9a-efa1-426f-a259-9720da5af2de": {"doc_hash": "2af8793f637f7fd63a5097a27420c1e3d5937c4a1ca95621cf69ce5fa3259a5c", "ref_doc_id": "c623fa36-2d98-4505-9e25-58df2db3a6ba"}, "c61dc562-96a2-4acc-8eca-054479699c8c": {"doc_hash": "7ff1b2212fbf12ebf9ea8e24e271d50294521a59604ef0091eea195772a01f5d", "ref_doc_id": "8da02310-cb83-45b9-a3d9-42cf63fe3d0b"}, "f0b8676e-eb5a-412d-9a4c-c91bec885880": {"doc_hash": "cb9f93f036503ff4653200009c6c972c32c0a3d22141a37cd9150deacf153325", "ref_doc_id": "37f6d1a1-eec4-46a4-9d61-a8377fe3e77e"}, "cccee87d-679a-42ed-aaef-4bb452468758": {"doc_hash": "fd5603611a7684ade274f2cf1106a7112f8fa086b0507e52fdcbe613334ae6c9", "ref_doc_id": "ae706473-fef6-4555-b941-b301c04bb3cf"}, "4141ad60-f6ee-4f8e-8fd9-52bbc307bbf7": {"doc_hash": "d38a8e8611c16c95bbce6c42bf12b4b696ba208e16942d40471c3bc992490612", "ref_doc_id": "1c735c43-6bf2-4679-a6ae-6c96dd34e388"}, "0479e479-642c-4587-ac7f-0af920a96e3e": {"doc_hash": "f4829244318c77cedd7fe7d6551529884b8a01c1fa6c32f6572c1789a92e61f0", "ref_doc_id": "c980619e-9217-49e1-8fe9-366ddc34bc5d"}, "5aded843-1d04-47ba-aef4-d6e94839f559": {"doc_hash": "dd98d51830fb9cccb28d5b149857c9991d69b5cd4b8632e0a39c17158e1e91b8", "ref_doc_id": "6ebac492-01b5-4265-9a44-e4f1fb18a19e"}, "ba5f0e82-8652-48c8-92b6-4e3a356c2e27": {"doc_hash": "0e275d9a7463dfef3d15689037014c06c4514d458dd887e81515174b7e0ba80f", "ref_doc_id": "152c7edd-f75a-40fe-a572-aae9a00deda7"}, "69cd4dae-7747-44d6-9f27-fe6f9c9c072e": {"doc_hash": "ea8cbe1ef6c3105dde9d7be7f484d55fbe5ab1b80112f4a145e353526e4f480a", "ref_doc_id": "440c1cdf-de46-459d-9473-49ddabfaac93"}, "de28a565-020b-493f-99e1-97070e50e70f": {"doc_hash": "81e35952e6d93036ea515e9fb7e7a82f9fd9d3bcb51ec730aa760c90801bb1a9", "ref_doc_id": "17e56c55-41f6-47b4-a1a8-6b954de62e61"}, "d03e0ecb-0433-40f7-b9ad-f5bdb564a731": {"doc_hash": "0712caf685c4a3c05ebe3c2f66faeee64590da014c2440a5d32c68eac71e0e87", "ref_doc_id": "eb32c2d7-3c92-4b4f-8b74-b9630fcfecce"}, "b7044f93-370f-4c57-a5e1-ce12ffaaca8f": {"doc_hash": "7634730957fa89b263528462982101c87bd454f28b8d31b21cf1d00f03ec2e0b", "ref_doc_id": "e6ed7066-287c-475c-b311-ef53fa8237fb"}, "9743d0dc-80e4-40a5-ab96-edde0a4bc09a": {"doc_hash": "d8a6e1ce76671e477c38eccc08d780b7355d506249d0c92cb2f01b7704f03434", "ref_doc_id": "1bb37ad9-bbac-4507-b8cc-db3520831e02"}, "dfc46287-0e58-4728-a84d-6ccc624edda5": {"doc_hash": "7641999d4666a835d5117d3fc3be92f5eaa8f86a0639ffe396b825e2da2b68c8", "ref_doc_id": "6efa7c17-ec93-4947-8bda-ff857bb1a138"}, "43757b94-79ff-4dd2-9c31-bd81e9059af8": {"doc_hash": "8a6e66a958622e2433fe9f9848991d60b879626baf8de2e265162e530ac9a6af", "ref_doc_id": "a057ce88-4814-48ba-8a36-e0ab1ef478c1"}, "1ebf39cc-38be-4d21-a657-16b7ceb5b364": {"doc_hash": "1fad4ccb55e76098b7ec76ac1ac60814c8db6b69406e35b2c3a88d592ab2a889", "ref_doc_id": "74b7fd9d-655a-4263-9710-0d52284273b6"}, "0a8dbd8a-c8e1-4d3c-abb8-6b20ab56b234": {"doc_hash": "d7404cc844d6257f61c520f79e8e6d377ec0cb7b107f1cdfda38f8ae4751912d", "ref_doc_id": "24646fbf-2a6e-492e-b019-5ed08b7f03b6"}, "6b3fd87d-63cd-4590-be2f-60cf7b58116d": {"doc_hash": "b099acfb38932ea3d69d14e058b0175ee00282c2fac5c0f3d47487079bd28ba9", "ref_doc_id": "a6e2c600-cd3a-47ad-8744-69a6e6185316"}, "d8ef6725-a6ef-4fb7-b692-c941e95bf3f4": {"doc_hash": "420432e12e5201c5604e1fec3258ff798208ba082779189f366f8f720bd3dff3", "ref_doc_id": "fe0b76b5-f71c-467a-8397-9a9b34d0f71a"}, "565787b4-713f-4dee-984e-e7bbf4176654": {"doc_hash": "84fa0d40ec89a2f746e9383a2ff900464174d6bba6b4bde0c49cef1b2b48e440", "ref_doc_id": "5258a212-690a-4c23-8440-7e008902d260"}, "8a7ddbad-e933-4020-88e2-6df80559d856": {"doc_hash": "42bebf229e0f64c65e1e4310e1eacf67d1934761cb86578efd2d3f9e514bf385", "ref_doc_id": "26761a96-e5a1-47ea-95a6-4373f37f48a1"}, "f323ee4e-084a-4c1c-9570-a76eec72dc6f": {"doc_hash": "c7b3da8acfc62c1cf3d2c88fec68821a1524e615f4a85874fd24d3fe6e4e604a", "ref_doc_id": "449bee29-05b6-4d00-ac43-bfc7df81cbc4"}, "0b62fff5-73de-463a-9365-e084ad09afe5": {"doc_hash": "3f48d53d908993657defc371cd01d65b79608d0a0df71ad90e53663432986f5f", "ref_doc_id": "9570b23a-0a7d-416f-85be-58fd624dd6f6"}, "17a065ce-af25-40d8-b3b5-1178a09eddb3": {"doc_hash": "ed4a9e8bd5ae7c69ab4a8615cb6841a439dde58b81ed6975215c652820f5644e", "ref_doc_id": "d1d7d505-320b-4596-a384-e0e1ccc66db7"}, "dd99c6e4-5759-4baa-8378-a9927d1f0d80": {"doc_hash": "f937f9001df088ed0ff0e2609dea121214845aa6d1b5aa91bc56344c1d394545", "ref_doc_id": "58de7747-74f4-4cc4-a446-fba876ddc04a"}, "ba66c8f2-b8d7-4a08-9e53-ff11ffab077c": {"doc_hash": "9950eeacc2f602a332475ea8c18e1f8eec22dd5a4d7d9a9f6cb86e041d00d410", "ref_doc_id": "485a1c3e-c2da-44f4-b9ec-ccd26efe7238"}, "a9039537-9d94-4dbc-bafc-8c694044db96": {"doc_hash": "5e071e95ff94fd25ae71fe4682d936f9beb7915b317d7c3cb0ea968685e62c9f", "ref_doc_id": "ed5996f2-250e-4290-9b86-c404faf8dccc"}, "d64d6fe8-1747-40b0-9801-951447f3a1a8": {"doc_hash": "5724c77d34c4348e52751e5450c5aba4a30d359e0b6df884aed99edfec5f3521", "ref_doc_id": "c797e5cf-5ca0-430c-9e3f-20eb20f77bc6"}, "1a5d213a-18d9-42be-a17c-74d921a27a27": {"doc_hash": "4711a9a1d8e5158dc2f20eb75f77204ea6b1588e60c449a78009377f10246fbd", "ref_doc_id": "ea525757-0554-4628-bc77-af600cf1060f"}, "ca1f1b7c-06aa-46a8-bc44-5cf72e9cb6ae": {"doc_hash": "9ce0d359d3000ed564ebaf124dfe86cc89c0b3e8ddf3fae37ac7be5c06018054", "ref_doc_id": "5b2a82d7-049d-4fe9-9e15-746007572c5c"}, "4f37191e-4501-4961-b72a-b961669f35c9": {"doc_hash": "36b1ef0d84df912bfdd221131854ea3b65490952a8ad83067369d55bec214a66", "ref_doc_id": "9e1c6472-477c-4ddd-b8c6-dd0cb4c479cf"}, "85c83eac-9df7-44aa-a7a1-9ad71871e3e3": {"doc_hash": "56f6f09b55041c3a8c5edfb2ed5fe4cfb7c18e1d386e6cae5d1545245b04df06", "ref_doc_id": "6204f493-5854-4ec8-8c9f-7220c13a9ee3"}, "c4136728-f4ba-465a-a72d-a2ba7c8aff7e": {"doc_hash": "2c0650d25a1452bdbd6dabbca4961f21e31146f6c0692764d0022c06c3488921", "ref_doc_id": "77075225-d6d6-4ce2-9107-9213391c2e3d"}, "a5d73010-2d71-4c0c-9e0b-f7419094280a": {"doc_hash": "60770d598f8e8c1d4744356403e3ff5e578376ff6c123a42ef30f62f577b68d3", "ref_doc_id": "f5742773-a6bc-43e0-940d-f1cc692c5e82"}, "1b269087-4255-4b34-bb34-5d371e01299c": {"doc_hash": "35ddbeea73d173ce1042ec99505aebc19bbd1d83fb7d07a44159059474fecb80", "ref_doc_id": "be0eaefc-bde6-4b96-875b-c032380a80d3"}, "d1ada68f-95d7-4b3e-b5ea-fc3efbfc1df4": {"doc_hash": "3cb09f7b6aa08fcda179da5d7829e4411f2c59bd759376ebd50247371f149117", "ref_doc_id": "1b341c41-8162-49b6-bb91-89080b046945"}, "6067c9fb-c9a6-4df4-8268-2dfb4c88763e": {"doc_hash": "afe02685c99953f979a7441cb3567ec77d109fc9984650747ec136de95bcc3ee", "ref_doc_id": "18dd8080-215e-4d38-8937-b297a5dabd88"}, "76fdfdf2-2125-4af5-a215-1c3dae2743fc": {"doc_hash": "93a2818d964e50c545f851750b9fbf902703fc93aebad89a52c8b0d4ff442c25", "ref_doc_id": "f97bd38b-afa2-4c1f-b2cd-d49ed72e0c56"}, "5531cc32-2957-4a35-867d-b5efc7fab502": {"doc_hash": "fdca3d7f345d4e1a67d17d785a656ea89bb63a7d796625061df9284f50fbc9bf", "ref_doc_id": "83d5360b-4c21-4330-88f3-c5ef9f35e0a0"}, "154bca11-700c-4ffc-ab70-67b0544d8682": {"doc_hash": "6e47de0cd84a0c1d8c26d564af678ffb4cfb1b23838032d2ffb1ecf2b429d228", "ref_doc_id": "4a090aff-483e-4bbc-a9d0-2f06057c4eec"}, "4fcf1194-00fa-4bbb-831d-1819f78cb4a6": {"doc_hash": "896c792b9ace740d673b9baa2fedfdfeb37434f4d1db188222c5a6f0c86c5a04", "ref_doc_id": "6ec7cbe1-c7e6-4a25-8505-1b335d39ede5"}, "47bcd8b2-dd97-4072-b697-1a96c68e5dc6": {"doc_hash": "470920718fda83901edda30b484be1c3db387e6bb108e88f8d6f3012b1d33c7b", "ref_doc_id": "375a6d45-5b96-4066-a609-92976da74def"}, "4963ebfd-de92-462d-9203-4c4a73794664": {"doc_hash": "6343717c8517639493067417d93898f4b2679b6d08284a7fb3b005a81d1336d0", "ref_doc_id": "1206487c-318d-4d86-a9cd-d6639a5dcae3"}, "79bd6d4e-fa9d-41a3-8bed-7061e2ac91e3": {"doc_hash": "ce4ab2e12e2462a8bc1e8c0280af108e313d2cf4fdd7f6132a3edce7bf7adc35", "ref_doc_id": "3aff15c2-2562-4613-b2e1-a29fd648478e"}, "40722910-fb12-43bd-86e6-3e719711c768": {"doc_hash": "20614885c76dd6482a01cfa66b613672f6a98d588f8bb2eaaca42b50b6c7fcee", "ref_doc_id": "276b72d1-6bb7-4aed-b700-142bd8735d56"}, "26d5a4fe-46c8-41ca-8da3-4a50a7a07c56": {"doc_hash": "64daaa96996ccb1fe13fb23b46f120a19ed6a34cb4ddf05df6eeea890de73f10", "ref_doc_id": "96d63c4e-0d89-46c8-a619-3418499348c9"}, "1cd596e0-ebd4-432b-9ca9-77f256e5f26d": {"doc_hash": "9d5199d6533af50be139c5bd089fdddc0dc7e0b1ec6c8f6282763b93719a2d1e", "ref_doc_id": "4d388dfe-1dfd-4445-b93b-e2a95a14d509"}, "a00020be-4c1f-4104-b86f-8186299ac107": {"doc_hash": "66a8337621cb68ab41ee708993ecbf35c5ec772195a7b142a025ba69af07d2d6", "ref_doc_id": "3c03b062-1584-4976-9197-1faf18348058"}, "30aa6e91-4e74-41c3-89e1-f8455a315724": {"doc_hash": "aa5870f18aa8d3f356585a42d383c3f7318c48821a3f67549a05c5d415d843b4", "ref_doc_id": "1a898361-f9d1-4490-9b85-8a00517d1782"}, "fe5984f7-142c-4c80-b2bf-3f5b3fbeb19a": {"doc_hash": "7f480475866d61d52fea547824f7e3a8c6ecca9e559eb4f0893821bc39cf082a", "ref_doc_id": "74d0cfd6-b76f-4d8e-970e-ef68500db9dc"}, "74bdef06-52b8-4dcf-9d55-444369bf721d": {"doc_hash": "2df59ea3100ddc62b08135dc0e4359bdc9d6390da71793b069a1c4be3cff4c91", "ref_doc_id": "4beae257-2931-4d2c-82fd-a0e1fb7c98e2"}, "c8257479-3ce0-458a-a54c-8afc2f26a054": {"doc_hash": "735f01372a6c3f4108e201d7e403d9deece8c4ba0ae50d89541456154c9e00ac", "ref_doc_id": "f6e0cf90-f622-4d21-9032-76d36547960b"}, "abd3507a-5e6e-4165-b85d-fe87c49cebd2": {"doc_hash": "46ad9bd339722cbfa77f0d423fe4f99594ed38170dc51a9b2a32882e46cd5d47", "ref_doc_id": "4935ca81-a397-4d14-adb2-222fd7176b32"}, "bfa5b301-04ec-462e-82e0-01d939d3f853": {"doc_hash": "9c26850cb1ff78a8d0b8bc29e59695cc7f2f36898ec1aafd1dc00910ab7de7e4", "ref_doc_id": "34891eee-e5d1-4275-8315-ade359a397c3"}, "dce1451d-2b18-4e98-b25a-509adb1e6ea1": {"doc_hash": "f9bd4a1ae78a56e975e34162801051a1d931162ed1be250b1a883be9258fc31a", "ref_doc_id": "4cebcabb-0c24-41f6-8a4c-ebede2fcb238"}, "50f5be85-cd2c-41c0-9a4c-62f739e1a42a": {"doc_hash": "282bf1a3059f3625b51e271baf5f19fd8091969b3e122f89c98881e8ecbbc733", "ref_doc_id": "ef54843c-ea66-4ddd-97f8-534fb50ac9d1"}, "90f42fcb-fd97-4c74-b83f-761787286af4": {"doc_hash": "5e7e39e37fb5405875ae6ebf6ced1992d0ebf517a9aab50959008e91641562a0", "ref_doc_id": "309bbfa1-ddc0-4501-9141-12672a740c34"}, "00724d84-2417-4fb1-b955-f3df9571f688": {"doc_hash": "c5d91483cb55427dde9333ea0650c5521f9608048ca785f6223e240ea330dab1", "ref_doc_id": "44d3029b-b91d-44e4-b396-d067e6490867"}, "8fb613ab-0561-4e66-be81-7b9aa95828d3": {"doc_hash": "5a7e0f41e9a94f9dd24bb35641daae1fa703ba11e413b4f69376e98e9889f60a", "ref_doc_id": "3bd14228-a814-406b-a2c4-0e2b1653bfa0"}, "6da64650-fd4c-4681-83ff-d0436ffbd743": {"doc_hash": "ac1c079416e43c043411efebc818af27fa9f89b01fe6ae97f631c9c84a071a3d", "ref_doc_id": "c6440385-41ca-4d63-a640-c6b60ef118a3"}, "81f0ef82-16e9-434e-913b-73e29492559f": {"doc_hash": "085d8773e600f78d7aa55eb3b86514a1f97c358b0b889b5fddf8e1f548edc657", "ref_doc_id": "abfa6591-e1b9-49ba-86ec-d4a7353de27b"}, "4b8178c4-cbae-4e99-914e-4907886dbb8b": {"doc_hash": "adeb1424857576190f188394f82817af4b082c90381fc5afdc2a13c4bd04637e", "ref_doc_id": "88ca3a9a-c571-45ca-a2a0-2c871e74d60e"}, "3514d3f3-796f-437f-9dc9-12cc2ba36dee": {"doc_hash": "b038fe5b0438502c2b88a32df642e3df9165fc40987253d9071b326be9af6be4", "ref_doc_id": "84e16337-50af-4ee1-85e3-7146a09029d8"}, "2e284ebd-2776-416c-89ca-8951eb39b17c": {"doc_hash": "b0a54dd5428f8f79486e0172322095b6ce125644ac30fc34b25705f91f194802", "ref_doc_id": "653a7c4b-8834-4b8c-b8d2-2dd60d663502"}, "553575ea-36a1-4ff3-9d92-5b37856de303": {"doc_hash": "693323cb5f9fadb1ec398cfff191962028dcab6a30fb7c3f0d9a6e3220623895", "ref_doc_id": "d6f8857a-1761-4121-b2ec-1860929989cc"}, "302e38ef-c217-43d3-8277-2f05409fd9c4": {"doc_hash": "4a3493ed1848e8eca17a6e3459b1862a356722dc6e9871c0e762e25f7160846e", "ref_doc_id": "563894cf-9067-4c75-9966-f4ac117449f7"}, "e7101447-b5e8-46c2-9b7c-37b6e86373f3": {"doc_hash": "c5514e1727a71c9bf0931ad200c1a9dbd59df1248bf8ac77959aadfde080c56a", "ref_doc_id": "35fdf474-c1b3-4c83-ba9f-bec0f96a7554"}, "bd4f1cf9-3c56-4fec-8c8c-6121854f1cca": {"doc_hash": "248ffcebbeb1915ca8fa6a7d70076d83ce506463ad4bfc3bd45e2c04bd30676f", "ref_doc_id": "0527a179-f47d-4bb3-85cb-a8e55b6ddea4"}, "80cc60f1-205c-4670-a69b-d9f6a496c998": {"doc_hash": "af0bdef841c7a9b9545d7b162fbf4fdb2d1eef1a940577e543e74047ff66a87b", "ref_doc_id": "ae74c5b0-989e-4543-afcc-edff35ab5525"}, "5b8d1807-d985-4e8c-8d4e-fff35735c56c": {"doc_hash": "fabd83fc00fb6071220e28c325cf5b3546f49fefebb066b87d9003db5f1ace7c", "ref_doc_id": "c3107673-6add-4e2b-abf0-79ecf797b6ba"}, "d2f69065-94d9-4249-a848-714dc82afc06": {"doc_hash": "c80f870f79c6ad1c0a392995956c407eb23b9b7ecc3b6a3fdf897af91937baaa", "ref_doc_id": "18dce106-3e5e-4262-8304-99a504a69248"}, "3560ea93-ec88-4e2c-975a-2130f019766d": {"doc_hash": "ad29688ebab93fd5490d80cc9fbdc926c0fc63124cd951d0940923630ddb14ea", "ref_doc_id": "9942236c-3fd4-4e84-b6db-ecf3dbe1db3c"}, "5ba21c4b-ae2f-4173-96a1-c7e9fab395c0": {"doc_hash": "58d76abb24fd83fd7387a7b7d22305103e3e23ebac4fa4849d0f2230422137b0", "ref_doc_id": "32270606-7c44-4d50-b287-0d70cc208afe"}, "5a29c815-5e81-41b3-882d-f0961150f993": {"doc_hash": "71aac01a3fac4d596cea5656dfdea06df513e284e03fddd09c39222379011c38", "ref_doc_id": "453fdf1c-db20-4a2c-bf71-822e09417986"}, "6b25d1ac-d7b4-44f1-bb5b-d7477c5d4f84": {"doc_hash": "629fb117cdd20446d459ad6ca78890482d6a135a6c9cec5ea5670648bf980e34", "ref_doc_id": "124fef4a-5350-4725-907a-d8d7b4ff6932"}, "b4e2b289-0531-4f3f-8d21-9ec4f0302343": {"doc_hash": "101d0eec19959bfe5fe573aa7018db84775e52ed9037556da28f1adb99e5bf4b", "ref_doc_id": "4eb8754f-2aba-4ab0-9765-bb7277f949a4"}, "62fe4755-42a9-45aa-b821-3b0b49f273b6": {"doc_hash": "ddc747c93c0cc65c1745352a98e6f8d75a97bac98be753f169438123441597bb", "ref_doc_id": "f2313df1-79a0-40c5-9819-8c2f7003456f"}, "ad6f5758-4f48-4473-af7d-c0efde3e8559": {"doc_hash": "7c4f5c079ab0f94f68fd19b73a63ce65c0350f05245e8b463da3ace3ad14ab3e", "ref_doc_id": "0a53e5ad-b647-446e-ad34-1deb0a7a6442"}, "e1fbd916-e652-4308-b1b0-674be967ae34": {"doc_hash": "cc884a3c7b30df7a00c20d00ee59f2e50093578971061dfd01db916a64db894f", "ref_doc_id": "ba338796-570e-4ad8-a295-c8bf1d7d3c21"}, "cd599e33-eb64-4538-a89b-62a95610cc0f": {"doc_hash": "5a383fa3e9a702870d60381e9df499f345a3864dbf0b94cd1b4a4b2544da84b6", "ref_doc_id": "949af885-3af7-4e96-8f8a-6ce50b9ff03c"}, "b707e542-6dd8-4f6c-910c-d91f93b5d0a0": {"doc_hash": "1b6c7ca6df6dd759420aa56158a6a1e4fc8ce02e368696c37482aa54bbe8bdc7", "ref_doc_id": "133c1fa9-d6d2-4a31-8a6c-bd35e63b0acf"}, "58cb32d4-a18c-433f-aea5-94464ecf3d1d": {"doc_hash": "d91a3a72510ac520665585340dac7ed3181f9a417bc239c5f37c8f9b5f21db27", "ref_doc_id": "bbfbd202-71d6-4988-bcf6-454a96b8552a"}, "fb6f596b-8601-4b3b-8006-76a10f19424a": {"doc_hash": "78ab9ac307b16aecc992a3f4a9e430fc418f64e8c27796f3020a52c89a2524cc", "ref_doc_id": "8e7a0086-b83f-478a-b717-b2835be58071"}, "b1001afd-20c5-440f-bb36-7ff94cb5339e": {"doc_hash": "bcc456d3567c19acf0b9462d093c1509552ed2826e2dfa20856fa7f5eb4884af", "ref_doc_id": "228fd0bd-68c2-40be-bba0-8187b36ac2d8"}, "f3dac615-d68b-40bd-880f-479c6a91367d": {"doc_hash": "4d52f8d7f95fe6fd77e98c22e3d93d71d092e134948ece119e53560751a9dcab", "ref_doc_id": "733c6af7-9920-4e06-9d17-bdae1ea700ef"}, "c2ae2556-d60d-4611-bade-a4f09ee4ec1a": {"doc_hash": "f6642e0779ca584f3246c6ea4ffbf43676328848f7427b4b82e4a2d472172e41", "ref_doc_id": "d4226151-ccac-4430-92ec-d1353b10f961"}, "18c26386-daf8-4470-b964-c879a4afb034": {"doc_hash": "e90d91c385b3d74a3b23b06e5cd66f635d585029cddd75ea1301ec53d1ab89ac", "ref_doc_id": "687a0f25-daf1-4a99-95da-bb9cefab34ee"}, "887c4a6f-d76d-49db-a234-c0877a87bfd8": {"doc_hash": "463d7bf8b0091f1840979a3b134bdbce4e5cb371777eb32c5172fde979cce5ab", "ref_doc_id": "ec92cdee-f64f-4881-baac-03c7f83a856b"}, "bccd66e7-31be-4e29-9730-028d07dfe988": {"doc_hash": "72052baf0c2df557443f789a370e5c866ae3f8dce147d78742aa902e810a4036", "ref_doc_id": "3d85146d-db46-4b7b-9502-29fad17afd22"}, "e874627c-855e-42d7-af75-8bf33146e88e": {"doc_hash": "b6feda3fb258ecbea533978ebb6e7fe858344f7a0ae6a2b4527270502d2336b5", "ref_doc_id": "795d23c5-75e9-43e8-88cb-bceeae772581"}, "e1394980-daac-4429-8188-a37c0bbb2651": {"doc_hash": "82e00e52dad26643ed5a900dab340a9213ce44df25c95a16635b6c5246969b83", "ref_doc_id": "a6f5d9be-66b8-45e1-9e7a-e2ffcc32b444"}, "48cc582d-b4e1-4b18-a9ea-811789602309": {"doc_hash": "613d0f8ec60d78af8af2eeaff043911b1e5e7e6f7c8516ac7378cf6d6dff6e07", "ref_doc_id": "50f1a77d-2e40-41d9-8ca7-a8e97bd07d99"}, "1a2e2e9a-4ac1-4fe3-9bba-b9e0a0e1aaac": {"doc_hash": "e755a12ef734a3ada2c289b664e02f671d8408504ec9b9e64a169618797267b0", "ref_doc_id": "a6a3de2d-4e6a-4453-9a55-0168b24bd5a5"}, "521524fd-282d-4c20-ba6f-6a8ba8aca209": {"doc_hash": "b4dcfb2e2a4c26371d93df4d657a665f91fa80d712c08e1654aeb80c2c36f504", "ref_doc_id": "8f1f6ad8-8a20-4841-9509-a71bce32c69b"}, "acfba396-1b31-46b0-9c1a-7e194b122d6a": {"doc_hash": "87563f1aafeeab034f70221ea9b7f75fefc360f365f75618a849b9da4ce2086d", "ref_doc_id": "1d1fe977-cf56-4c87-a133-7aa37b9b634f"}, "402e400b-bdd5-4d53-9ab7-66faced28f78": {"doc_hash": "f05c9b765a8a278f187b629176d2889f9aabbb2c7961395515eced801cfae689", "ref_doc_id": "c882a693-aed9-4ef3-b57d-2fc07270bb57"}, "895f7caa-7ba5-47db-8ddf-88da25ce1d10": {"doc_hash": "e7bc34399879f95a32e09572637387c114224050ef4897c774be29d57a5b6b95", "ref_doc_id": "f84a97ca-9388-490e-9c4e-ef6046b8231f"}, "58a41b1f-3320-4d20-9988-d849ea4208f3": {"doc_hash": "2e1f79f98fe68df057d1f56432aaf0efa0c5b82660db683f999d76a76ed256eb", "ref_doc_id": "c5014c6b-ec97-492d-b74c-fd25db85d719"}, "c5014c6b-ec97-492d-b74c-fd25db85d719": {"doc_hash": "23e286bc8a5e45c129dfa6c2d7b48f055baaa25fd4e844b17a3bd9dd5b073c4e"}}, "docstore/data": {"01c05495-adfd-4316-b2ce-21e05a24f70b": {"__data__": {"id_": "01c05495-adfd-4316-b2ce-21e05a24f70b", "embedding": null, "metadata": {"page_label": "1", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3213ff5c-8c24-4f2d-a974-af52bc835c43", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "846fd4f408c6cf1f6102e2b410bd20643360c6a9c2926f43b56eb82a257da2b9", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing \nGenerative AI on \nVertex AI using \nMLOps\nAuthors: Anant Nawalgaria,  \nGabriela Hernandez Larios, Elia Secchi,  \nMike Styer, Christos Aniftos  \nand Onofrio Petragallo", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 183, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8aeafac7-9e2c-464a-b214-9ba2ae36fd80": {"__data__": {"id_": "8aeafac7-9e2c-464a-b214-9ba2ae36fd80", "embedding": null, "metadata": {"page_label": "2", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b700f50c-1139-45c9-8927-43c5dc436c2c", "node_type": "4", "metadata": {"page_label": "2", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e78a6d6724d6126a217f552549ea47b591850804d295eae526d35e0360125da1", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n2\nSeptember 2024\nAcknowledgements\nReviewers and Contributors\nNenshad Bardoliwalla\nWarren Barkley\nMikhail Chrestkha\nChase Lyall\nLakshmanan Sethu\nErwan Menard\nCurators and Editors\nAntonio Gulli\nAnant Nawalgaria\nGrace Mollison \nTechnical Writer\nJoey Haymaker\nDesigner\nMichael Lanning", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1ebe3d61-3d0b-4cc1-94ea-993080934e8a": {"__data__": {"id_": "1ebe3d61-3d0b-4cc1-94ea-993080934e8a", "embedding": null, "metadata": {"page_label": "3", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5f87f6aa-d840-4b07-94cb-b6450e13782f", "node_type": "4", "metadata": {"page_label": "3", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2b59e6f23a361bde605d57609a68ff3eaa4b271aadaa8047bd01b24ce56d5953", "class_name": "RelatedNodeInfo"}}, "text": "Introduction 5\n What are DevOps and MLOps? 6\n Lifecycle of a gen AI system 7\nDiscover 9\nDevelop and experiment 10\n The foundational model paradigm 11\n The core component of LLM Systems: A prompted model component 13\n Chain & Augment 16\n Tuning & training 20\n Data Practices 23\n Evaluate 27\nDeploy 30\n Deployment of gen AI systems 31\n  Version control 31\n  Continuous integration of gen AI systems 32\n  Continuous delivery of gen AI systems 33\n Deployment of foundation models 34\n  Infrastructure validation 34\nTable of contents", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 527, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b59825bd-b723-41e7-8537-7781a9e15391": {"__data__": {"id_": "b59825bd-b723-41e7-8537-7781a9e15391", "embedding": null, "metadata": {"page_label": "4", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142f0ade-146a-4229-a099-b6a9f0adc1bc", "node_type": "4", "metadata": {"page_label": "4", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "a6118eaaa16834a8add41db56350edf5989cd89a9e97991895d46846e18913a6", "class_name": "RelatedNodeInfo"}}, "text": "Compression and optimization 35\n  Deployment, packaging, and serving checklist 36\n Logging and monitoring 37\n Govern 41\nThe role of an AI platform for gen AI operations 42\n Key components of Vertex AI for gen AI 43\n Discover: Vertex Model Garden 44\n Prototype: Vertex AI Studio & Notebooks 47\n Customize: Vertex AI training & tuning  48\n  Train  49\n  Tune  49\n  Orchestrate 51\n Chain & Augment: Vertex AI Grounding, Extensions, and RAG building blocks 52\n Evaluate: Vertex AI Experiments, Tensorboard, & evaluation pipelines 55\n  Experiment 56\n  Evaluation 57\n Predict: Vertex AI endpoints & monitoring 57\n Govern: Vertex AI Feature Store, Model Registry, and Dataplex 59\nConclusion 61\nEndnotes 63", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 699, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1fa93bab-ff3d-4a36-a4e7-9675a2d0aefb": {"__data__": {"id_": "1fa93bab-ff3d-4a36-a4e7-9675a2d0aefb", "embedding": null, "metadata": {"page_label": "5", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "03607783-5262-489c-a800-9624e7bfa7d4", "node_type": "4", "metadata": {"page_label": "5", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "9fe71e79dcec919831119857de0db7e2788ee1fb4f1de61727db7047ee2dcd46", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n5\nSeptember 2024\nIntroduction\nThe emergence of foundation models and generative AI (gen AI) has introduced a new era \nfor building AI systems. Selecting the right model from a diverse range of architectures \nand sizes, curating data, engineering optimal prompts, tuning models for specific tasks, \ngrounding model outputs in real-world data, optimizing hardware - these are just a few of the \nnovel challenges that large models introduce.  \nThis whitepaper delves into the fundamental tenets of MLOps and the necessary adaptations \nrequired for the domain of gen AI and Foundation Models. We also examine the diverse range \nof Vertex AI products, specifically tailored to address the unique demands of foundation \nmodels and gen AI-based applications. Through this exploration we uncover how Vertex AI, \nwith its solid foundations of AI infrastructure and MLOps tools, expands its capabilities to \nprovide a comprehensive MLOps platform for gen AI.\nEmergence of foundation models \nand generative AI (gen AI) has \nintroduced a new era for building \nAI systems.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1116, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5c66ea5a-c497-4946-b957-5aed34ab4531": {"__data__": {"id_": "5c66ea5a-c497-4946-b957-5aed34ab4531", "embedding": null, "metadata": {"page_label": "6", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ba3d7135-07f0-40b4-bb99-52fbc3688d3b", "node_type": "4", "metadata": {"page_label": "6", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "a7f8fb9f7c460f08fbbcbeeef6e5f1b171bd02431a8c22352cc507d65c92807f", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n6\nSeptember 2024\nWhat are DevOps and MLOps?\nDevOps is a software engineering methodology that aims to bridge the gap between \ndevelopment (Dev) and operations (Ops). It promotes collaboration, automation, and \ncontinuous improvement to streamline the software development lifecycle, introducing \npractices such as continuous integration and continuous delivery. \nMLOps builds upon DevOps principles to address the unique challenges of operationalizing \nMachine Learning systems rapidly and reliably. In particular, MLOps tackles the experimental \nnature of ML through practices like:\n\u2022 Data validation: Ensuring the quality and integrity of training data.\n\u2022 Model evaluation: Rigorously assessing model performance with appropriate metrics.\n\u2022 Model monitoring: Tracking model behavior in production to detect and mitigate drift.\n\u2022 Tracking & reproducibility: Maintaining meticulous records for experiment tracking and \nresult reproduction.\nFigure 1. Machine learning workflow", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1032, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b989c3da-91f1-47a6-97cd-3d4a75903f75": {"__data__": {"id_": "b989c3da-91f1-47a6-97cd-3d4a75903f75", "embedding": null, "metadata": {"page_label": "7", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "908a4100-2a8c-49e2-bb19-04716070d338", "node_type": "4", "metadata": {"page_label": "7", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "f2307130c740b37f168a019d6bbe8720e05b74e9e259e621c39c2476bebbbe70", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n7\nSeptember 2024\nLifecycle of a gen AI system\nImagine deploying your first chatbot after months of dedicated work, and it's now interacting \nwith users and answering questions. Behind this seemingly simple interaction lies the \ncomplex and fascinating life cycle of a gen AI System, which can be broken down into five \nkey moments.\nFirst in the discovery phase, developers and AI engineers must navigate the expanding \nlandscape of available models to identify the most suitable one for their specific gen AI \napplication. They must consider each model's strengths, weaknesses, and costs to make an \ninformed decision.\nNext, development and experimentation become paramount, with prompt engineering \nplaying a crucial role in crafting and refining input prompts to elicit desired outputs based on \nan understanding of the model's intricacies. Few-shot learning, where examples are provided, \ncan further guide model behavior, while additional customization may involve parameter-\nefficient fine-tuning (PEFT). Most gen AI systems also involve model chaining, which refers to \norchestrating calls to multiple models in a specific sequence to create a workflow.\nData engineering practices have a critical role across all development stages, with factual \ngrounding (ensuring the model's outputs are based on accurate, up-to-date information) and \nrecent data from internal and enterprise systems being essential for reliable outputs. Tuning \ndata is often needed to adapt models to specific tasks, styles, or to rectify persistent errors.\nDeployment needs to manage many new artifacts in the deployment process, including \nprompt templates, chain definitions, embedding models, retrieval data stores, and fine-tuned \nmodel adapters among others. These artifacts each have unique governance requirements, \nnecessitating careful management throughout development and deployment. Gen AI system \ndeployment also needs to account for the technical capabilities of the target infrastructure, \nensuring that system hardware requirements are fulfilled.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2099, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c49e5693-d851-4cb3-8d57-bd85dec7f0a2": {"__data__": {"id_": "c49e5693-d851-4cb3-8d57-bd85dec7f0a2", "embedding": null, "metadata": {"page_label": "8", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "74eb1c3d-ca2f-403f-9165-ba146f98147a", "node_type": "4", "metadata": {"page_label": "8", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "8135a0dcada4badec4b5e426c8d43ec443514622c07c3b6907de96b3410c1f28", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n8\nSeptember 2024\nContinuous monitoring in production ensures improved application performance and \nmaintains safety standards through responsible AI techniques, such as ensuring fairness, \ntransparency, and accountability in the model's outputs.\nContinuous Improvement  as a concept is still key for Gen AI-based applications, though \nwith a twist. For most Gen AI applications, instead of training models from scratch, we\u2019re \ntaking foundation models (FMs) and then adapting them to our specific use case. This means \nconstantly tweaking these FMs through prompting techniques, swapping them out for newer \nversions, or even combining multiple models for enhanced performance, cost efficiency, or \nreduced latency. Traditional continuous training still holds relevance for scenarios when \nrecurrent fine-tuning or incorporating human feedback loops are still needed.\nNaturally, this lifecycle assumes that the foundational model powering the gen AI system is \nalready operationalized. It's important to recognize that not all organizations will be directly \ninvolved in this part of the process. In particular, the operationalization of foundational \nmodels is a specialized set of tasks that is typically only relevant for a select few companies \nwith the necessary resources and expertise.\nBecause of that, this whitepaper will focus on practices required to operationalize gen AI \napplications using and adapting existing foundation models, referring to other whitepapers in \nthe book should you want to deepdive into how foundational models are operationalized. \nThis includes active areas of research such as model pre-training, alignment (ensuring the \nmodel's outputs align with the desired goals and values), evaluation or serving.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1797, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73439f44-5cc3-4938-bca5-f226ef367283": {"__data__": {"id_": "73439f44-5cc3-4938-bca5-f226ef367283", "embedding": null, "metadata": {"page_label": "9", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0afe5736-70b7-40e4-ae41-8c8d549d826c", "node_type": "4", "metadata": {"page_label": "9", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6329092bdda9089b6efd61811227a88db95e79b60e2a61f2a742a3bda8203820", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n9\nSeptember 2024\nFigure 2. Lifecycle of a Foundational Model & gen AI system and relative operationalization practices \nDiscover\nAs mentioned before, building foundational models from scratch is resource-intensive. \nTraining costs and data requirements are substantial, pushing most practitioners towards \nadapting existing foundation models through techniques like fine-tuning and prompt \nengineering. This shift highlights a crucial need: efficiently discovering the optimal foundation \nmodel for a given use case.\nThese two characteristics of the gen AI landscape make model discovery an essential \nMLOps practice:\n1. An abundance of models: The past year has witnessed an explosion of open-source \nand proprietary foundation models. Navigating this complex landscape, each with varying \narchitectures, sizes, training datasets, and licenses, requires a systematic approach to \nidentify suitable candidates for further evaluation.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 990, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "664e8cbe-9ef3-4309-86ad-6935567a1b60": {"__data__": {"id_": "664e8cbe-9ef3-4309-86ad-6935567a1b60", "embedding": null, "metadata": {"page_label": "10", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d73def69-ba4d-4e9e-b401-b11be4b82416", "node_type": "4", "metadata": {"page_label": "10", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "39f6f8ee4d7fb6a3da1f0782f9db6493d1fa84f47ca911e07db81b869102808d", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n10\nSeptember 2024\n2. No one-size-fits-all solution: Each use case presents unique requirements, demanding a \nnuanced analysis of available models across multiple dimensions.\nHere are some factors to consider when exploring models:\n1. Quality: Early assessments can involve running test prompts or analyzing public \nbenchmarks and metrics to gauge output quality.\n2. Latency & throughput: These factors directly impact user experience. A chatbot \ndemands lower latency than batch-processed summarization tasks.\n3. Development & maintenance time: Consider the time investment for both initial \ndevelopment and ongoing maintenance. Managed models often require less effort than \nself-deployed open-source alternatives.\n4. Usage cost: Factor in infrastructure and consumption costs associated with using the \nchosen model.\n5. Compliance: Assess the model's ability to adhere to relevant regulations and \nlicensing terms.\nBecause the activity of discovery has become so important for gen AI systems, many model \ndiscoverability platforms were created to support this need. An example of that is Vertex \nModel Garden,1 which is explored later in this whitepaper.\nDevelop and experiment\nThe process of development and experimentation remains iterative and orchestrated \nwhile building gen AI applications. Each experimental iteration involves a tripartite \ninterplay between data refinement, foundation model(s) selection and adaptation, and", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1491, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ae4b564a-d66f-44db-b04c-a328009cd3d5": {"__data__": {"id_": "ae4b564a-d66f-44db-b04c-a328009cd3d5", "embedding": null, "metadata": {"page_label": "11", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "255b6a1f-6214-44d0-b8c3-143a79e6d69f", "node_type": "4", "metadata": {"page_label": "11", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "a49244b9c44457a7f11f4a9fd39801ede8a4362474f83d013fc28019832c4c55", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n11\nSeptember 2024\nrigorous evaluation. Evaluation provides crucial feedback, guiding subsequent iterations \nin a continuous feedback loop. Subpar performance might call for gathering more data, \naugmenting data, or further curating the data. Similarly, the adaptation of the foundation \nmodel itself might need tweaking - optimizing prompts, applying fine-tuning techniques, or \neven swapping it out for a different one altogether. This iterative refinement cycle, driven by \nevaluation insights, is just as critical for optimizing gen AI applications as it\u2019s always been for \ntraditional machine learning.\nThe foundational model paradigm\nFoundation models differ from predictive models most importantly because they are multi-\npurpose models. Instead of being trained for a single purpose, on data specific to that \ntask, foundation models are trained on broad datasets, and therefore can be applied to \nmany different use cases. This distinction brings with it several more important differences \nbetween foundation models and predictive models.\nFoundation models also exhibit what are known as \u2018emergent properties\u2019,2 capabilities that \nemerge in response to specific input without additional training. Predictive models are \nonly able to perform the single function they were trained for; a traditional French-English \ntranslation model, for instance, cannot also solve math problems.\nFoundation models are also highly sensitive to changes in their input. The output of the \nmodel and the task it performs are strongly affected, indeed determined, by the input to the \nmodel. A foundation model can be made to perform translation, generation, or classification \ntasks simply by changing the input. Even insignificant changes to the input can affect its \nability to correctly perform that task.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1854, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0fa1efec-9424-4847-ad18-ad8fa899aa29": {"__data__": {"id_": "0fa1efec-9424-4847-ad18-ad8fa899aa29", "embedding": null, "metadata": {"page_label": "12", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f202208-b3c5-4af0-a1f6-9de0c4eca794", "node_type": "4", "metadata": {"page_label": "12", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2060f1ac52de6d08aea34524f3d4d5b2dd06025eff6eee8457b30e57d148e3c4", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n12\nSeptember 2024\nThese new properties of foundation models have created a corresponding paradigm shift \nin the practices required to develop and operationalize Gen AI systems. While models in \nthe predictive AI context are self-sufficient and task-specific, gen AI models are multi-\npurpose and need an additional element beyond the user input to function as part of a \ngen AI Application: a prompt, and more specifically, a prompt template, defined as a set of \ninstructions and examples along with placeholders to accommodate user input. A prompt \ntemplate, along with dynamic data such as user input, can be combined to create a complete \nprompt, the text that is passed as input to the foundation model.\nFigure 3.  How Prompt Template and User input can be combined to create a prompt", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 846, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03e97897-da03-48a4-8794-a80f3bacb5a1": {"__data__": {"id_": "03e97897-da03-48a4-8794-a80f3bacb5a1", "embedding": null, "metadata": {"page_label": "13", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "516c00dc-8f35-43fd-a713-a4062b3e69d4", "node_type": "4", "metadata": {"page_label": "13", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "f53c30a64bbe42a7c4112d24d8cffc11b84a18f4ad762d33f8ffed5b4e4274d0", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n13\nSeptember 2024\nThe core component of LLM Systems: A prompted \nmodel component\nThe presence of the prompt element is a distinguishing feature of gen AI applications. \nNeither the model nor the prompt is sufficient for the generation of content; gen AI needs the \ncombination of both. We refer to the combination as a \u2018prompted model component\u2019. This \nis the smallest independent component sufficient to create an LLM application. The prompt \ndoes not need to be very complicated. It can be a simple instruction, such as \u201ctranslate \nthe following sentence from English to French\u201c, followed by the sentence to be translated. \nWithout that preliminary instruction, though, a foundation model would not perform the \ndesired translation task. So a prompt, even just a basic instruction, is necessary along with \nthe input to get the foundation model to do the task required by the application.\nFigure 4.  Predictive AI unit compared with the gen AI unit\nThis introduces an important distinction when it comes to MLOps practices for gen AI. In \nthe development of a gen AI System, experimentation and iteration need to be done in the \ncontext of a prompted model component, the combination of a model and a prompt. The Gen", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1275, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08e0947b-5fcb-4ab5-ae52-d302872f43ec": {"__data__": {"id_": "08e0947b-5fcb-4ab5-ae52-d302872f43ec", "embedding": null, "metadata": {"page_label": "14", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b015510a-98a0-44ad-a087-2dec8ab133b3", "node_type": "4", "metadata": {"page_label": "14", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "5ca21dcefcfb6c4a468bb582646de31cbee7dc7b60fd6778960d9bfbff42f21b", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n14\nSeptember 2024\nAI experimentation cycle typically begins with testing variations of the prompt \u2013 changing the \nwording of the instructions, providing additional context, or including relevant examples, etc., \nand evaluating the impact of those changes. This practice is commonly referred to as prompt \nengineering. \nPrompt engineering involves two iterative steps:\n1. Prompting: Crafting and refining prompts to elicit desired behaviors from a foundational \nmodel for a specific use case.\n2. Evaluation: Assessing the model's outputs, ideally programmatically, to gauge its \nunderstanding and success in fulfilling the prompt's instructions.\nFigure 5.  The activity of prompt engineering\nResults of an evaluation can be optionally registered as part of an experiment, to allow for \nresult tracking. Since the prompt itself is a core element of the prompt engineering process, \nit becomes a first class citizen within the artifacts part of the experiment. \nHowever, we need to identify which type of artifacts they are. In the good old days of \nPredictive AI, we had clear lines - data was one thing, pipelines and code another. But with \nthe \u201cPrompt\u201d paradigm in gen AI, those lines get blurry. Think about it: prompts can include \nanything from context, instructions, examples, guardrails to actual internal or external data \npulled from somewhere else. So, are prompts data? Are they code?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1451, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f6eb5175-cfc3-458a-a5a2-e2e2a50b4cb8": {"__data__": {"id_": "f6eb5175-cfc3-458a-a5a2-e2e2a50b4cb8", "embedding": null, "metadata": {"page_label": "15", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac659523-7346-40d2-9bd0-b1f1af71134e", "node_type": "4", "metadata": {"page_label": "15", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "067a1143fa97965fa3e84828be53c1d129c7625d3549a172b55e37258cd8a532", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n15\nSeptember 2024\nTo address these questions, a hybrid approach is needed, recognizing that a prompt has \ndifferent components and requires different management strategies. Let\u2019s break it down:\nPrompt as Data: Some parts of the prompt will act just like data. Elements like few-shot \nexamples, knowledge bases, and user queries are essentially data points. For these \ncomponents, we need data-centric MLOps practices such as data validation, drift detection, \nand lifecycle management.\nPrompt as Code: Other components such as context, prompt templates, guardrails are mode \ncode-like. They define the structure and rules of the prompt itself. Here, we need code-\ncentric practices such as approval processes, code versioning, and testing.\nAs a result, when applying MLOps practices to gen AI, it becomes important to have in place \nprocesses that give developers easy storage, retrieval, tracking, and modification of prompts. \nThis allows for fast iteration and principled experimentation. Often one version of a prompt \nwill work well with a specific version of the model and less well with a different version. In \ntracking the results of an experiment, both the prompt and its components version, and the \nmodel version must be recorded and stored along with metrics and output data produced by \nthe prompted model.\nThe fact that development and experimentation in gen AI requires working with the prompt \nand the model together introduces changes in some of the common MLOps practices, \ncompared to the predictive AI case in which experimentation is done by changing the model \nalone. Specifically, several of the MLOps practices need to be expanded to consider the \nprompted model component together as a unit. This includes practices like evaluation, \nexperiment tracking, model adaptation and deployment, and artifact management, \nwhich will be discussed below in this whitepaper.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1946, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "58038040-1eb2-4cb6-990b-75a418d07783": {"__data__": {"id_": "58038040-1eb2-4cb6-990b-75a418d07783", "embedding": null, "metadata": {"page_label": "16", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e07d6102-a855-434c-a27a-fa6351667458", "node_type": "4", "metadata": {"page_label": "16", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "150a835ce3ac1ff2b5899a889977e186540a7fa64433f147e1b1a6f7b9cd3304", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n16\nSeptember 2024\nChain & Augment\nGen AI models, particularly large language models (LLMs), face inherent challenges in \nmaintaining recency and avoiding hallucinations. Encoding new information into LLMs \nrequires expensive and data-intensive pre-training, posing a significant hurdle. Additionally, \nLLMs might be unable to solve complex challenges, especially when step-by-step reasoning \nis required. Depending on the use case, leveraging only one prompted model to perform \na particular generation might not be sufficient. To solve this issue, leveraging a divide and \nconquer approach, several prompted models can be connected together, along with calls \nto external APIs and logic expressed as code. A sequence of prompted model components \nconnected together in this way is commonly known as a chain. \nFigure 6.  Components of a chain and relative development process", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 932, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0f0fe4d4-74ae-4dae-af76-2df2150979a5": {"__data__": {"id_": "0f0fe4d4-74ae-4dae-af76-2df2150979a5", "embedding": null, "metadata": {"page_label": "17", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0805e4c-5453-4975-afae-5a8b8e6f94f7", "node_type": "4", "metadata": {"page_label": "17", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c1740b7d850b9f3b4e5b2e521f07858e18081b8d453cfbe53104ef1cb62fe7cb", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n17\nSeptember 2024\nTwo common chain-based patterns that have emerged to mitigate recency and \nhallucinations are retrieval augmented generation (RAG)3 and Agents. \n\u2022 RAG addresses these challenges by augmenting pre-trained models with \n\u201cknowledge\u201d retrieved from databases, bypassing the need for pre-training. This \nenables grounding and reduces hallucinations by incorporating up-to-date factual \ninformation directly into the generation process. \n\u2022 Agents, popularized by the ReAct prompting technique,4 leverage LLMs as mediators \ninteracting with various tools, including RAG systems, internal or external APIs, \ncustom extensions, or even with other agents. This enables complex queries and \nreal-time actions by dynamically selecting and utilizing relevant information sources. \nThe LLM, acting as an agent, interprets the user\u2019s query, decides which tool to utilize, \nand how to formulate the response based on the retrieved information.\nRAG and Agents approaches can be combined to create multi-agent systems connected \nto large information networks, enabling sophisticated query handling and real-time \ndecision-making. \nThe orchestration of different models, logic and APIs is not a novelty of gen AI \nApplications. For example, recommendation engines have long combined collaborative \nfiltering models, content-based models, and business rules to generate personalized \nproduct recommendations for users. Similarly, in fraud detection, machine learning \nmodels are integrated with rule-based systems and external data sources to identify \nsuspicious activities.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1629, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "582ea820-9b83-49b3-b861-e31f24500685": {"__data__": {"id_": "582ea820-9b83-49b3-b861-e31f24500685", "embedding": null, "metadata": {"page_label": "18", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "84402524-b756-4bbe-af30-1bc6c088de1f", "node_type": "4", "metadata": {"page_label": "18", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "166cd3ad357a26d00a89e19fc33d9fc9c30905be830dba62952ecad5b9935aee", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n18\nSeptember 2024\nWhat makes these chains of gen AI components different, is that, we can't a priori \ncharacterize or cover the distribution of component inputs, which makes the individual \ncomponents much harder to evaluate and maintain in isolation.\nThis results in a paradigm shift in how AI applications are being developed for gen AI.\nUnlike Predictive AI where it is often possible to iterate on the separate models and \ncomponents in isolation to then chain in the AI application, in gen AI it\u2019s often easier to \ndevelop a chain in integration, performing experimentation on the chain end-to-end, iterating \nover chaining strategies, prompts, the underlying foundational models and other APIs in \na coordinated manner to achieve a specific goal. No feature engineering, data collection, \nor further model training cycles is often needed; just changes to the wording of the \nprompt template.\nThe shift towards MLOps for gen AI, in contrast to predictive AI, brings forth a new set of \ndemands. Let's break down these key differences:\n1. Evaluation: Because of their tight coupling, chains need end-to-end evaluation, not just \non a per-component basis, to gauge their overall performance and the quality of their \noutput. In terms of evaluation techniques and metrics, evaluating chains is not dissimilar \nto evaluating prompted models. Please refer to the below segment on evaluation for more \ndetails on these approaches.\n2. Versioning: A chain needs to be managed as a complete artifact in its entirety. The chain \nconfiguration should be tracked with its own revision history for analysis, reproducibility, \nand understanding the impact of changes on output. Logging should also include the \ninputs, outputs, and intermediate states of the chain, and any chain configurations used \nduring each execution.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1871, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b069d57d-86d2-4070-aa8e-b6e1d788622c": {"__data__": {"id_": "b069d57d-86d2-4070-aa8e-b6e1d788622c", "embedding": null, "metadata": {"page_label": "19", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3cd33769-a765-4bb0-b415-a4fecbf9faf7", "node_type": "4", "metadata": {"page_label": "19", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "dd653ba80b1dfbc538f44bf63d58ed70a81e2c7b856c3190896c18ff098edfd9", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n19\nSeptember 2024\n3. Continuous Monitoring: Establishing proactive monitoring systems is vital for detecting \nperformance degradation, data drift, or unexpected behavior in the chain. This ensures \nearly identification of potential issues to maintain the quality of the generated output. The \nactivity of monitoring Chains is discussed in detail in the section \u2018Logging and Monitoring\u2019. \n4. Introspection: The ability to inspect the internal data flows of a chain (inputs and outputs \nfrom each component) as well as the inputs and outputs of the entire chain is paramount. \nBy providing visibility into the data flowing through the chain and the resulting content, \ndevelopers can pinpoint the sources of errors, biases, or undesirable behavior.\nFigure 7.  Putting together chains, prompted models and model tuning\nThere are several products in Vertex AI that can support the need for chaining and \naugmentation, including Grounding as a service,5 Extensions,6 and Vector Search,7 Agent \nBuilder.8 We discuss the products in the  section \u201cRole of a AI Platform\u201d. Langchain9 is also \nintegrated with the Vertex SDK,10 and can be used alongside the core Vertex products to \ndefine and configure gen AI chained applications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1279, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ae1e9bc8-44a3-4210-996d-0a6b0d1f4459": {"__data__": {"id_": "ae1e9bc8-44a3-4210-996d-0a6b0d1f4459", "embedding": null, "metadata": {"page_label": "20", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c54cd93d-86fb-4cda-b685-45f87aef1ed0", "node_type": "4", "metadata": {"page_label": "20", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "db3468f1774c678922225515cc4bcf189b5e687f86051d3d31415fe23ed23cda", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n20\nSeptember 2024\nTuning & training\nWhen developing a gen AI use case and a specific task that involves LLMs, it can be difficult, \nespecially for complex tasks, to rely on only prompt engineering and chaining to solve it.      \nTo improve task performance practitioners often also need to fine-tune the model directly. \nFine-tuning lets you actively change the layers or a subset of layers of the LLM to optimize \nthe capability of the model to perform a certain task. Two of the most common ways of \ntuning a model are:\n1. Supervised fine-tuning: This is where we train the model in a supervised manner, teaching \nit to predict the right output sequence for a given input. \n2. Reinforcement Learning from Human Feedback (RLHF): In this approach, we first train \na reward model to predict what humans would prefer as a response. Then, we use this \nreward model to nudge the LLM in the right direction during the tuning process. Like \nhaving a panel of human judges guiding the model's learning. \nFigure 8.  Putting together chains, prompted models and model tuning", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1122, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dd968119-91dd-496e-beab-48eedfc44612": {"__data__": {"id_": "dd968119-91dd-496e-beab-48eedfc44612", "embedding": null, "metadata": {"page_label": "21", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f4ccc425-43dd-4444-8d53-ebc57808c268", "node_type": "4", "metadata": {"page_label": "21", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "49c5ffc1bfabf4a15643b792eb905d72965d80e36ef51d8bd0c4045eb542bf4d", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n21\nSeptember 2024\nWhen viewed through the MLOps lens, fine-tuning shares similar requirements with \nmodel training:\n1. The capability to track artifacts being part of the tuning job. This includes for example the \ninput data or the parameters being used to tune the model.\n2. The capability to measure the impact of the tuning. This translates into the capability \nto perform evaluation of the tuned model for the specific tasks it was trained on and to \ncompare results with previously tuned models or frozen models for the same task.\nPlatforms like Vertex AI11 (and the Google Cloud platform more broadly) provide a robust \nsuite of services designed to address these MLOps requirements: Vertex Model Registry,12 \nfor instance, provides a centralized storage location for all the artifacts created during the \ntuning job, and Vertex Pipelines13 streamlines the development and management of these \ntuning jobs. Dataplex,14 meanwhile, provides an organization-wide data fabric for data lineage \nand governance and integrates well with both Vertex AI and BigQuery.15 What\u2019s more, these \nproducts provide the same governance capability for both predictive and gen AI applications, \nmeaning customers do not need separate products or configurations to manage generative \nversus AI development.\nContinuous Training & Tuning\nIn machine learning operations (MLOps), continuous training is the practice of repeatedly \nretraining machine learning models in a production environment. This is done to ensure \nthat the model remains up-to-date and performs well as real-world data patterns change \nover time. For gen AI models, continuous tuning of the models is often more practical than \nretraining from scratch due to the high data and computational costs involved.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1815, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bdd1deb3-38d8-4356-a2bf-fcf12e4d6ca2": {"__data__": {"id_": "bdd1deb3-38d8-4356-a2bf-fcf12e4d6ca2", "embedding": null, "metadata": {"page_label": "22", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0ef40838-49a3-4387-9b5b-b629b863bc59", "node_type": "4", "metadata": {"page_label": "22", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2aeee0f26479f5b3cb7c8640e081aa1422a536f9b180f839a3507a96961f6844", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n22\nSeptember 2024\nThe approach to continuous tuning depends on the specific use case and goals. For relatively \nstatic tasks like text summarization, the continuous tuning requirements may be lower. But \nfor dynamic applications like chatbots that need constant human alignment, more frequent \ntuning using techniques like RLHF based on human feedback is necessary. \nTo determine the right continuous tuning strategy, AI practitioners must carefully evaluate \nthe nature of their use case and how the input data evolves over time. Cost is also a major \nconsideration, as the compute infrastructure greatly impacts the speed and expense of \ntuning.  We discuss in detail monitoring of GenAI systems in the Logging and Monitoring \nsection of this whitepaper.\nGraphics processing units (GPUs) and tensor processing units (TPUs) are key hardware for \nfine-tuning. GPUs, known for their parallel processing power, are highly effective in handling \nthe computationally intensive workloads and often associated with training and running \ncomplex machine learning models. TPUs, on the other hand, are specifically designed \nby Google for accelerating machine learning tasks. TPUs excel in handling large matrix \noperations common in deep learning neural networks.\nTo manage costs, techniques like model quantization can be applied. This represents model \nweights and activations using lower-precision 8-bit integers rather than 32-bit floats, which \nreduces computational and memory requirements.\nWe discuss in detail the support for tuning in Vertex AI in the Customize: Vertex AI Training & \nTuning section.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1658, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "006973cd-936c-44b3-8cc3-b2ad1a3aa1ba": {"__data__": {"id_": "006973cd-936c-44b3-8cc3-b2ad1a3aa1ba", "embedding": null, "metadata": {"page_label": "23", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88be3ac9-e0e0-42dd-9321-be28d3d93014", "node_type": "4", "metadata": {"page_label": "23", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b443f63c8eb7bbacaabd0e9ccc1779d456cbdcc063992d923565c3d1b2a8e5be", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n23\nSeptember 2024\nData Practices\nTraditionally, ML model behavior was dictated solely by its training data. While this still holds \ntrue for foundation models \u2013 trained on massive, multilingual, multimodal datasets \u2013 gen AI \napplications built on top of them introduce a new twist: model behavior is now determined by \nhow you adapt the model using different types of input data (Figure. 9).\nFigure 9.  Examples of data spectrum for foundation models \u2013 creation (left) vs. adaptation (right)\nThe key difference between traditional predictive ML and gen AI lies in where you start. In \npredictive ML, the data is paramount. You spend a lot of time on data engineering, and if you \ndon\u2019t have the right data, you cannot build an application. Gen AI takes a unique approach to \nthis matter. You start with a foundation model, some instructions and maybe a few example \ninputs (in-context learning). You can prototype and launch an application with surprisingly \nlittle data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1028, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bbd40ded-1082-4e46-85e2-c899938debb1": {"__data__": {"id_": "bbd40ded-1082-4e46-85e2-c899938debb1", "embedding": null, "metadata": {"page_label": "24", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a81c7340-e0df-4108-90b5-2f7bf33cd219", "node_type": "4", "metadata": {"page_label": "24", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6699b567f0559100180610e06812907e555a6070a4b01a5d9cc2ce4ae6943b85", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n24\nSeptember 2024\nThis ease of prototyping, however, comes with a challenge. Traditional predictive AI relies on \napriori well-defined dataset(s). In gen AI, a single application can leverage various data types, \nfrom completely different data sources, all working together (Figure 10). Let\u2019s explore some \nof these data types:\n\u2022 Conditioning prompts: These are essentially instructions given to the Foundation Model \n(FM) to guide its output, setting boundaries of what it can generate.\n\u2022 Few-shot examples: A way to show the model what you want to achieve through input-\noutput pairs. This helps the model grasp the specific task(s) at hand, and in many cases, it \nboosts performances.\n\u2022 Grounding/augmentation data: Data coming from either external APIs (like Google \nSearch) or internal APIs and data sources. This data  permits the FM to produce answers \nfor a specific context, keeping responses current, relevant without retraining the entire \nFM. This type of data also supports reducing hallucinations.\n\u2022 Task-specific datasets: These are used to fine-tune an existing FM for a particular task, \nimproving its performance in that specific area.\n\u2022 Human preference datasets: These capture feedback on generated outputs, helping \nrefine the model\u2019s ability to produce outputs that align with human preferences. \n\u2022 Full pre training corpora: These are massive datasets used to initially train foundation \nmodels. While application builders may not have access to them nor the tokenizers, \nthe information encoded in the model itself will influence the application\u2019s output \nand performance.\nThis is not an exhaustive list. The variety of data used in gen AI applications is constantly \ngrowing and evolving.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1770, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "711091c8-7551-4ef6-8796-910f1d7b8d7a": {"__data__": {"id_": "711091c8-7551-4ef6-8796-910f1d7b8d7a", "embedding": null, "metadata": {"page_label": "25", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "10bc31b9-3e74-4656-9192-4fd76a336d0b", "node_type": "4", "metadata": {"page_label": "25", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "8a9448ea3c05bf36f19a015a6d835bd063e28febd80ef0fc4c8bb9def463e08b", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n25\nSeptember 2024\nFigure 10.  Example of high-level data and adaptations landscape for developing gen AI applications using \nexisting foundation models\nThis diverse range of data adds another complexity layer in terms of data organization, \ntracking and lifecycle management. Take a RAG-based application as an example: it might \ninvolve rewriting user queries, dynamically gathering relevant examples using a curated set \nof examples, querying a vector database, and combining it all with a prompt template. This \ninvolves managing multiple data types: user queries,  vector databases with curated few-shot \nexamples and company information, and prompt templates.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 721, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f9eaf67c-26b5-43b9-89a8-d130743afbf9": {"__data__": {"id_": "f9eaf67c-26b5-43b9-89a8-d130743afbf9", "embedding": null, "metadata": {"page_label": "26", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c93fcecb-672e-4e21-a3c6-3933c291b2f0", "node_type": "4", "metadata": {"page_label": "26", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "cdacf58561c3f90db09dcc967f0239d550cd3d8920a3dfe9c845a17d0bf6c788", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n26\nSeptember 2024\nEach data type needs careful organization and maintenance. For example, the vector \ndatabase requires processing data into embeddings, optimizing chunking strategies, and \nensuring only relevant information is available. The prompt template itself needs versioning \nand tracking, the user queries need rewriting, etc. This is where  traditional MLOps and \nDevOps best practices come into play, with a twist. We need to ensure reproducibility, \nadaptability, governance, and continuous improvement using all the data required in an \napplication as a whole but also individually. Think of it this way: in predictive AI, the focus \nwas on well-defined data pipelines for extraction, transformation, and loading. In gen AI, \nit's about building pipelines to manage, evolve, adapt and integrate different data types in a \nversionable, trackable, and reproducible way. \nAs mentioned earlier, fine-tuning foundation models (FMs) can boost gen AI app \nperformance, but it needs data. You can get this data by launching your app and gathering \nreal-world data, generating synthetic data, or a mix of both. Using large models to generate \nsynthetic data is becoming popular because it speeds things up, but it's still good to have a \nhuman check the results for quality assurance. Here are few ways to leverage large models \nfor data engineering purposes:\n1. Synthetic data generation: This process involves creating artificial data that closely \nresembles real-world data in terms of its characteristics and statistical properties, often \nbeing done with a large and capable model. This synthetic data serves as additional \ntraining data for gen AI, enabling it to learn patterns and relationships even when labeled \nreal-world data is scarce.\n2. Synthetic data correction: This technique focuses on identifying and correcting errors \nand inconsistencies within existing labeled datasets. By leveraging the power of larger \nmodels, gen AI can flag potential labeling mistakes and propose corrections, improving the \nquality and reliability of the training data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2127, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7920b910-679c-4333-89e8-497f857726df": {"__data__": {"id_": "7920b910-679c-4333-89e8-497f857726df", "embedding": null, "metadata": {"page_label": "27", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b566ef62-2afe-4e87-abd0-85899b9051c4", "node_type": "4", "metadata": {"page_label": "27", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "8f18018f506928a2aacb419b009f49a5301b5959e2610c89b3214d747acb61f6", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n27\nSeptember 2024\n3. Synthetic data augmentation: This approach goes beyond simply generating new \ndata. It involves intelligently manipulating existing data to create diverse variations while \npreserving essential features and relationships. Thus, gen AI can encounter a broader \nrange of scenarios during training, leading to improved generalization and ability to \ngenerate nuanced and relevant outputs.\nEvaluating gen AI, unlike predictive AI, is tricky. You don't usually know the training data \ndistribution of the foundational models. Building a custom evaluation dataset reflecting your \nuse case is essential. This dataset should cover essential, average, and edge cases. Similar \nto fine-tuning data, you can leverage powerful language models to generate, curate, and \naugment data for building robust evaluation datasets.\nEvaluate\nEven if only prompt engineering is performed, as any experimental process, it does require \nevaluation in order to iterate and improve. This makes the evaluation process a core activity \nof the development of any gen AI systems.\nIn the context of gen AI systems, evaluation might have different degrees of automation: from \nentirely driven by humans to entirely automated by a process. \nIn the early days of a project, when you're still prototyping, evaluation is often a manual \nprocess. Developers eyeball the model's outputs, getting a qualitative sense of how it's \nperforming. But as the project matures and the number of test cases balloons, manual \nevaluation becomes a bottleneck. That's when automation becomes key.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1623, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "60610e1f-b039-4b9c-b8f1-7f7ef79c1b28": {"__data__": {"id_": "60610e1f-b039-4b9c-b8f1-7f7ef79c1b28", "embedding": null, "metadata": {"page_label": "28", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "11d7f8b9-9033-47b4-aad4-ecd5751a266b", "node_type": "4", "metadata": {"page_label": "28", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "f470d97c2568128a52d2e33ac0050ad4ba6bb13eb30c9ab13ad2a21a18c3e4a0", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n28\nSeptember 2024\nAutomating evaluation has two big benefits. First, it lets you move faster. Instead of spending \ntime manually checking each test case, you can let the machines do the heavy lifting. \nThis means more iterations, more experiments, and ultimately, a better product. Second, \nautomation makes evaluation more reliable. It takes human subjectivity out of the equation, \nensuring that results are reproducible.\nBut automating evaluation for gen AI comes with its own set of challenges. \nFor one, both the inputs (prompts) and outputs can be incredibly complex. A single prompt \nmight include multiple instructions and constraints that the model needs to juggle. And the \noutputs themselves are often high-dimensional - think a generated image or a block of text. \nCapturing the quality of these outputs in a simple metric is tough.\nThere are some established metrics, like BLEU for translations and ROUGE for summaries, \nbut they don't always tell the full story. That's where custom evaluation methods come in. \nOne approach is to use another foundational model as a judge. For example, you could \nprompt a large language model to score the quality of generated texts across various \ndimensions. This is the idea behind techniques like AutoSxS.16\nAnother challenge is the subjective nature of many evaluation metrics for gen AI. What \nmakes one output \u2018better\u2019 than another can often be a matter of opinion. The key here is to \nmake sure your automated evaluation aligns with human judgment. You want your metrics \nto be a reliable proxy for what people would think. And to ensure comparability between \nexperiments, it's crucial to lock down your evaluation approach and metrics early in the \ndevelopment process.\nLack of ground truth data is another common hurdle, especially in the early stages of a \nproject. One workaround is to generate synthetic data to serve as a temporary ground truth, \nwhich can be refined over time with human feedback.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2019, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f9c39f70-cd3b-43d6-89cf-db214ffc7838": {"__data__": {"id_": "f9c39f70-cd3b-43d6-89cf-db214ffc7838", "embedding": null, "metadata": {"page_label": "29", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3630a184-666e-4a10-9ada-96416b58572a", "node_type": "4", "metadata": {"page_label": "29", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "19aea4c92ac59ee2e9eea8f7439da06ed7aab9e44bdc1c8e3f8fecda80fa91e8", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n29\nSeptember 2024\nFinally, comprehensive evaluation is essential for safeguarding gen AI applications against \nadversarial attacks. Malicious actors can craft prompts to try to extract sensitive information \nor manipulate the model's outputs. Evaluation sets need to specifically address these attack \nvectors, through techniques like prompt fuzzing (feeding the model random variations on \nprompts) and testing for information leakage.\nAutomating the evaluation process ensures speed, scalability and reproducibility\nAn automation of the evaluation process can be considered a proxy for the \nhuman judgmen\nDepending on the use case, the evaluation process will require a high degree \nof customization.\nTo ensure comparability it is essential to stabilize the evaluation approach, metrics, \nand ground truth data as early as possible in the development phase.\nIt is possible to generate synthetic ground truth data to accommodate for the lack of \nreal ground truth data.\nIt is important to include test cases of adversarial prompting as part of the evaluation \nset to test the reliability of the system itself for these attacks.\nTable 1.  Key suggestions to approach evaluation of gen AI systems", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1252, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5da0c19-7530-4809-ba60-0f340ab78674": {"__data__": {"id_": "b5da0c19-7530-4809-ba60-0f340ab78674", "embedding": null, "metadata": {"page_label": "30", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "52c3f5e3-3196-411b-a1cc-7aa8137549c2", "node_type": "4", "metadata": {"page_label": "30", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "88660ba6f85b8e292919a90c7c0322e0e7bb8b021ac21d3eea900c4fb78736ad", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n30\nSeptember 2024\nDeploy\nIt should be clear by this point that production gen AI applications are complex systems with \nmany interacting components. Some of the common components discussed include multiple \nprompts, models, adapter layers and external data sources. In deploying a gen AI system to \nproduction, all these components need to be managed and coordinated with the previous \nstages of gen AI system development. Given the novelty of these systems, best practices \nfor deployment and management are still evolving, but we can discuss observations and \nrecommendations for these components and indicate how to address the major concerns.\nDeploying gen AI solutions necessarily involves multiple steps. For example, a single \napplication might utilize several large language models (LLMs) alongside a database, all \nfed by a dynamic data pipeline. Each of these components potentially requires its own \ndeployment process.\nFor clarity, we distinguish between two main types of deployment:\n1. Deployment of gen AI systems: This focuses on operationalizing a complete system \ntailored for a specific use case. It encompasses deploying all the necessary elements \n-  the application, chosen LLMs, database, data pipelines, and any other relevant \ncomponents - to create a functioning end-user solution.\n2. Deployment of foundational models: This applies to open-weight models, where the \nmodel weights are publicly available on platforms like Vertex Model Garden or Hugging \nFace, or privately trained models. Deployment in this scenario centers around making \nthe foundational model itself accessible to users. Given their multipurpose nature, these \ndeployments often aim to support various potential use cases.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1775, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "db7bee45-925c-4103-a72b-c6f6c7093253": {"__data__": {"id_": "db7bee45-925c-4103-a72b-c6f6c7093253", "embedding": null, "metadata": {"page_label": "31", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8193005d-6228-42ba-a51c-3fd5be310802", "node_type": "4", "metadata": {"page_label": "31", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "dc5b5d18e6c065c822a811dbae172869c7617c619ffddc9a2256d3d9d996d4e3", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n31\nSeptember 2024\nDeployment of gen AI systems\nDeployment of gen AI systems is broadly similar to deployment of any other complex \nsoftware system. Most of the system components \u2013 databases, Python applications, etc. \u2013 \nare also found in other non-gen AI applications. As a result, our general recommendation is \nto manage these components using standard software engineering practices such as version \ncontrol17 and Continuous Integration / Continuous Delivery (CI/CD).18\nVersion control\nGen AI experimentation is an iterative process involving repeated cycles of development, \nevaluation, and modification. To ensure a structured and manageable approach, it's crucial to \nimplement strict versioning for all modifiable components. These components include:\n\u2022 Prompt templates: Unless leveraging specific prompt management solutions, version \nthem through standard version control tools like Git.\n\u2022 Chain definitions: The code defining the chain (including API integrations, database calls, \nfunctions, etc.) should also be versioned using tools like Git. This provides a clear history \nand enables easy rollback if needed.\n\u2022 External datasets: In retrieval augmented generation (RAG) systems, external datasets \nplay a key role. It\u2019s important to track these changes and versions of these datasets for \nreproducibility. You can do that by leveraging existing data analytics solutions such as \nBigQuery, AlloyDB, Vertex Feature Store. \n\u2022 Adapter models: The landscape of techniques like LoRA tuning for adapter models is \nconstantly evolving. . You can leverage established data storage solutions (e.g. cloud \nstorage) to manage and version these assets effectively.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1724, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d24dae32-74a5-4c98-9831-f8751b5c079e": {"__data__": {"id_": "d24dae32-74a5-4c98-9831-f8751b5c079e", "embedding": null, "metadata": {"page_label": "32", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "59d416bc-59ec-4715-81d0-a4a6e2731daf", "node_type": "4", "metadata": {"page_label": "32", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "8c8d5752cd33d9d66d8fc31e8031200e7ab3437bc3a125042a60698835a858a8", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n32\nSeptember 2024\nContinuous integration of gen AI systems\nIn a continuous integration framework, every code change goes through automatic testing \nbefore merging to catch issues early. Here, unit and integration testing are key for quality \nand reliability. Unit tests act like a microscope, zooming in on individual code pieces, while \nintegration testing verifies that different components work together.\nThe benefits of continuous integration in traditional software development are well-\nunderstood. Implementing a CI system helps to do the following:\n1. Ensure reliable, high-quality outputs: Rigorous testing increases confidence in the \nsystem's performance and consistency.  \n2. Catch bugs early: Identifying issues through testing prevents them from causing bigger \nproblems downstream. It also makes the system more robust and resilient to edge cases \nand unexpected inputs.\n3. Lower maintenance costs: Well-documented test cases simplify troubleshooting and \nenable smoother modifications in the future, reducing overall maintenance efforts\nThese benefits are applicable to gen AI Systems as much as any software product. \nContinuous Integration should be applied to all elements of the system, including the prompt \ntemplates, the chain and chaining logic, and any embedding models and retrieval systems.\nHowever, applying CI to gen AI comes with challenges:\n1. Difficult to generate comprehensive test cases: The complex and open-ended nature of \ngen AI outputs makes it hard to define and create an exhaustive set of test cases that \ncover all possibilities.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1630, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4e835b84-892f-490e-af73-a7f4475cf64b": {"__data__": {"id_": "4e835b84-892f-490e-af73-a7f4475cf64b", "embedding": null, "metadata": {"page_label": "33", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ce7aeee7-643c-4775-b071-9f78d78693a8", "node_type": "4", "metadata": {"page_label": "33", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b66de9012b7bfe49169339fd61767ba7f0207cef42b468e89d9765ad37469323", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n33\nSeptember 2024\n2. Reproducibility issues: Achieving deterministic, reproducible results is tricky since \ngenerative models often have intrinsic randomness and variability in their outputs, even for \nidentical inputs. This makes it harder to consistently test for specific expected behaviors.\nThese challenges are closely related to the broader question of how to evaluate gen AI \nsystems. Many of the same techniques discussed in the Evaluation section above can also \nbe applied to the development of CI systems for gen AI. This is an ongoing area of research, \nhowever, and more techniques will undoubtedly emerge in the near future.\nContinuous delivery of gen AI systems\nOnce the code is merged, a continuous delivery process begins to move the built and tested \ncode through environments that closely resemble production for further testing before the \nfinal deployment. \nAs mentioned in the \"'\"Develop and Experiment\"'\" segment, chain elements become one \nof the main components to deploy, as they fundamentally constitute the gen AI application \nserving users.\nThe delivery process of the gen AI application containing the chain may vary depending on \nthe latency requirements and whether the use case is batch or online:\n1. Batch use cases require deploying a batch process executed on a schedule in production. \nThe delivery process should focus on testing the entire pipeline in integration in an \nenvironment close to production before deployment. As part of the testing process, \ndevelopers can assert specific requirements around the throughput of the batch process \nitself and checking that all components of the application are functioning correctly (e.g., \npermissioning, infrastructure, code dependencies).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1782, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a08c638c-23a9-4e05-a7ca-ce99eeb66994": {"__data__": {"id_": "a08c638c-23a9-4e05-a7ca-ce99eeb66994", "embedding": null, "metadata": {"page_label": "34", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fba2d7d4-ea40-4ab5-99bc-5cf227c352f3", "node_type": "4", "metadata": {"page_label": "34", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "8d6cbbbe998a981e4efbf60115f6c78eed42d4faa7ebf27f461ad5cfdf162f86", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n34\nSeptember 2024\n2. Online use cases require deploying an API, in this case, the application containing the \nchain, capable of responding to users at low latency. The delivery process should involve \ntesting the API in integration in an environment close to production, with tests to assert \nthat all components of the application are functioning correctly (e.g., permissioning, \ninfrastructure, code dependencies). Non-functional requirements (e.g., scalability, \nreliability, performance) can be verified through a series of tests, including load tests.\nDeployment of foundation models\nBecause foundation models are so large and complex, deployment and serving of these \nmodels raises a number of issues \u2013 most obviously, the compute and storage resources \nneeded to run these massive models successfully. At a minimum, a foundation model \ndeployment needs to include several key considerations: selecting and securing necessary \ncompute resources, such as GPUs or TPUS; choosing appropriate data storage services \nlike BigQuery or Google Cloud Storage that can scale to deal with the large datasets; and \nimplementing model optimization or compression techniques.\nInfrastructure validation\nOne technique that can be applied to address the resource requirements of gen AI systems is \ninfrastructure validation. This refers to the introduction of an additional verification step, prior \nto deploying the training and serving systems, to check both the compatibility of the model \nwith the defined serving configuration and the availability of the required hardware. There \nare a number of optional infrastructure validation layers that can perform some of these \nchecks automatically. For instance, TFX19 has an infrastructure validation layer that checks", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1814, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "55f3fff1-41f8-4fe7-ac45-92d575a7469a": {"__data__": {"id_": "55f3fff1-41f8-4fe7-ac45-92d575a7469a", "embedding": null, "metadata": {"page_label": "35", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "87348c05-dd56-419d-b3e5-d2759f1f9544", "node_type": "4", "metadata": {"page_label": "35", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "95d25b230c1bdc086c7f21734301016d4b702ec8cf9f68f5baeedb6e42c12509", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n35\nSeptember 2024\nwhether the model will run correctly on a specified hardware configuration, which can help \ncatch configuration issues before deployment. Nevertheless, the availability of the required \nhardware still needs to be verified by hand by the engineer or the system administrator.\nCompression and optimization\nAnother way of addressing infrastructure challenges is to optimize the model itself. \nCompressing and/or optimizing the model can often significantly reduce the storage and \ncompute resources needed for training and serving, and in many cases can also decrease \nthe serving latency.\nSome techniques for model compression and optimization include quantization, distillation \nand model pruning. Quantization reduces the size and computational requirements of the \nmodel by converting its weights and activations from higher-precision floating-point numbers \nto lower-precision representations, such as 8-bit integers or 16-bit floating-point numbers. \nThis can significantly reduce the memory footprint and computational overhead of the model. \nModel Pruning is a technique for eliminating unnecessary weight parameters or by selecting \nonly important subnetworks within the model. This reduces model size while maintaining \naccuracy as high as possible. Finally, distillation trains a smaller model, using the responses \ngenerated by a larger LLM, to reproduce the output of the larger LLM for a specific domain. \nThis can significantly reduce the amount of training data, compute, and storage resources \nneeded for the application.\nIn certain situations, model distillation can also improve the performance of the model itself \nin addition to reducing resource requirements. This happens because the smaller model can \ncombine the knowledge of the larger model with labeled data, which can help it to generalize \nbetter to new data on a limited use case.The process of distillation usually involves training \na large foundational LLM (teacher model) and having it generate responses to certain tasks,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2079, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b3c82c8d-78bf-4280-b0ca-ce5f7a385060": {"__data__": {"id_": "b3c82c8d-78bf-4280-b0ca-ce5f7a385060", "embedding": null, "metadata": {"page_label": "36", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bb253272-2931-4385-a6d7-fb46f508a42e", "node_type": "4", "metadata": {"page_label": "36", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "57f4c01b7c2f0a70e8be783687a7c83db91250487b830f640c65303d6637331e", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n36\nSeptember 2024\nand then having the smaller LLM (student model) use a combination of the LLMs knowledge \nas well as task specific supervised dataset to learn. The size and complexity of the smaller \nLLM can be adjusted to achieve the desired trade-off between performance and resource \nrequirements. A technique known as step-by-step distillation20 has proven to achieve \ngreat results.\nDeployment, packaging, and serving checklist\nFollowing are the important steps to take when deploying a model on Vertex AI.\n \u25a1 Configure version control: Implement version control practices for LLM deployments. \nThis allows you to roll back to previous versions if necessary and track changes made to \nthe model or deployment configuration.\n \u25a1 Optimize the model: Perform any model optimization (distillation, quantization, pruning, \netc.) before packaging or deploying the model.\n \u25a1 Containerize the model: Package the trained LLM model into a container. \n \u25a1 Define target hardware requirements: Ensure the target deployment environment \nmeets the requirements for optimal performance of the LLM model, such as GPUs, as well \nas TPUs and other specialized hardware accelerators.\n \u25a1 Define model endpoint: Define the endpoint configuration using Vertex AI's endpoint \ncreation interface or the Vertex AI SDK. Specify the model container, input and output \nformats, and any additional configuration parameters.\n \u25a1 Allocate resources: Allocate the appropriate compute resources for the endpoint based \non the expected traffic and performance requirements.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1599, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2bc27c9d-608f-442e-b2ee-2d64444e3c24": {"__data__": {"id_": "2bc27c9d-608f-442e-b2ee-2d64444e3c24", "embedding": null, "metadata": {"page_label": "37", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0e2c83ca-206a-4eb3-83a9-95ff1305fc14", "node_type": "4", "metadata": {"page_label": "37", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "1c06cc5c5a3129a77d3bc957c7f3fde447b3e9cee8972f4bdf05702db0fa44d2", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n37\nSeptember 2024\n \u25a1 Configure access control: Set up access control mechanisms to restrict access to \nthe endpoint based on authentication and authorization policies. This ensures that only \nauthorized users or services can interact with the deployed LLM.\n \u25a1 Create model endpoint: Create a Vertex AI endpoint to deploy21 the LLM as a REST API \nservice. This allows clients to send requests to the endpoint and receive responses from \nthe LLM..\n \u25a1 Configure monitoring and logging: Establish monitoring and logging systems to track \nthe endpoint's performance, resource utilization, and error logs.\n \u25a1 Deploy custom integrations: Integrate the LLM into custom applications or services \nusing the model's SDK or APIs. This provides more flexibility for integrating the LLM into \nspecific workflows or frameworks.\n \u25a1 Deploy Real-time Applications: For real-time applications, consider using Cloud \nFunctions and Cloud Run in combination with LLMs hosted in Vertex AI to create a \nstreaming pipeline that processes data and generates responses in real time.\nLogging and monitoring\nMonitoring gen AI applications and, as a result, their components, presents unique \nchallenges that require additional techniques and approaches on top of those in traditional \nMLOps. The use of gen AI requires the chaining of components in order to produce results \nfor practical applications. Additionally, to your application user, all the components are \nhidden. Therefore, the interface they have to your application is their input and the final \noutput. This creates the need to log and monitor your application end-to-end: that is, logging \nand monitoring the input and output of your application overall as well as the input and \noutput of every single component.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1807, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "65ff2806-b724-451f-a5a0-812362ee79d9": {"__data__": {"id_": "65ff2806-b724-451f-a5a0-812362ee79d9", "embedding": null, "metadata": {"page_label": "38", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a4e87799-7d1e-4c72-a051-8cd02591474d", "node_type": "4", "metadata": {"page_label": "38", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c38182933376fc9a31f20bb4068d0ec3085c3a9ea3c8cd0260e19848208dee11", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n38\nSeptember 2024\nLogging is necessary for applying monitoring and debugging on your gen AI system in \nproduction. An input to the application triggers multiple components. Imagine the output \nto a given input is factually inaccurate. How can you find out which of the components are \nthe ones that didn\u2019t perform well? To answer this question it is necessary to apply logging \non the application level and at the component level. We need lineage in our logging for all \ncomponents executed. For every component we need to log their inputs and outputs. We \nalso need to be able to map those with any additional artifacts and parameters they depend \non so we can easily analyze those inputs and outputs.\nMonitoring can be applied to the overall gen AI application and to individual components. We \nprioritize monitoring at the application level. This is because if the application is performant \nand monitoring proves that, it implies that all components are also performant. You can also \napply the same practices to each of the prompted model components to get more granular \nresults and understanding of your application.\nSkew detection in traditional ML systems refers to training-serving skew that occurs when \nthe feature data distribution in production deviates from the feature data distribution \nobserved during model training. In the case of Gen AI systems using pretrained models in \ncomponents chained together to produce the output, we need to modify our approach. We \ncan measure skew by comparing the distribution of the input data we used to evaluate our \napplication (the test set as described under the Data Curation and Principles section above) \nand the distribution of the inputs to our application in production. Once the two distributions \ndrift apart,further investigation is needed. The same process can be applied to the output \ndata as well.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1924, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "799acb1a-88dd-46b0-816c-d028b16ce76b": {"__data__": {"id_": "799acb1a-88dd-46b0-816c-d028b16ce76b", "embedding": null, "metadata": {"page_label": "39", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eed7d48e-b661-422c-ba1b-fd1625f3e606", "node_type": "4", "metadata": {"page_label": "39", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "37c6f57c5840fd35f8111775bd0c54512688c6e1941bb284edd7bd9971749fe4", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n39\nSeptember 2024\nFigure 11.  Drift/skew detection process overview\nLike skew detection, the drift detection process checks for statistical differences between \ntwo datasets. However, instead of comparing evaluations and serving inputs, drift looks for \nchanges in input data. This allows you to check how the inputs and therefore the behavior of \nyour users changed over time. This is the same as traditional MLOps. \nGiven that the input to the application is typically text, there are a few approaches to \nmeasuring skew and drift. In general all the methods are trying to identify significant \nchanges in production data, both textual (size of input) and conceptual (topics in input), \nwhen compared to the evaluation dataset. All these methods are looking for changes that \ncould potentially indicate the application might not be prepared to successfully handle the \nnature of the new data that are now coming in. Some common approaches are calculating \nembeddings and distances, counting text length and number of tokens, and tracking \nvocabulary changes, new concepts and intents, prompts and topics in datasets, as well \nas statistical approaches such as least-squares density difference,22 maximum mean \ndiscrepancy (MMD),23 learned kernel MMD,24 or context-aware MMD.25 As gen AI use cases \nare so diverse, it is often necessary to create additional custom metrics that better capture \nabnormal changes in your data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1482, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "44fbd4dd-c6c9-410e-b96e-66d63ac62be9": {"__data__": {"id_": "44fbd4dd-c6c9-410e-b96e-66d63ac62be9", "embedding": null, "metadata": {"page_label": "40", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cbd6c2c6-300c-43a3-9474-284b4e8f0fcd", "node_type": "4", "metadata": {"page_label": "40", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "02c3949ff6b5446bc37c1ea1658333797b664e942a49e561003d456eec5a1096", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n40\nSeptember 2024\nContinuous evaluation is another common approach to GenAI application monitoring. In \na continuous evaluation system, you capture the model's production output and run an \nevaluation task using that output, to keep track of the model's performance over time. One \napproach is collecting direct user feedback, such as ratings (for example thumbs up/down), \nwhich provides immediate insight into the perceived quality of outputs. In parallel, comparing \nmodel-generated responses against established ground truth, often collected through \nhuman assessment or as a result of an ensemble AI Model approach, allows for deeper \nanalysis of performance. Ground truth metrics can be used to generate evaluation metrics \nas described in the Evaluation section. This process provides a view on how your evaluation \nmetrics changed from when you developed your model to what you have in production today.\nAs with traditional monitoring in MLOps an alerting process should be deployed for notifying \napplication owners when a drift, skew or performance decay from evaluation tasks is \ndetected. This can help you promptly intervene and resolve issues. This is achieved by \nintegrating alerting and notification tools into your monitoring process.\nMonitoring expands beyond drift, skew and evaluation tasks. Monitoring in MLOps includes \nefficiency metrics like resources utilization and latency. Efficiency metrics are as relevant and \nimportant in gen AI as they are in any other AI application.\nVertex AI provides a set of tools that can help with monitoring. Model Evaluation for gen AI26 \ntasks can be used for classification, summarization, question answering, and text generation \ntasks. Vertex Pipelines can be used to allow the recurrent execution of evaluation jobs in \nproduction as well as running pipelines for skew and drift detection processes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1921, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "570fda88-9932-4ad4-9684-6ff3896eb9bc": {"__data__": {"id_": "570fda88-9932-4ad4-9684-6ff3896eb9bc", "embedding": null, "metadata": {"page_label": "41", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "268147d0-ec9e-4386-ae6a-00b0b17d496c", "node_type": "4", "metadata": {"page_label": "41", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "4b43aeb5233337b3851714e5ebbad4c1754d5a9013f84e2f9d00c429423f639e", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n41\nSeptember 2024\nGovern\nIn the context of MLOps governance encompasses all the practices, and policies that \nestablish control, accountability, and transparency over the development, deployment, and \nongoing management of machine learning (ML) models, including all the activities related to \nthe code, data and models lifecycle.\nAs mentioned in the Develop & Experiment section the chain element and the relative \ncomponents become a new type of assets that need to be governed over the full lifecycle \nfrom development to deployment, to monitoring. \nThe governance of the chain element lifecycle extends to lineage tracking practices as well.  \nWhile for predictive AI systems lineage focuses on tracking and understanding the complete \njourney of a machine learning model, in gen AI, lineage goes beyond the model artifact \nextending to all the components in the chain. This includes the data and models used and \ntheir lineage, the code involved and the relative evaluation data and metrics. This can help \nauditing, debugging and improvements of the models\nAlong with these new practices, existing MLOps and DevOps practices still apply to MLOps \nfor gen AI:\n1. The need to govern the data lifecycle; see \u201cData Practices\u201d.\n2. The need to govern the tuned model lifecycle; see \u201cTuning and Training\u201d.\n3. The need to govern the code lifecycle; see \u201cDeployment of GenAI \nSystem components\u201d.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1449, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d9f0af45-b744-4007-aeee-98eead94cd35": {"__data__": {"id_": "d9f0af45-b744-4007-aeee-98eead94cd35", "embedding": null, "metadata": {"page_label": "42", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9fc72680-8426-45e3-a91e-4bbb734c308c", "node_type": "4", "metadata": {"page_label": "42", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "8274098914a983040d94068ffb6dcedee54a10cc7f183f277915de5a62da826f", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n42\nSeptember 2024\nThe next segment will introduce a set of products that allow developers to perform \ngovernance of the data, model and code assets. We will discuss products like Google \nCloud Dataplex, which centralizes the governance of model and data, Vertex ML Metadata \nand Vertex Experiment, which allows developers to register experiments, their metrics \nand artifacts.\nThe role of an AI platform for gen \nAI operations\nAlongside the explosion of both predictive and gen AI applications, AI platforms, like Vertex \nAI,11 have emerged as indispensable tools for organizations seeking to leverage the power of \nArtificial Intelligence (AI). These comprehensive platforms provide a unified environment that \nstreamlines the entire AI lifecycle, from data preparation and model training to deployment, \nautomation, continuous integration/continuous delivery (CI/CD), governance, and monitoring.\nAt the heart of an AI platform lies its ability to support diverse AI development needs. \nWhether you seek to utilize pre-trained AI solutions, adapt existing models through tuning \nor transfer learning, or embark on training your own large models, AI platforms provide the \ninfrastructure and tools necessary to support these journeys. The advent of these platforms \nhas revolutionized the way organizations approach AI, enabling them to productionize AI \napplications in a secure, enterprise-ready, responsible, controlled and scalable manner. \nThese platforms accelerate innovation as well as foster reproducibility and collaboration \nwhile reducing costs and maximizing Return on Investment (ROI).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1656, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2b826e2b-bbbb-4393-808a-e6c57d66dbc3": {"__data__": {"id_": "2b826e2b-bbbb-4393-808a-e6c57d66dbc3", "embedding": null, "metadata": {"page_label": "43", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33616cbf-7045-48cb-ad07-8f4a5949ccf9", "node_type": "4", "metadata": {"page_label": "43", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "a35ad4240d7942f0c651453f60dc7403603677029cd84fc66f60db8d92d93f21", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n43\nSeptember 2024\nThe new gen AI paradigm discussed in prior sections demands a robust and reliable AI \nplatform that can seamlessly integrate and orchestrate a wide range of functionalities.   \nThese functionalities include model tuning for specific tasks; leveraging paradigms like \nretrieval augmented generation3 (RAG) to connect to internal and external data sources; \nand pre-training or instruction fine-tuning large models from scratch. Complex applications \nalso often require chaining with other models, such as classifiers to route inputs to the \nappropriate LLM/ML model, extraction of customer information from a knowledge base, \ninclusion of safety checks, or even creation of caching systems for cost optimization.  \nFigure 12.  Key components of Vertex AI for gen AI\nKey components of Vertex AI for gen AI\nVertex AI eliminates the complexities of managing the entire infrastructure required for AI \ndevelopment and deployment. Instead, Vertex AI offers a user-centric approach, providing \non-demand access to the needed resources. This flexibility empowers organizations to \nfocus on innovation and collaboration, rather than infrastructure management, and up-\nfront hardware purchase. The features of Vertex AI that support gen AI development can be \ngrouped into eight areas.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1350, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "85d707b4-493c-4959-bb30-c47a37540424": {"__data__": {"id_": "85d707b4-493c-4959-bb30-c47a37540424", "embedding": null, "metadata": {"page_label": "44", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8f47c2f0-f803-4e2f-af8c-d1599f44c456", "node_type": "4", "metadata": {"page_label": "44", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "5fc5b8b6c90201cbd10e996b70fb46fa97a18df9ce21dff017baefdca22448af", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n44\nSeptember 2024\nDiscover: Vertex Model Garden\nAs discussed before, there is already a wide variety of available foundation models, trained \non a broad range of datasets, and the cost of training a new foundation model can be \nprohibitive. Thus it often makes sense for companies to adapt existing foundation models \nrather than creating their own from scratch. As a result, a platform facilitating seamless \ndiscovery and integration of diverse model types is critical.\nVertex AI Model Garden1 supports these needs, offering a curated collection of over \n150 Machine Learning and gen AI models from Google, Google partners, and the open-\nsource community. It simplifies the discovery, customization, and deployment of both \nGoogle\u2019s proprietary foundational models and diverse open-source models across a \nvast spectrum of modalities, tasks, and features. This comprehensive repository permits \ndevelopers to leverage the collective research on artificial intelligence models within a single \nstreamlined environment.\nModel Garden encompasses a diverse range of modalities such as Language, Vision, Tabular, \nDocument, Speech, Video, and Multimodal data. This broad coverage enables developers \nto tackle a multitude of tasks, including generation, classification, regression, extraction, \nrecognition, segmentation, tracking, translation, and embedding. Model Garden houses \nGoogle\u2019s proprietary and foundational models (like Gemini,27 PaLM 2,28 Imagen29) alongside \nnumerous popular open source and third-party partner models like like Llama 3,30 T5 Flan,31 \nBERT,32 Stable Diffusion,33 Claude 3 (Anthropic),34 and Mistral AI.35 Additionally, it offers task-\nspecific models for occupancy analysis, watermark detection, text-moderation, text-to-video, \nhand-gesture recognition, product identification, and tag recognition, among others. Every \nmodel36 in Vertex Model Garden has a model card which includes a description of the model, \nthe main use cases that can cover, and the option (if available) to tune the model or deploy \nit directly.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2104, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5bce91c1-ad4a-4750-aa75-4a40014b88d7": {"__data__": {"id_": "5bce91c1-ad4a-4750-aa75-4a40014b88d7", "embedding": null, "metadata": {"page_label": "45", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "155745fa-3404-4d32-8c79-ecbc77ab8797", "node_type": "4", "metadata": {"page_label": "45", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "15921c0a1248ddf0b65a7ab40de7d3abb4e41e6e763c018ef8edd25d6d8fbbc2", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n45\nSeptember 2024\nModel Garden fosters experimentation by facilitating access to Google\u2019s proprietary \nfoundational models through the Vertex AI Studio UI,37 a playground where you can play \naround with prompts, models, and open-source models using provided Colab notebooks. \nOne-click deployment is available for some external models, and there are more than 40 \nmodels available for fine-tuning for specific needs. Furthermore, the platform allows users to \nleverage technologies like vLLM38 and quantization techniques for optimizing deployments for \nefficiency and reduced costs. We present below an overview of some of the models in Model \nGarden. For an up-to-date list, please visit.36", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 749, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4bcf327f-1b76-419c-8d60-f0370e332dcd": {"__data__": {"id_": "4bcf327f-1b76-419c-8d60-f0370e332dcd", "embedding": null, "metadata": {"page_label": "46", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b3c8654-1be7-43bb-b1b6-a69cdfafe24d", "node_type": "4", "metadata": {"page_label": "46", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "474ccaf3a1fac460115db1f8dbe55eb697797de3f290481eba3ab1cd116efa09", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n46\nSeptember 2024\nModel Type Description Details\nFirst-party models Foundation models\nLeverage multimodal models \nfrom Google across vision, \ndialog, code generation, and \ncode completion.\nGemini39 and Palm240\nImagen for text-to-image41\nCodey for code generation \nand completion42\nChirp for speech-to-text43\nFirst-party models Pre-trained APIs\nBuild and deploy AI \napplications faster with our \npre-trained APIs powered by \nthe best Google AI research \nand technology.\nText-to-Speech44\nNatural Language processing 45\nTranslation46\nVision47\nOpen  models Open source models\nAccess a wide variety of \nenterprise-ready open \nsource models\nGoogle\u2019s Gemma,48 PaliGemma,16 \nCodeGemma49 \nMeta's Llama30\nTII's Falcon50\nMistral AI51\nBERT,32 T-5 FLAN,31 \nViT,52 EfficientNet53\nThird-party models Third-party models\nModel Garden will support \nthird-party models \nfrom partners with \nfoundation models.\nAnthropic\u2019s Claude 3 Haiku,  \nSonnet and Opus54,55\nTable 2.  An overview of some of the models in Model Garden [Last Updated: March 18th, 2024]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1090, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a7e0d2dc-c095-4e72-b26d-c9b4d7abf43b": {"__data__": {"id_": "a7e0d2dc-c095-4e72-b26d-c9b4d7abf43b", "embedding": null, "metadata": {"page_label": "47", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2f9dbfb7-a77a-4704-b997-c6d6ababc8e4", "node_type": "4", "metadata": {"page_label": "47", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "88a845271f44270f12dcf0d08eeea7124029d4a781f69897b7fdc3356eda550f", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n47\nSeptember 2024\nPrototype: Vertex AI Studio & Notebooks\nRapid development and prototyping capabilities are also essential for developing gen AI \napplications. Vertex AI prioritizes inclusivity and flexibility in its development environments, \ncatering to a wide range of developer preferences and proficiency levels. This platform \nprovides options for both console-driven and programmatic development workflows. Users \ncan leverage the intuitive web interface for end-to-end application creation or utilize various \nAPIs for deeper customization and control. These include the REST API56 and dedicated \nSDKs for Python,57 NodeJS58 and Java,59 ensuring compatibility with diverse programming \nlanguages and ecosystems. Developers can choose to use the tools and IDEs of their \nchoice for interacting with the platform, or take advantage of Vertex-native tools like Vertex \nColab Enterprise or Vertex Workbench to explore and experiment with code within familiar \nnotebook environments.\nVertex AI Studio60 provides a unified console-driven entry point to access and leverage the \nfull spectrum of Vertex AI's gen AI services. It facilitates exploration and experimentation with \nvarious Google first party foundation models (for example, PaLM 2, Gemini, Codey, Imagen, \nand Universal Speech Model). Additionally, it offers prompt examples and functionalities \nfor testing distinct prompts and models with diverse parameters. It\u2019s also possible to adapt \nexisting models through various techniques like supervised fine-tuning (SFT), reinforcement \nlearning tuning techniques, and Distillation, and deploy gen AI applications in just a few \nclicks. Vertex AI Studio considerably simplifies and democratizes gen AI adoption, catering \nto a variety of users, from business analysts to machine learning engineers. You can see the \nhomepage of Vertex AI Studio in Figure 13.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1926, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b89c9e5-8cd9-480e-b49e-a7171c91f4ab": {"__data__": {"id_": "1b89c9e5-8cd9-480e-b49e-a7171c91f4ab", "embedding": null, "metadata": {"page_label": "48", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ec3eed3-cbbd-4123-ab88-02a69dfe6b40", "node_type": "4", "metadata": {"page_label": "48", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "015ec61d8e95c937d756b19210cea1eb069534855c826436453569c0d05ef8c1", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n48\nSeptember 2024\nFigure 13.  Vertex AI Studio - Homepage\nCustomize: Vertex AI training & tuning \nWhile prompt engineering and augmentation are sufficient for some gen AI use cases, other \ncases require training, tuning and adapting the models to get the best results. Vertex AI \nprovides a comprehensive platform for training and adapting LLMs, supporting a range of \ntechniques and approaches from prompt engineering to training models from scratch.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 508, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2b0fea0d-63e0-4931-bba9-bfc3e5f73b22": {"__data__": {"id_": "2b0fea0d-63e0-4931-bba9-bfc3e5f73b22", "embedding": null, "metadata": {"page_label": "49", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7129473f-8679-4d1a-bdf2-9ce2450a28c7", "node_type": "4", "metadata": {"page_label": "49", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "ff152168725073ddaed0cd3d6e700adb1cdcc09e2f820c80f890c12153e94ddc", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n49\nSeptember 2024\nTrain \nFor full-scale LLM training, TPUs and GPUs are vital because of their superior processing \npower and memory capacity compared to CPUs. GPUs excel at parallel processing, enabling \nfaster model training. TPUs, specifically designed for machine learning tasks, offer even \nfaster processing and higher energy efficiency. This makes them ideal for large-scale, \ncomplex models. Google Cloud provides a range of offerings to support LLM training, \nincluding TPU VMs with various configurations, pre-configured AI platforms like Vertex AI, \nand dedicated resources like Cloud TPU Pods for scaling up training. These offerings allow \nusers to choose the right infrastructure for their needs, accelerating LLM development and \nenabling cutting-edge research and applications.\nTune \nVertex AI also provides a comprehensive solution for adapting pre-trained LLMs. It supports \na spectrum of techniques from a non-technical prompt engineering playground at inference \ntime, to data-driven approaches involving tuning, reinforcement learning and distillation \nmethods during the development or adaptation phase. The following five techniques \u2013 many \nof which are unique to Vertex AI \u2013 enable users to explore and implement them effectively. \nThis applies to both proprietary and open-source LLMs, allowing you to achieve superior \nresults while optimizing for costs and latency requirements.\n\u2022 Prompt engineering61 leverages carefully crafted natural language prompts, potentially \nchained and enriched with external knowledge and examples, to nudge the LLM towards \ndesired outputs without necessitating further training. Vertex AI through Vertex AI Studio \noffers a dedicated playground for crafting, testing, comparing and managing diverse \nprompts and techniques. Users can access various pre-built prompt templates within the \nplatform and leverage public prompting guidelines62 for Google\u2019s proprietary large models.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1993, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8edd0f1f-4431-4ea4-aeb6-2d114a5f098a": {"__data__": {"id_": "8edd0f1f-4431-4ea4-aeb6-2d114a5f098a", "embedding": null, "metadata": {"page_label": "50", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7a8caf13-deac-43b9-b6cf-59ae67e088fa", "node_type": "4", "metadata": {"page_label": "50", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "4f49643d778f72696c62993802508aa585d127db5e8accce8fd4ca146ee81a5d", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n50\nSeptember 2024\n\u2022 Supervised fine-tuning (SFT) 63 on Vertex AI facilitates model adaptation by leveraging a \nset of labeled examples (even a few hundred is enough) to tune a model on specific tasks \nand contexts within domain-specific datasets. The required examples resemble the one-\nshot example structure employed in the construction of a prompt. This effectively extends \nthe few-shot learning approach for enhanced optimization. This focused tuning enables \nthe model to encode additional parameters in the model necessary for mimicking desired \nbehaviors such as improved complex prompt comprehension, adaptation to specific \noutput formats, correcting errors, and learning new tasks. The SFT tuning approach on \nVertex AI, minimizes computational overhead and time while yielding an updated model \nthat integrates the newly acquired parameters with the original model\u2019s core parameters.\n\u2022 Reinforcement learning with human feedback (RLHF) ,64 available on Vertex AI for \nfoundational models like PaLM 2,and open-source models like T5 (s-xxl) and Llama2, \nleverages human feedback to train large models to align with human preferences. This \ntechnique is well-suited in complex tasks involving preference modeling and optimizes \nLLMs on intricate, sequence-level objectives not easily addressed by traditional \nsupervised fine-tuning. The process involves first training a reward model using a human \npreference dataset, then utilizing it to score the output from the LLM, and finally applying \nreinforcement learning to optimize the LLM. This approach is recognized as a key driver of \nsuccess in conversational large language models.\n\u2022 Distillation step-by-step20 is an advanced distillation technique transferring knowledge \nfrom a significantly larger model (known as teacher model) to a smaller task-specific \nmodel (known as student model), preserving important information while reducing model \nsize. Step-by-Step Distillation20 surpasses common techniques by requiring significantly \nless data. This method, accessible on Vertex AI,65 significantly reduces inference costs and \nlatencies while minimizing performance impact in the resulting smaller LLM.66", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2228, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a0734d7d-9b46-43ce-884a-5377f07af948": {"__data__": {"id_": "a0734d7d-9b46-43ce-884a-5377f07af948", "embedding": null, "metadata": {"page_label": "51", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3124aaeb-ddb0-4e2f-aec9-a575c267029f", "node_type": "4", "metadata": {"page_label": "51", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "73012f3bf927f9e1cb8893f2acafdaadca6dd5c83e550a755a2ae2b3517907a1", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n51\nSeptember 2024\nOrchestrate\nAny training or tuning job you run can be orchestrated and then operationalized using Vertex \nPipelines,13 a service that aims to simplify and automate the deployment, management, and \nscaling of your ML workflows. \nIt provides a platform for building, orchestrating, scheduling and monitoring complex and \ncustom ML pipelines, enabling you to efficiently translate your models from prototypes \nto production.\nVertex Pipelines is also the platform behind all the managed tuning and evaluation services \nfor the Google Foundation Models on Vertex AI. This ensures consistency as you can \nconsume and extend those pipelines easily, without having to familiarize yourself with \nmany services.\nGetting started with Vertex Pipelines is simple: you define the pipeline\u2019s step sequence in \na Python file utilizing Kubeflow SDK.67 For further details and comprehensive onboarding, \nconsult the official documentation.68", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 998, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e6bf13d4-8d19-44a2-ad6a-36e4f5aa3e0b": {"__data__": {"id_": "e6bf13d4-8d19-44a2-ad6a-36e4f5aa3e0b", "embedding": null, "metadata": {"page_label": "52", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ad1b552-06a1-4bcf-b641-c17c4995b3db", "node_type": "4", "metadata": {"page_label": "52", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e4c2bd082b4fa51a7edeccc083c96e014d68828627a85dd02458bcf153795af9", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n52\nSeptember 2024\nChain & Augment: Vertex AI Grounding, Extensions, and RAG \nbuilding blocks\nBeyond training, tuning and adapting models and prompts directly, Vertex AI offers a \ncomprehensive ecosystem for augmenting LLMs, to address the challenges of factual \ngrounding and hallucination. The platform incorporates emerging techniques like RAG and \nagent-based approaches.\nRAG overcomes limitations by enriching prompts with data retrieved from vector databases, \ncircumventing pre-training requirements and ensuring the integration of up-to-date \ninformation. Agent-based approaches, popularized by ReAct prompting, leverage LLMs as \nmediators interacting with tools like RAG systems, APIs, and custom extensions. Vertex AI \nfacilitates this dynamic information source selection, enabling complex queries, real-time \nactions, and the creation of multi-agent systems connected to vast information networks for \nsophisticated query processing and real-time decision-making.\nVertex AI function calling69 empowers users by enhancing the capabilities of language \nmodels (LLMs). It enables LLMs to access real-time data and interact with external systems, \nproviding users with more accurate and up-to-date information. To do that, users need to \nprovide function definitions such as description, inputs, outputs to the gen AI model. Instead \nof directly executing functions, the LLM intelligently analyzes user requests and generates \nstructured data outputs. These outputs propose which function to call and what arguments \nto use.\nVertex AI Grounding5 helps users connect large models with verifiable information by \ngrounding them to internal data corpora on Vertex AI Agent Builder70 or external sources \nusing Google Search. This enables two key functionalities: verifying model-generated outputs \nagainst internal or external sources and creating RAG systems using Google\u2019s advanced \nsearch capabilities that produce quality content grounded in your own or web search data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2035, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "649bbc92-dc02-40a6-aa85-aac0aef9de61": {"__data__": {"id_": "649bbc92-dc02-40a6-aa85-aac0aef9de61", "embedding": null, "metadata": {"page_label": "53", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93b01571-6a44-4819-96f7-d84f3de12661", "node_type": "4", "metadata": {"page_label": "53", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "036d60c15129df447bf6cf09030bdc5709004909eba1cee92f1bbfd00a151389", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n53\nSeptember 2024\nVertex AI extensions 6 let developers integrate Vertex Foundation Models with real-time \ndata and real-world actions through APIs and functions, enabling task execution and allowing \nenhanced capabilities. This extends to leveraging 1st party extensions like Vertex AI Search7 \nand Code Interpreter,71 or 3rd party extensions for triggering and completing transactions. \nImagine building an application that leverages the LLM's knowledge to plan a trip and \nseamlessly utilizes internal APIs to book hotels and flights, all within a single interface. \nAdditionally, Vertex Extensions facilitate function calling with the gemini-pro model, enabling \nyou to generate descriptions, pass them to the large model, receive JSON with function \narguments, and automatically call the function.\nVertex AI Agent Builder70 is an out-of-the-box solution that allows you to quickly build gen \nAI agents, to be used as conversational chatbots or as part of a search engine. With Vertex \nAI Agent Builder, you are be able to easily ground your agents by pointing to a diverse range \nof data sources, including structured datastores such us BigQuery, Spanner, Cloud SQL, \nunstructured sources like website content crawling and cloud storage as well as connectors \nto Google drive and other APIs. Agent Builder utilizes a robust foundation of Google Search \ntechnologies, encompassing semantic search, content chunking, ranking, algorithms, \nand user intent understanding. Under the hood it optimizes document loading, chunking, \nembedding models, and ranking strategies. It abstracts away these complexities and allows \nusers to simply specify their data source to initiate the gen AI-powered agent.This approach \nis ideal for organizations seeking to build robust search experiences for standard use cases \nwithout extensive technical expertise. \nVector databases are specialized systems for managing multi-dimensional data. This data, \nencompassing images, text, audio, video, and other structured or unstructured formats, \nis represented as vectors capturing its semantic meaning. Vector databases accelerate \nsearching and retrieval within these high-dimensional spaces, enabling efficient tasks like \nfinding similar images from billions or extracting relevant text snippets based on various", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2354, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2630ac98-8b4a-4cf4-9752-f9296f4dad22": {"__data__": {"id_": "2630ac98-8b4a-4cf4-9752-f9296f4dad22", "embedding": null, "metadata": {"page_label": "54", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "960b3455-de29-40f9-bec4-fe285ff0e3a8", "node_type": "4", "metadata": {"page_label": "54", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b142fe561eaf701067db531ea8c5851e05a5b79bd37ffbd87b935cd648e78384", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n54\nSeptember 2024\ninputs. For a deeper dive into these topics, refer to 4 and 19. Vertex AI offers three flexible \nsolutions for storing and serving embeddings at scale, catering to diverse use cases and \nuser profiles.\nVertex AI Vector Search7 is a highly scalable low-latency similarity search and fully \nmanaged vector database scaling to billions of vector embeddings with auto-scaling. This \ntechnology, built upon ScaNN72 (a Google-developed technology used in products like \nSearch, YouTube, and Play), allows you to search from billions of semantically similar or \nrelated items within your stored data. In the context of gen AI, the most common use cases \nwhere Vertex Vector Search can be used are:\n1. Finding similar items (either text or image) based solely on their semantic meaning, in \nconjunction with an embedding model.\n2. Creating a hybrid search approach that combines semantic and keyword or metadata \nsearch to refine the results.\n3. Extracting relevant information from the database to feed into LLMs, enabling them to \ngenerate more accurate and informed responses.\nVertex AI Vector Search primarily functions as a vector database for storing pre-generated \nembeddings. These embeddings must be created beforehand using separate models like \nVertex Embedding models73 (namely textembedding-gecko, text-embedding-gecko-\nmultilingual, or multimodalembedding). Choosing Vertex Vector Search is optimal \nwhen you require control over aspects like the chunk, retrieval, query and models strategy. \nThis includes fine-tuning an embedding model for your specific data. However, if your use \ncase is a standard one requiring little customization, a readily available solution like Vertex \nSearch might be a better choice.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1794, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b158531-5e1c-4084-b0bd-9c0046a5c9e8": {"__data__": {"id_": "1b158531-5e1c-4084-b0bd-9c0046a5c9e8", "embedding": null, "metadata": {"page_label": "55", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cd9511fd-4575-4787-849b-d5114ca1238b", "node_type": "4", "metadata": {"page_label": "55", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2d991b52037b391d179015e0a26a18a758646e1a1e994bf95b4b8fa46669c656", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n55\nSeptember 2024\nVertex AI Feature Store 74 is a centralized and fully managed repository for ML features \nand embedding. It enables teams to share, serve, and reuse machine learning features and \nembeddings effortlessly alongside other data. Its native BigQuery23 integration eliminates \nduplication, simplifies lineage tracking and preserves data governance. Vertex AI Feature \nStore supports offline retrieval and an easy and fast online serving for machine learning \nfeatures and embeddings. Vertex AI Feature Store is a good choice when you want to iterate \nand maintain different embedding versions alongside other machine learning features in a \nsingle place.\nVertex AI offers the flexibility to seamlessly create and connect various products to build \nyour own custom grounding, RAG, and Agent systems. This includes utilizing diverse \nembedding models (multimodal, multilingual), various vector stores (Vector Search, Feature \nStore) and search engines like Vertex AI Agent Builder, extensions, grounding, and even SQL \nquery generation for complex natural language queries. Moreover, Vertex AI provides SDK \nintegration with LangChain9 to easily build and prototype applications using the umbrella \nof Vertex AI products. For further details and integration information, consult the official \ndocumentation75 and official examples.76\nEvaluate: Vertex AI Experiments, Tensorboard, & \nevaluation pipelines\nIn the dynamic world of gen AI, experimentation and evaluation are the cornerstones of \niterative development and continuous improvement. With a multitude of variables influencing \nGen AI models (prompt engineering, model selection, data interaction, pretraining, \nand tuning), evaluation goes hand-in-hand with experimentation. The more seamlessly \nexperiments and evaluations can be integrated into the development process, the", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1901, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "24953547-4889-4cb7-8ab1-85f7cb1b9faf": {"__data__": {"id_": "24953547-4889-4cb7-8ab1-85f7cb1b9faf", "embedding": null, "metadata": {"page_label": "56", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "707e85d0-463c-4259-81b7-634665797bed", "node_type": "4", "metadata": {"page_label": "56", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "aca2a1cae11275df10defab2181e55d28479d2bd7b4d5c0c29f53ad0325c3f55", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n56\nSeptember 2024\nsmoother and more efficient the overall development becomes. Vertex AI provides cohesive \nexperimentation and evaluation products permitting connected iterations over applications \nand models alongside their evaluations.\nExperiment\nThe process of selecting, creating, and customizing machine learning (including large \nmodels) and its applications involves significant experimentation, collaboration, and iteration. \nVertex AI seamlessly integrates experimentation and collaboration into the development \nlifecycle of AI/ML and gen AI models and applications. Its Workbench Instances77 provide \nJupyter-based development environments for the entire data science workflow, connected \nto other Google Cloud services and with GitHub synchronization capabilities. Vertex Colab \nEnterprise78 accelerates the AI workflow by enabling collaborative coding and leveraging \ncode completion and generation features.\nVertex AI also provides two tools for tracking and visualizing the output of many experiment \ncycles and training runs. Vertex AI Experiments79 facilitates meticulous tracking and \nanalysis of model architectures, hyperparameters, and training environments. It logs \nexperiments, artifacts, and metrics, enabling comparison and reproducibility across multiple \nruns. This comprehensive tracking permits data scientists to select the optimal model \nand architecture for their specific use case. Vertex AI TensorBoard80 complements the \nexperimentation process by providing detailed visualizations for tracking, visualizing, and \nsharing ML experiments. It offers a range of visualizations, including loss and accuracy \nmetrics tracking, model computational graph visualization, and weight and bias histograms, \nwhich - for example - can be used for tracking various metrics pertaining to training and \nevaluation of gen AI models with different prompting and tuning strategies. It also projects \nembeddings to lower-dimensional space, and displays image, text, and audio samples.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2058, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4fe8a12d-74c8-42a5-9c77-c3bb49b30cd4": {"__data__": {"id_": "4fe8a12d-74c8-42a5-9c77-c3bb49b30cd4", "embedding": null, "metadata": {"page_label": "57", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7af93020-9572-4c3e-a9eb-524373653695", "node_type": "4", "metadata": {"page_label": "57", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "59b18708ee5ca1656e281bef260e614af2e0968443633131805609db63dc54fc", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n57\nSeptember 2024\nEvaluation\nVertex AI also provides a comprehensive set of evaluation tools for gen AI, from ground truth \nmetrics to using LLMs as raters. \nFor Ground Truth-based metrics, Automatic Metrics in Vertex AI81 lets you evaluate a model \nbased on a defined task and \u201cground truth\u201d dataset. For LLM-based evaluation, Automatic \nSide by Side (Auto SxS) in Vertex AI82 uses a large model to evaluate the output of multiple \nmodels or configurations being tested, helping to augment human evaluation at scale. \nIn addition to that, users can also leverage Rapid Evaluation API, which offers a set of pre-\nbuilt metrics for evaluating gen AI applications and relative SDK, integrated into the Vertex \nAI Python SDK for rapid and flexible, notebook-based, prototyping. To get started with Rapid \nEvaluation Vertex AI SDK see example in the official documentation.83\nPredict: Vertex AI endpoints & monitoring\nOnce developed, a production gen AI application must be deployed, including all its model \ncomponents. If the application uses any models that have been trained or adapted, those \nmodels need to be deployed to their own serving endpoints. You can serve any model in the \nModel Garden through Vertex AI Endpoints21,which acts as the gateway for deploying your \ntrained machine learning models. They allow you to serve online predictions with low latency, \nmanage access controls, and monitor model performance easily through Model Monitoring. \nEndpoints also offer scaling options to handle varying traffic demands, ensuring optimal user \nexperience and reliability.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1636, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8e704d1-0ec2-45ed-bcb2-e2909ef7b71a": {"__data__": {"id_": "e8e704d1-0ec2-45ed-bcb2-e2909ef7b71a", "embedding": null, "metadata": {"page_label": "58", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7a201452-0449-4ee4-af26-a8050dac730a", "node_type": "4", "metadata": {"page_label": "58", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "9ac4597f512fb50deeeb5cb4d1f0c66af4b612cb2bee6585c9df50e9adf06cc0", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n58\nSeptember 2024\nAlong with the prediction service, Vertex AI offers the following features for all Google \nmanaged models:\n\u2022 Citation checkers: Gen AI on Vertex performs Citation checks71. Citations are important \nfor LLMs and gen AI for several reasons. Citing sources ensures proper acknowledgment \nof sources and prevents plagiarism and demonstrates transparency and accountability. \nCiting sources is essential for LLMs and gen AI also because they help identify, \nunderstand potential biases, and enable reproducibility and verification. For example in \nGoogle Cloud,84 the gen AI models are designed to produce original content, limiting the \npossibility of copying existing contents. If this happens, Google Cloud provides quotes for \nwebsites and code repositories. \n\u2022 Safety scores: Safety attributes are crucial for LLMs and gen AI to mitigate potential \nrisks like bias, lack of explainability, and misuse. These attributes help detect and mitigate \nbiased outputs and mitigate misuse, enabling these tools to be used responsibly. As \nLLMs and gen AI evolve, incorporating safety attributes will be increasingly essential for \nresponsible and ethical use. For example, Google Cloud added safety scores in Vertex \nAI PaLM API and Vertex AI Gemini API85: content processed through the API is checked \nagainst a list of safety attributes, including \"harmful categories\" and sensitive topics. Each \nattribute has a confidence score between 0.0 and 1.0, indicating the likelihood of the \ninput belonging to that category. These safety filters can be used in conjunction with all \nmodels: be it proprietary ones like Palm2 and Gemini or OSS ones like the ones available in \nModel garden.\n\u2022 Watermarking: With AI-based tools becoming increasingly popular for creation of \ncontent, it\u2019s very important to identify if an image has been created using AI. Vertex AI \noffers digital watermarking and verification for AI-generated images86 using the algorithm \nSynthID87 developed by Google DeepMind.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2057, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "090b31c6-2494-484c-a962-ee006cc21ffb": {"__data__": {"id_": "090b31c6-2494-484c-a962-ee006cc21ffb", "embedding": null, "metadata": {"page_label": "59", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "608e44ad-b3dc-4fd5-b28d-84231d51fe6a", "node_type": "4", "metadata": {"page_label": "59", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2feb4747e52ab33e454594e184104de6722b7be80c6f8c8e3dd31e7c072117c4", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n59\nSeptember 2024\n\u2022 Content moderation and bias detection: By using the Content moderation88 and Bias89 \ndetection tools on Vertex AI, you can add an extra layer of security on the responses \nof the LLMs to mitigate the risk that the model training and tuning may sway a model to \ngenerate outputs that aren\u2019t fair or appropriate for the task.\nGovern: Vertex AI Feature Store, Model Registry, \nand Dataplex\nAddressing the multifaceted requirements of data and model lineage and governance in \ngen AI requires a comprehensive strategy that tackles both conventional challenges and \nnovel regulatory or technical complexities associated with large models. By adopting robust \ngovernance, observability, and lineage practices in the development of gen AI solutions, \norganizations can ensure comprehensive tracking, iteration, and evolution of data. They \ncan also track the large models used, prompt adaptations, tuning, and other artifacts. This \nfacilitates reproducibility of results, transparency and understanding of generated content \nsources, troubleshooting, compliance enforcement, and enhanced reliability and security. \nThese practices collectively enable the ethical and responsible development and deployment \nof gen AI solutions. This fosters internal and external trust and fairness in gen AI models and \npractices. Vertex AI and Google Cloud offer the following comprehensive suite of tools for \nunified lineage, governance and monitoring, effectively addressing these critical concerns.\nIn the context of governance and lineage, Vertex AI Feature Store74 offers:\n\u2022 Track feature and embeddings versions and lineage, ensuring transparency\n\u2022 Monitor feature (prompt) and embedding, response drift, and identify potential \nissues proactively\n\u2022 Store feature formulas and discover relevant features or embeddings for different \nuse cases", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1905, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ed2479c3-543c-475a-9b60-a0f2874bdf9a": {"__data__": {"id_": "ed2479c3-543c-475a-9b60-a0f2874bdf9a", "embedding": null, "metadata": {"page_label": "60", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c9287b8-2123-4df3-a65d-c0f08ec9bfea", "node_type": "4", "metadata": {"page_label": "60", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "67fc6b6fd15db9b4f0d52722051686559da51be15ccd61fad26b49298495a9d5", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n60\nSeptember 2024\n\u2022 Utilize feature selection algorithms to optimize model performance\n\u2022 Consolidate and unify all machine learning data within a singular repository encompassing \nnumerical data, categorical data, textual data, and embeddings representations\nVertex AI Model Registry12 serves as a centralized repository for comprehensive lifecycle \nmanagement of both Google proprietary foundational and open-source Machine Learning \nmodels. This includes gen AI models in addition to predictive models. This unified platform \nenables registration, storage, and version control of diverse model types, including various \niterations of tuning for large models. Vertex AI Model Registry seamlessly integrates with \nVertex Pipelines,13 facilitating orchestration and management of training and tuning jobs \nwhile leveraging lineage capabilities for recording and documenting the lineage from \ndatasets to models and associated artifacts. It also couples with Vertex AI Experiments79 \nand Vertex AI Model Evaluation,90 enabling performance monitoring and comparison of \ndifferent model versions alongside their artifacts \u2013 all within a single interface. Furthermore, \nVertex AI Model Registry bolsters observability by providing integrated configuration and \naccess to Vertex AI Model Monitoring91 and logging functionalities. This enables proactive \nidentification and mitigation of both training-serving skew and prediction drift, ensuring \nreliability and accuracy of deployed models. Users can directly assign desired model versions \nto endpoints for one-click deployment from Vertex Model Registry or leverage aliases for \nsimplified deployment.\nGoogle Cloud Dataplex14 provides an organization-wide lineage across product boundaries \nin Google Cloud. Within the domains of AI and gen AI (and more broadly across data analytics \nand AI/ML) Dataplex seamlessly integrates with BigQuery and Vertex AI. Dataplex facilitates \nthe unification, management, discovery, and governance of both data and models. Through \ncomprehensive data lineage, quality, and metadata management capabilities it provides \nactionable insights for comprehensive data and model understanding. This promotes \ncompliance, facilitates data analysis, and guarantees the training of machine learning \nmodels on trusted data sources. This in turn leads to enhanced accuracy and reliability. This", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2421, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66e8f045-9da8-4b46-9274-894d73311c35": {"__data__": {"id_": "66e8f045-9da8-4b46-9274-894d73311c35", "embedding": null, "metadata": {"page_label": "61", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e1dd6a7b-de97-4fc4-b189-82d3542fe82e", "node_type": "4", "metadata": {"page_label": "61", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "982c002d8a4bf9894c4e8dc357c8a0b764ad86a4a4141d9e91017f4bb0bad5d7", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n61\nSeptember 2024\nintegration permits users across an organization to identify \u2018champion models\u2019 and \u2018golden \ndatasets and features\u2019 across projects and regions in a secure way by adhering to identity \naccess management (IAM)92 boundaries. In short, Dataplex encapsulates a framework within \nan organization that governs the interaction between people, processes and technology \nacross all the products in Google Cloud.\nConclusion\nThe explosion of gen AI in the last several years introduced fundamental changes in the way \nAI applications are developed \u2013 but far from upending the MLOps discipline, these changes \nhave only reinforced its basic principles and processes. As we have seen, the principles of \nMLOps that emphasize reliability, repeatability, and dependability in ML systems development \nare comfortably extended to include the innovations of gen AI. Some of the necessary \nchanges are deeper and more far-reaching than others, but nowhere do we find any change \nthat MLOps cannot accommodate.\nAs a result, many tools and processes built to support traditional MLOps can also support \nthe requirements of gen AI. Vertex AI, for instance, is a powerful platform that can be used to \nbuild and deploy machine learning models and AI applications. It provides a comprehensive \nsuite of functions for developing both Predictive and gen AI systems, encompassing data \npreparation, pre-trained APIs, AutoML capabilities, training and serving hardware,  advanced \nfine-tuning techniques and deployment tools, and a diverse selection of proprietary and \nopen-source foundation models. It also offers evaluation methods, monitoring capabilities, \nand governance tools, all unified within a single platform to streamline the AI development \nlifecycle. It\u2019s built on Google Cloud Platform, which provides a scalable, reliable, secure and \ncompliant infrastructure for machine learning. It\u2019s a good choice for organizations that want \nto build and deploy machine learning models and AI applications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2057, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e3a8a419-759f-4fb1-b7b2-583c11a7cd3c": {"__data__": {"id_": "e3a8a419-759f-4fb1-b7b2-583c11a7cd3c", "embedding": null, "metadata": {"page_label": "62", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3567dbe-48fa-486b-bdd7-9e8068e1394b", "node_type": "4", "metadata": {"page_label": "62", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "3fb9500ccc58c1aef4e2899b9d701b1d9009a3cafe4c249e2b09beff7b59fb1e", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n62\nSeptember 2024\nThe next few years will undoubtedly see gen AI extended in directions that today are \nunimaginable. Regardless of the direction these developments take, it will continue to \nbe important to build on solid engineering processes that embody the basic principles \nof MLOps. These principles support the development of scalable, robust production AI \napplications today, and no doubt will continue to do so into the future.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 494, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c420230c-42e4-4ebc-ba2e-613da876a762": {"__data__": {"id_": "c420230c-42e4-4ebc-ba2e-613da876a762", "embedding": null, "metadata": {"page_label": "63", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2d4a939-df28-47d2-a0a9-19e5e75878e8", "node_type": "4", "metadata": {"page_label": "63", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "35ee99f9ab3fdccb71ff1c89a3e19f1452ce4a8200312dcad4bd230f39562283", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n63\nSeptember 2024\nEndnotes\n1. Model Garden on Vertex AI. Available at: https://cloud.google.com/model-garden\n2. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, \nMaarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, \nJeff Dean, William Fedus. 2022. Emergent Abilities of Large Language Models. Available at: https://arxiv.org/\npdf/2206.07682.pdf\n3. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich \nK\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, Douwe Kiela. 2022. Retrieval-Augmented \nGeneration for Knowledge-Intensive NLP Tasks. Available at: https://arxiv.org/pdf/2005.11401.pdf\n4. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, Department of \nComputer Science, Princeton University, Google Research, Brain team, REACT: SYNERGIZING REASONING AND \nACTING IN LANGUAGE MODELS. Available at: https://arxiv.org/pdf/2210.03629.pdf\n5. Grounding in Vertex AI. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/grounding/\nground-language-models\n6. Vertex Extensions. Connect models to APIs by using extensions. Available at:  https://cloud.google.com/\nvertex-ai/docs/generative-ai/extensions/overview\n7. Overview of Vertex AI Vector Search. Available at: https://cloud.google.com/vertex-ai/docs/vector-search/\noverview\n8. What is Vertex AI Agent Builder? Available at: https://cloud.google.com/generative-ai-app-builder/docs/\nintroduction\n9. LangChain. Get your LLM application from prototype to production. Available at: https://www.langchain.\ncom/\n10. Introduction to the Vertex AI SDK for Python. Available at: https://cloud.google.com/vertex-ai/docs/python-\nsdk/use-vertex-ai-python-sdk\n11. Introduction to Vertex AI. Available at: https://cloud.google.com/vertex-ai/docs/start/introduction-unified-\nplatform\n12. Introduction to Vertex AI Model Registry. Available at: https://cloud.google.com/vertex-ai/docs/model-\nregistry/introduction", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2127, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e10f41c0-d908-4d5d-88e7-85a320b9b893": {"__data__": {"id_": "e10f41c0-d908-4d5d-88e7-85a320b9b893", "embedding": null, "metadata": {"page_label": "64", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bba70202-ee19-4a9e-a90a-ce784c75e75f", "node_type": "4", "metadata": {"page_label": "64", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "782dc83165d4be3aafb2cb71eec6b045c62539e45c11d826b987f1b08b01b5e4", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n64\nSeptember 2024\n13. Introduction to Vertex AI Pipelines. Available at: https://cloud.google.com/vertex-ai/docs/pipelines/\nintroduction\n14. Dataplex. Available at: https://cloud.google.com/dataplex\n15. BigQuery. Available at: https://cloud.google.com/bigquery?hl=en\n16. PaLi-Gemma model card. Available at: https://ai.google.dev/gemma/docs/paligemma/model-card\n17. Version Control. Available at: https://en.wikipedia.org/wiki/Version_control\n18. Continuous integration. Available at: https://wikipedia.org/wiki/Continuous_integration\n19. TFX is an end-to-end platform for deploying production ML pipelines. Available at: https://www.tensorflow.\norg/tfx\n20. Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay \nKrishna, Chen-Yu Lee, Tomas Pfister. 2023. Distilling Step-by-Step! Outperforming Larger Language Models with \nLess Training Data and Smaller Model Sizes. Available at: https://arxiv.org/pdf/2305.02301.pdf\n21. Vertex Endpoints. Use private endpoints for online prediction. Available at: https://cloud.google.com/vertex-\nai/docs/predictions/using-private-endpoints\n22. Tuan Duong Nguyen, Marthinus Christoffel du Plessis, Takafumi Kanamori, Masashi Sugiyama, 2014. \nConstrained Least-Squares Density-Difference Estimation. Available at: https://www.ms.k.u-tokyo.ac.jp/\nsugi/2014/CLSDD.pdf\n23. Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Sch\u00f6lkopf, Alexander Smola, 2012. A Kernel \nTwo-Sample Test. Available at: https://jmlr.csail.mit.edu/papers/v13/gretton12a.html\n24. Oliver Cobb, Arnaud Van Looveren, 2022. Context-Aware Drift Detection. Available at: https://arxiv.org/\npdf/2203.08644.pdf\n25. Google Gemma Model. Available at: https://gemini.google.com/\n26. Perform metrics-based evaluation. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/\nmodels/evaluate-models\n27. Gemini Team, Google, 2023. Gemini: A Family of Highly Capable Multimodal Models. Available at: https://\nstorage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf\n28. Anil, Dai et al., 2023. PaLM 2 Technical Report. Available at: https://arxiv.org/abs/2305.10403", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2197, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4c4e489c-de2c-4721-9b92-48206b8a92a4": {"__data__": {"id_": "4c4e489c-de2c-4721-9b92-48206b8a92a4", "embedding": null, "metadata": {"page_label": "65", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bf8be6ab-1925-4318-bd95-8b59cc86e06d", "node_type": "4", "metadata": {"page_label": "65", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2b312adef1ffb3a2ae91f78c7d7cff915aca69acf3fc8c7cca428dda3c8894d5", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n65\nSeptember 2024\n29. Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed \nGhasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David \nJ Fleet, Mohammad Norouzi, 2022. Photorealistic Text-to-Image Diffusion Models with Deep Language \nUnderstanding. Available at: https://arxiv.org/abs/2205.11487\n30. Build the future of AI with Meta Llama 3. Available at: https://llama.meta.com/llama3\n31. Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, \nMostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun \nChen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, \nGaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff \nDean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, Jason Wei. 2022. Scaling Instruction-Finetuned \nLanguage Models. Available at: https://arxiv.org/abs/2210.11416\n32. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 2018. BERT: Pre-training of Deep \nBidirectional Transformers for Language Understanding. Available at: https://arxiv.org/abs/1810.04805\n33. Stable Diffusion. Available at: https://github.com/CompVis/stable-diffusion\n34. Vertex AI Function Calling. Available at: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/\nfunction-calling\n35. Mistral AI. Available at: https://mistral.ai/\n36. Models available in Model Garden. Available at: https://cloud.google.com/vertex-ai/docs/start/explore-\nmodels#available-models\n37. Vertex AI Studio. Customize and deploy generative models. Available at: https://cloud.google.com/\ngenerative-ai-studio\n38. vLLM. Easy, fast, and cheap LLM serving for everyone. Available at: https://github.com/vllm-project/vllm\n39. Overview of multimodal models. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/\nmultimodal/overview\n40. Text models. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text\n41. Imagen on Vertex AI | AI Image Generator. Available at: https://cloud.google.com/vertex-ai/docs/\ngenerative-ai/image/overview\n42. Code models overview. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-\nmodels-overview", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2434, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "080e6c27-223d-4020-95f1-e426c23eb52e": {"__data__": {"id_": "080e6c27-223d-4020-95f1-e426c23eb52e", "embedding": null, "metadata": {"page_label": "66", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f9ca9a4-f53e-4604-9a81-ca6f1170d8fd", "node_type": "4", "metadata": {"page_label": "66", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6a8d7a8b856dedea6733b3c73fdeadcec066d1fc08c8680992c4af5777c9a2ac", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n66\nSeptember 2024\n43. Convert speech to text. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/speech/\nspeech-to-text\n44. Text-to-Speech AI. Available at: https://cloud.google.com/text-to-speech\n45. Natural Language AI. Available at: https://cloud.google.com/natural-language\n46. Translate docs, audio, and videos in real time with Google AI. Available at: https://cloud.google.com/\ntranslate\n47. Vision AI. Available at: https://cloud.google.com/vision\n48. Git. Available at: https://git-scm.com/\n49. CodeGemma model card. Available at: https://ai.google.dev/gemma/docs/codegemma/model_card\n50. TII\u2019s Falcon. Available at: https://falconllm.tii.ae/\n51. Mistral AI. Available at: https://mistral.ai/\n52. Hugging Face, 2024. Vision Transformer (ViT) Documentation. Hugging Face, [online] Available at:   \nhttps://huggingface.co/docs/transformers/en/model_doc/vit\n53. Mingxing Tan, Quoc V. Le, 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. \nAvailable at: https://arxiv.org/abs/1905.11946\n54. Anthropic Claude 3. Available at: https://www.anthropic.com/news/claude-3-haiku\n55. Anthropic Claude 3 on Google Cloud Model Garden. Available at: https://cloud.google.com/blog/products/\nai-machine-learning/announcing-anthropics-claude-3-models-in-google-cloud-vertex-ai\n56. Vertex AI API. Available at: https://cloud.google.com/vertex-ai/docs/reference/rest\n57. Vertex AI: Python SDK. Available at: https://cloud.google.com/python/docs/reference/aiplatform/latest/\nvertexai\n58. Vertex AI: Node.js Client. Available at: https://cloud.google.com/nodejs/docs/reference/aiplatform/latest/\noverview\n59. Vertex AI for Java. Available at: https://cloud.google.com/java/docs/reference/google-cloud-aiplatform/\nlatest/overview\n60. Customize and deploy generative models. Available at: https://cloud.google.com/generative-ai-studio", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1922, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5dbe7476-03cd-4c71-91e5-3e74625ffbb2": {"__data__": {"id_": "5dbe7476-03cd-4c71-91e5-3e74625ffbb2", "embedding": null, "metadata": {"page_label": "67", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "30132288-07bb-430b-aab5-876ee7ec5820", "node_type": "4", "metadata": {"page_label": "67", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6ecf69bd738bec3e941fd2aee1d6c952f890f195cb05c0c670422f5d4cb308ca", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n67\nSeptember 2024\n61. Design text prompts. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-\nprompts\n62. Introduction to prompt design. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/learn/\nintroduction-prompt-design\n63. Supervised tuning. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-\nmodels#supervised-tuning\n64. RLHF model tuning. Available at: https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-text-\nmodels-rlhf\n65. Vertex AI Distilation. Available at: https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-\ntext-models\n66. Create distilled text models. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/models/\ndistill-text-models\n67. Pipeline Basics. Available at: https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/pipeline-\nbasics/\n68. Build a pipeline. Available at: https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline\n69. Vertex AI Search extension. Available at: https://cloud.google.com/vertex-ai/generative-ai/docs/\nextensions/vertex-ai-search\n70. What is Vertex AI Agent Builder? Available at: https://cloud.google.com/generative-ai-app-builder/docs/\nintroduction\n71. Generative AI on Vertex AI, Citation Check. Available at: https://cloud.google.com/vertex-ai/generative-ai/\ndocs/learn/overview#citation_check\n72. Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, and Sanjiv Kumar, 2020. \nAccelerating Large-Scale Inference with Anisotropic Vector Quantization. Available at: https://arxiv.org/\npdf/1908.10396.pdf\n73. Get text embeddings. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/\nget-text-embeddings\n74. About Vertex AI Feature Store. Available at: https://cloud.google.com/vertex-ai/docs/featurestore/latest/\noverview", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1912, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c5f693d-0707-4c34-85b2-9c0cdb28ae98": {"__data__": {"id_": "1c5f693d-0707-4c34-85b2-9c0cdb28ae98", "embedding": null, "metadata": {"page_label": "68", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0f84254f-7c00-4dad-aec8-286d2eb8b928", "node_type": "4", "metadata": {"page_label": "68", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "055468fce763611c627364e6d9c683da95dca6d67d49d09ec96835983f963e3b", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n68\nSeptember 2024\n75. Google Cloud Vertex AI. Available at: https://python.langchain.com/docs/integrations/llms/google_vertex_\nai_palm\n76. Generative AI - Language - LangChain. Available at: https://github.com/GoogleCloudPlatform/generative-\nai/tree/main/language/orchestration/langchain\n77. Introduction to Vertex AI Workbench, Workbench Instances. Available at: https://cloud.google.com/vertex-\nai/docs/workbench/introduction\n78. Introduction to Colab Enterprise. Available at: https://cloud.google.com/colab/docs/introduction\n79. Introduction to Vertex AI Experiments. Available at: https://cloud.google.com/vertex-ai/docs/experiments/\nintro-vertex-ai-experiments\n80. Vertex AI TensorBoard Introduction to Vertex AI TensorBoard. Available at https://cloud.google.com/vertex-\nai/docs/experiments/tensorboard-introduction\n81. Perform metrics-based evaluation. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/\nmodels/evaluate-models\n82. Perform automatic side-by-side evaluation. Available at: https://cloud.google.com/vertex-ai/docs/\ngenerative-ai/models/side-by-side-eval\n83. Rapid Evaluation Vertex AI. Available at: https://cloud.google.com/vertex-ai/generative-ai/docs/models/\nrapid-evaluation\n84. Citation metadata. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-\nai#citation_metadata\n85. Responsible AI. Available at: https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-\nai#filters-palm-api\n86. Imagen on Vertex AI | AI Image Generator. Available at: https://cloud.google.com/vertex-ai/docs/\ngenerative-ai/image/overview\n87. SynthID. Identifying AI-generated content with SynthID. Available at: https://deepmind.google/technologies/\nsynthid/\n88. Moderate text. Available at: https://cloud.google.com/natural-language/docs/moderating-text\n89. Model bias metrics for Vertex AI. Available at: https://cloud.google.com/vertex-ai/docs/evaluation/model-\nbias-metrics", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2003, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fa0b5bdb-ed2f-40a2-b2f3-0bcdc38a28de": {"__data__": {"id_": "fa0b5bdb-ed2f-40a2-b2f3-0bcdc38a28de", "embedding": null, "metadata": {"page_label": "69", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "358dfe1f-2289-48c4-9700-dc9410f1f9e7", "node_type": "4", "metadata": {"page_label": "69", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "ae40492e7b0df6b9817c165e647f4b62ce04b01658929757063dc99d99c12d9b", "class_name": "RelatedNodeInfo"}}, "text": "Operationalizing Generative AI on Vertex AI using ML Ops\n69\nSeptember 2024\n90. Model evaluation in Vertex AI. Available at: https://cloud.google.com/vertex-ai/docs/evaluation/\nintroduction\n91. Introduction to Vertex AI Model Monitoring. Available at: https://cloud.google.com/vertex-ai/docs/model-\nmonitoring/overview\n92. Identity and Access Management (IAM). Available at: https://cloud.google.com/iam/docs", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 407, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a7a29a4-3324-4a81-8b64-2f60bdc44dca": {"__data__": {"id_": "1a7a29a4-3324-4a81-8b64-2f60bdc44dca", "embedding": null, "metadata": {"page_label": "1", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "be290469-6ccf-4772-822e-cdb73f85f798", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "551fd0adc2e8e8a9d8003a5df980384d83f5a9a27e8f757fc3cf47c0fc194358", "class_name": "RelatedNodeInfo"}}, "text": "Solving  \nDomain-Specific \nProblems Using \nLLMs\nAuthors: Christopher Semturs,  \nShekoofeh Azizi, Scott Coull,  \nUmesh Shankar  \nand Wieland Holfelder", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 149, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b6859c2a-1eb0-40ca-b2b4-6d4aa51adcc5": {"__data__": {"id_": "b6859c2a-1eb0-40ca-b2b4-6d4aa51adcc5", "embedding": null, "metadata": {"page_label": "2", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9104a78a-b065-431e-aed9-dcc8d5c56ef6", "node_type": "4", "metadata": {"page_label": "2", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b25db53e4ff2a85c12825d6e9966e82bfae60f9fb64562b3bc61c73a444673bc", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n2\nSeptember 2024\nAcknowledgements\nReviewers and Contributors\nJohan Schalkwyk\nSami Lachgar\nDale Webster\nYun Liu\nConnie Fan\nChris Grier\nAntonio Gulli\nAnant Nawalgaria\nCurators and Editors\nAntonio Gulli\nAnant Nawalgaria\nGrace Mollison \nTechnical Writer\nKaren Lin\nDesigners\nMichael Lanning\nLuxi Chen", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 339, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73f351ee-347f-4fe0-81dd-e29889cac465": {"__data__": {"id_": "73f351ee-347f-4fe0-81dd-e29889cac465", "embedding": null, "metadata": {"page_label": "3", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2494b4a7-6242-48d8-b648-ae0c0e761b08", "node_type": "4", "metadata": {"page_label": "3", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "76c05465445d229cc51c6e5989b1c706a173627474fc44f2697dc16bbfb3af43", "class_name": "RelatedNodeInfo"}}, "text": "Introduction 4\nSecLM and the future of cybersecurity 5\n Challenges in cybersecurity  6\n How GenAI can tackle the challenges in cybersecurity 7\n SecLM: An API for cybersecurity tasks 10\n  Security-focused large language models 12\n  A flexible planning and reasoning framework 16\nMedLM and the future of health tech 20\n The potential for GenAI in medical Q&A 20\n The opportunities 21\n The scientific starting point 22\n  How to evaluate: quantitative and qualitative 24\n Evaluation in real clinical environments 30\n Task- vs. domain-specific models 31\n Training strategies for Med-PaLM 2 32\nSummary 35\nEndnotes 36\nTable of contents", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 628, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd9f3cdc-c05b-4433-ab7f-4af5f9ea5d5d": {"__data__": {"id_": "bd9f3cdc-c05b-4433-ab7f-4af5f9ea5d5d", "embedding": null, "metadata": {"page_label": "4", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ddc539bb-70b5-4830-bb31-ddfaeee6bb00", "node_type": "4", "metadata": {"page_label": "4", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "d9c6f2a66f9c81a15a331779444b2e6d75beccf73047ff74552d844b845b3d51", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n4\nSeptember 2024\nIntroduction\nLarge language models (LLMs) have emerged as powerful tools for tackling complex \nchallenges in numerous domains. While early iterations focused on general-purpose tasks, \nrecent developments have highlighted the potential of fine-tuning LLMs to address specific \nproblems within specialized fields. This whitepaper explores these concepts in two distinct \ndomains: cybersecurity and medicine. Each showcases the unique ability of LLMs to enhance \nexisting workflows and unlock new possibilities.\nCybersecurity presents a number of unique challenges for LLMs, including a scarcity of \npublicly available data, a wide diversity of highly technical concepts, and information about \nthreats that change on a daily basis. Additionally, sensitive use cases, like malware analysis, \nnecessitate specific considerations for model development. We address these challenges \n... recent developments \nhave highlighted the potential \nof fine-tuning LLMs \nto address specific problems \nwithin specialized fields.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1073, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d76b5cc0-fc89-4323-a48b-b0cd49b7ae72": {"__data__": {"id_": "d76b5cc0-fc89-4323-a48b-b0cd49b7ae72", "embedding": null, "metadata": {"page_label": "5", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1e018e8d-7f33-45c8-a97f-0c270e86a69d", "node_type": "4", "metadata": {"page_label": "5", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "4ed25ff0ccf0c55d2470e8e4dfb58465d0cb5c43afd0527c532a4e0b8ee13fd4", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n5\nSeptember 2024\nby focusing on cybersecurity-specific content and tasks, pairing security-focused language \nmodels with a suite of supporting techniques to offer improved performance for vital tasks \nlike threat identification and risk analysis.\nIn the field of medicine, LLMs face a different set of obstacles, such as the vast and ever-\nevolving nature of medical knowledge and the need to apply said knowledge in a context-\ndependent manner that makes accurate diagnosis and treatment a continual challenge. \nLLMs like Med-PaLM, customized for medical applications, demonstrate the ability to answer \ncomplex medical questions and provide insightful interpretations of medical data, showing \npotential for supporting both clinicians and patients.\nThrough the lens of these two distinct domains, in this whitepaper we will explore the \nchallenges and opportunities presented by specialized data, technical language, and \nsensitive use cases. By examining the unique paths taken by SecLM and Med-PaLM, we \nprovide insights into the potential of LLMs to revolutionize various areas of expertise.\nSecLM and the future of cybersecurity\nSecurity practitioners face a myriad of challenges, including new and evolving threats, \noperational toil, and a talent shortage. Specialized Generative AI (Gen AI) can help address \nthese challenges by automating repetitive tasks, freeing up time for more strategic activities, \nand providing new opportunities to access knowledge.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1511, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3db29c44-d8fe-4791-864c-21d55ffdf44c": {"__data__": {"id_": "3db29c44-d8fe-4791-864c-21d55ffdf44c", "embedding": null, "metadata": {"page_label": "6", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5b12ffcf-f432-462b-a81f-fede63e40862", "node_type": "4", "metadata": {"page_label": "6", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e2d5b53c761b616c526e3c8a5f9fe1038c0865d6307cd63f4572685ad3810ff9", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n6\nSeptember 2024\nChallenges in cybersecurity \nIn the movies, we often see information security reduced to the caricature of hoodie-clad \nand headset-wearing hackers with ill intent, armed with ruggedized laptops, tapping away \nfuriously until we hear the two magic words: \u201cI\u2019m in.\u201d \nTo the extent that you even see the defenders, they are in reactive mode-think war rooms, \nempty coffee cups, people barking orders, and monitors showing the attacker\u2019s every move \nin real-time. \nThat is Hollywood; we live in the real world.\nIn reality, the people who practice cybersecurity - the developers, system administrators, \nSREs, and many junior analysts to whom our work here is dedicated - have the Sisyphean \ntask of keeping up with the latest threats and trying to protect complex systems against \nthem. Many practitioners\u2019 days are largely filled with repetitive or manual tasks, such as \nindividually triaging hundreds of alerts, that take valuable time away from developing more \nstrategic defenses. The momentum is definitely not in the defender\u2019s favor; attackers are \nadopting advanced technologies, including artificial intelligence,1 to extend their reach and \nquicken the pace of exploitation. And there are definitely no monitors showing the attacker\u2019s \nevery move!\nBased on our experience working with users and partners, we see three major challenges in \nthe security industry today: threats, toil, and talent. \n\u2022 New and evolving threats: The threat landscape is constantly changing, with new \nand increasingly sophisticated attacks emerging all the time. This makes it difficult for \ndefenders to keep up with the latest information, and conversely for practitioners to sift \nthrough that flood of data to identify what\u2019s relevant to them and take action.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1810, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3b8882e-8254-4d71-89fd-75062b41a559": {"__data__": {"id_": "f3b8882e-8254-4d71-89fd-75062b41a559", "embedding": null, "metadata": {"page_label": "7", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "723eca7e-9228-4bd0-9f8d-6d9d40ba18f3", "node_type": "4", "metadata": {"page_label": "7", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6c6d3055a13bd4b1fad864e533a65af2a098a7a6f87da1b40e5cc940078754d0", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n7\nSeptember 2024\n\u2022 Operational toil: People working in security operations or DevOps roles often spend a \nsignificant amount of time on repetitive manual tasks that could be automated or assisted. \nThis leads to overload and takes away time from more strategic activities. Excessive focus \non minutiae also prevents analysts and engineers from seeing the bigger picture that is \nkey to securing their organizations.\n\u2022 Talent shortage : There is a shortage of skilled security professionals, making it difficult \nfor organizations to find the people they need to protect their data and systems. Often, \npeople enter security-focused roles without much training and with little spare time to \nexpand their skills on the job.\nWithout the ability to address these three challenges, it will be difficult to keep up with the \ndemands of modern cybersecurity systems.\nHow GenAI can tackle the challenges in cybersecurity\nWe envision a world where novices and security experts alike are paired with AI expertise \nto free themselves from repetition and toil, accomplish tasks that seem impossible to us \ntoday, and provide new opportunities to share knowledge. Large language models (LLMs) \nand adjacent GenAI techniques can meaningfully improve the working lives of both security \nnovices and experienced practitioners. Indeed, in many cases, we have already found that \nGenAI is useful to solve a number of real-world security problems in our challenge areas:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1496, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "631815f3-6f55-4ff3-a987-c7025719bd13": {"__data__": {"id_": "631815f3-6f55-4ff3-a987-c7025719bd13", "embedding": null, "metadata": {"page_label": "8", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8b267e18-0194-4ebe-8f97-6ff008e0ab3d", "node_type": "4", "metadata": {"page_label": "8", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "9b6f43996108463a285df73e6151dc73e3d8476520649744aca877b4f82b4ecf", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n8\nSeptember 2024\nPersona(e) Challenges faced How Gen AI can help\nSecurity analyst\nAnalysts not familiar with \neach tool\u2019s bespoke schema \nand query language.\nTranslate natural-language \nqueries into a domain-specific \nsecurity event query language and \nrules language.\nInvestigating, clustering, and \ntriaging incoming alerts is \ntime-consuming and requires \nmultiple steps and tools.\nAutonomous capabilities to \nperform investigation, grouping, \nand classification, incorporating \ncontext and real-time tool use.\nHard to assemble the right \nseries of tailored steps to \nremediate an issue.\nPersonalized, case-specific \nremediation planning in \nuser environments.\nThreat Researcher or \nSystem Administrator\nAn unknown and obfuscated \nartifact (such as a script \nor binary) is discovered \nand can\u2019t be easily \nanalyzed manually.\nAutomated reverse engineering \nwith LLM-powered code analysis \nwith tool use for de-obfuscation \nand decompilation. Explain, \nanalyze, and classify potentially \nmalicious artifacts.\nCISO team\nManual work required to \nidentify and summarize the \nmost likely threats facing \nthe organization.\nGenerate a readable document \nor slide deck, applying the latest \nthreat intelligence and findings \nfrom security tools to the \nspecific organization.\nIT Administrator \nDedicated Security Team\nHard to understand all the \nways an attacker could \naccess sensitive resources.\nIdentify potential or actual attack \npaths, highlighting key elements \nand remediations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1524, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "debff26c-0158-41e1-a3f2-c0e189690213": {"__data__": {"id_": "debff26c-0158-41e1-a3f2-c0e189690213", "embedding": null, "metadata": {"page_label": "9", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de46e4c9-fbca-470d-bb91-19df4c033cac", "node_type": "4", "metadata": {"page_label": "9", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "59e5828479f8bef4fb177361fa7f1a2b04006e8bdb983e5d0ceb5764e85800e4", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n9\nSeptember 2024\nApplication Developers\nChallenging to determine \nthe right places to fuzz-test \nan application.\nIdentify which locations to \nfuzz-test and generate the \nappropriate code.\nApplication Developers & \nIT Administrators\nKeep access policies \naligned to the principle of \nleast privilege.\nGiven historical access patterns \nand current configuration, \nconstruct a configuration file \nmodification that grants a more \nminimal set of roles.\nA person responsible for an \napplication or system\nPeople don\u2019t always \nunderstand security concepts \nor how to apply them to their \nenvironments; they have to \nknow how to break a problem \ndown, ask questions in many \nplaces, and then combine \nthem to obtain an answer.\nGive an answer that reflects \nauthoritative security expertise \nand, using integrations, is relevant \nto the user\u2019s working environment.\nTo tackle these problems in a meaningful and holistic way, however, we need a \nmulti-layered approach:\n\u2022 Top layer: existing security tools that understand the relevant context and data, and \ncan actuate necessary changes;\n\u2022 Middle layer: a security-specialized model API with advanced reasoning and \nplanning capabilities;\n\u2022 Bottom layer: datastores of authoritative security intelligence and \noperational expertise\nNotably, one of the key benefits of LLMs is their ability to process and synthesize vast \namounts of heterogenous data \u2013 an important capability in the increasingly siloed world \nof cybersecurity data. We seek to leverage that capability to solve challenging security", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1585, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "88370bfd-88a4-4ff9-94e7-6f69da65932b": {"__data__": {"id_": "88370bfd-88a4-4ff9-94e7-6f69da65932b", "embedding": null, "metadata": {"page_label": "10", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "45d23f52-e91d-4ff2-b915-372bd68bd59a", "node_type": "4", "metadata": {"page_label": "10", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "a9237f75efa4f442599bb9be2f65c4dfd027eb71c2cddf0cb1a5acb2b50e63a7", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n10\nSeptember 2024\nproblems, whether by assisting human analysts or through autonomous agents, by combining \nrelevant context and authoritative sources with a flexible planning framework in a single API, \nwhich we call SecLM.\nThis API offers rich planning capabilities that combine LLMs and other ML models, Retrieval-\nAugmented Generation (RAG) to ground results in authoritative data, and tool use to perform \nactions or look up relevant information. We argue that this holistic approach is critical \nbecause accuracy is so important in security and LLMs alone cannot inherently solve all \nsecurity problems.\nSecLM: An API for cybersecurity tasks\nOur vision of the SecLM API is to provide a \u2018one-stop shop\u2019 for getting answers to security \nquestions, regardless of their level of complexity. That is, the engineer or analyst can pose \nquestions and refer to data sources with natural language, and expect an answer that \nautomatically incorporates the necessary information. However, security problems often \nrequire a lot of information to be gathered and analyzed using domain-specific reasoning, \noften by experts across several disciplines.\nIdeally, one can ask the SecLM API a question in a zero-shot manner and get a high-quality \nresponse without fussing over prompting or manually integrating external data. In order to \nachieve this in a coherent and seamless manner, it is important to have a well-designed API \nthat interacts with LLMs and traditional ML models, the user\u2019s data, and other services to \naccurately complete the task at hand. Due to the complex nature of these security problems, \nwe must aim to address the following key requirements:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1706, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e0c48c32-d613-4722-b2b4-0808f821788e": {"__data__": {"id_": "e0c48c32-d613-4722-b2b4-0808f821788e", "embedding": null, "metadata": {"page_label": "11", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9d8c91ec-64e7-429d-8d0f-c4285a280d7c", "node_type": "4", "metadata": {"page_label": "11", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "08021980bba05157049b6bfeeef738fb8508bc148b4e46734e51778031cd9b7d", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n11\nSeptember 2024\n\u2022 Freshness: The model should be able to access the latest threat and vulnerability \ndata, which changes on a daily basis. Due to its cost and duration (often days), \nretraining the model on a daily or hourly basis to incorporate the latest data is not a \nfeasible approach.\n\u2022 User-specific data: The model should be able to operate on the user\u2019s own security \ndata within the user\u2019s environment without the risk of exposing that sensitive data \nto others or the infrastructure provider. This rules out any centralized training on \nuser data.\n\u2022 Security expertise: The model should be able to understand high-level security \nconcepts and terminology, and break them into manageable pieces that are useful \nwhen solving the problem. For instance, decomposing a high-level attack strategy (e.g., \nlateral movement) into its constituent components for search or detection.\n\u2022 User-specific data: The model should be able to reason about the provided security \ndata in a multi-step fashion by combining different data sources, techniques, and \nspecialized models to solve security problems.\nSecLM addresses these challenges through the use of security-specialized LLMs, traditional \nML models, and a flexible planning framework that enables dynamic use of tools and \ninteraction among multiple domain-specialized agents to reason over the provided data. \nHere, we will briefly discuss our approach to training security-specialized models and \ndesigning the planning framework that drives the SecLM API.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1559, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ae104ce2-6e4a-4c55-ab7e-24a9d31e074e": {"__data__": {"id_": "ae104ce2-6e4a-4c55-ab7e-24a9d31e074e", "embedding": null, "metadata": {"page_label": "12", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a6946c91-28e2-4802-a826-dd8d5f9a0bd5", "node_type": "4", "metadata": {"page_label": "12", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "4ed1941ba865b834e936dc197c47cc497e7b98d2a59691f993724b258ea255a7", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n12\nSeptember 2024\nSecurity-focused large language models\nOne of the things we observed in applying LLMs to security is that general-purpose models \ndidn\u2019t peform as well as we needed on some security tasks. The reasons for this fall into \nthree categories:\n\u2022 Lack of publicly available security data: LLMs are data-hungry, requiring large pre-\ntraining corpora for best results. At the same time, security data is sensitive so we cannot \nuse real security data in training. Moreover, what little data is available publicly is usually \nconcentrated on a small number of the most popular security products or on generic \nsecurity content that lacks connection to concrete application. \n\u2022 Limited depth of security content: Similarly, there is a certain highly technical language \nthat is used to talk about security or express security insights, often crossing disciplines \nfrom low-level computer science concepts to high-level policy and intelligence analysis. \nTo be effective, security LLMs must seamlessly blend this language, connect them to \ntheir underlying technical concepts, and synthesize relevant, accurate output for security \nanalysts and engineers to consume. While there are some high-quality, in-depth articles \nthat explain how to address well-known vulnerabilities or attacks, thousands of new \nthreats emerge each year.\n\u2022 Sensitive use cases: There are some use cases in security that general purpose models \ndo not handle by design such as abuse areas like malware or phishing. In most cases, \ngeneral-purpose LLMs would actively work to avoid incorporating such tasks or related \ndata for fear of increasing risk of misuse or abuse. However, these cases are crucial for \nsecurity practitioners looking to secure their systems, to analyze artifacts, or even for \ntesting purposes. \nTaken together, these challenges motivate the development of security-focused LLMs \nthat operate across as many security platforms and environments as the humans they will \nultimately support. To this end, we develop specialized LLMs that have been trained on a \nvariety of cybersecurity-specific content and tasks.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2161, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ab177ab-0e2d-425f-93f1-b176a6854972": {"__data__": {"id_": "0ab177ab-0e2d-425f-93f1-b176a6854972", "embedding": null, "metadata": {"page_label": "13", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c32ea6cc-0e53-4775-ae62-fe94952e1e8c", "node_type": "4", "metadata": {"page_label": "13", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "307a40460a398d2cf76120ce34285643120a65e3c1108a84f24c7255077b36ae", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n13\nSeptember 2024\nThis broad set of supported tasks means that we have to take into account multiple use \ncases and environments when making design decisions, such as choosing the model size and \ncomposition of training tasks. For example, an LLM with hundreds of billions of parameters \nmay maximize reasoning and abstraction capabilities, but might not be ideal for latency-\nsensitive or high-volume tasks, like summarizing and categorizing security events.\nTo ensure the model generalizes to new tasks and security products not directly visible in the \ntraining data, we have to be very careful with the training regime used to create the models. \nAs an example, consider that for many task areas, such as translating natural language into a \ndomain-specific query language, it is highly likely that any training data we have will contain \nonly a fraction of the eventual targets for our users. In this case, without careful curation \nof the training data, we may inadvertently eliminate the ability of the model to generalize \nto new tasks or data sources that are important to users. Likewise, some data sources are \nparticularly sensitive or proprietary and should not be included in generalized training of \nthe model. Instead, these data sources should be incorporated into a specialized derivative \nmodel (using a lightweight, parameter-efficient process) that does not degrade the overall \nperformance of the core security-specialized model.\nThe training process, shown in Figure 1, demonstrates how we leverage each phase of \ntraining to target specific tasks and types of data to balance performance, generalization, \nand separation of proprietary data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1709, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a007407-e225-47bf-aba1-2d39c8722779": {"__data__": {"id_": "4a007407-e225-47bf-aba1-2d39c8722779", "embedding": null, "metadata": {"page_label": "14", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f3eec094-2c81-49b2-af38-1405c8711455", "node_type": "4", "metadata": {"page_label": "14", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "085bb7020aeba0d808b204f42621027231fe88d725d4254c65b20c2f4832bc74", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n14\nSeptember 2024\nFigure 1. High-level training flow for core SecLM and specialized derivative models \nAs pre-training is the most expensive and time-consuming stage, it makes sense to start \nfrom a robust foundational model with exposure to the broadest set of training data possible, \nincluding billions or even trillions of tokens of general text, code, and structured data across \ndozens of languages and formats. This gives us the added benefit of multilingual support, \nwhich is an important feature for threat intelligence use cases and international users.\nFrom this foundational model, we apply a phase of continued pre-training where we \nincorporate a large collection of open source and licensed content from security blogs, \nthreat intelligence reports, detection rules, information technology books, and more. This \nhelps develop the specialized language and core technology understanding necessary to", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 958, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e380fc18-9380-45d3-87e8-a6596a2dd173": {"__data__": {"id_": "e380fc18-9380-45d3-87e8-a6596a2dd173", "embedding": null, "metadata": {"page_label": "15", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a1f06841-cabd-4417-99d8-39e9af0c7946", "node_type": "4", "metadata": {"page_label": "15", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c1055cd6177bd432aa3d989e1e3bdfc57eb138cbba28642dca44cd3273ef90fd", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n15\nSeptember 2024\nperform the broad range of tasks that SecLM models will be trained on in the supervised \nfine-tuning phase. Here, proprietary data is compartmentalized within specific tasks that \nmirror those performed by security experts on a day-to-day basis, including analysis of \nmalicious scripts, explanation of command line invocations, explanation of security events, \nsummarization of threat intelligence reports, and generation of queries for specialized \nsecurity event management technologies.\nGiven the diversity of downstream tasks that are expected of the model, evaluating its \nperformance can be a challenging exercise, particularly when some categories of tasks may \nexperience inherent trade-offs. For this reason, the fine-tuned model is evaluated using a \nnumber of complementary methods. Several of our downstream tasks, such as malware \nclassification and certain types of simple security-focused question answering, can be \nframed as classification problems and a standard battery of classification metrics can be \nused to concretely quantify the performance on those tasks. For other, less quantifiable \ntasks, we can leverage a set of golden responses that we can use to calculate similarity-\nbased metrics (e.g., ROUGE,2 BLEU,3 BERTScore4), but we can also compare across models \nusing automated side-by-side preference evaluations using a separate (oftentimes larger) \nLLM. Finally, given the highly technical nature of security problems and the importance of \naccuracy in our tasks, we rely on expert human evaluators to score outputs using a Likert \nscale and side-by-side preference evaluation. Taken together, these metrics provide us with \nthe guidance needed to ensure our fine-tuning training has improved overall model quality, \nand help us direct future changes in model training.\nAt the conclusion of the fine-tuning stage, we have a model capable of performing many \nof the same core tasks as security experts. However, because of our need to ensure \ngeneralization across a wide range of user environments and the inherent trade-off among \nsome security tasks, the model may still require the use of in-context learning examples, \nretrieval-augmented generation, and parameter-efficient tuning (PET) methods. For example, \nif a new user wanted to leverage SecLM to query and analyze data on a new security platform", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2401, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ee076983-e37e-4007-889b-4da07f01b33c": {"__data__": {"id_": "ee076983-e37e-4007-889b-4da07f01b33c", "embedding": null, "metadata": {"page_label": "16", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "353282f2-6e8c-41db-ba7c-8d2a120d9a6c", "node_type": "4", "metadata": {"page_label": "16", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "1609141b1c2908100be6d95af1b7b5a18ad9f471c8866798313e59e3d2ee5acc", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n16\nSeptember 2024\nthat was not present during core training, it is likely that the model may need in-context \nexamples to help generalize to the new system. Similarly, if a user wanted to incorporate \nspecialized knowledge about their network and assets or better align model behavior with \nhuman security experts, it would be best added via PET adapters trained on their sensitive \ndata. Retrieval-augmented generation, meanwhile, allows us to pull in the freshest and most \nrecent threat information for the model to process, rather than relying on stale data ingested \nduring less frequent training runs.\nA flexible planning and reasoning framework\nAs you might imagine, actually building the underlying framework that orchestrates the \nplanning and execution of these complex tasks requires solving some difficult systems \nengineering and machine learning challenges. The example, shown in Figure 2, illustrates how \nSecLM's specialized models can be tied into a broader ecosystem to best leverage fresh, \nuser-specific data and authoritative security expertise in a natural and seamless way.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1140, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d7f5b0f3-f113-489c-8325-61d624761d96": {"__data__": {"id_": "d7f5b0f3-f113-489c-8325-61d624761d96", "embedding": null, "metadata": {"page_label": "17", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "81c46c2f-f5b8-488f-94b9-04c8b701e91f", "node_type": "4", "metadata": {"page_label": "17", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e55faabb8641cb83e032750baa8aae501d5b569bf7a5121eb7040256f41ffe71", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n17\nSeptember 2024\nFigure 2. SecLM platform leveraging multi-step reasoning to answer a broad, high-level question about \nadvanced persistent threat actor activity \nIn Figure 2, we have a fairly broad, high-level question regarding the tactics, techniques, and \nprocedures (TTPs) of an advanced persistent threat (APT) group, in this example \u2018APT41\u2019. The \nanalyst asking this question needs to understand what those TTPs are and discover potential \nindications of them in their own network. To answer this question, the SecLM API needs to \ninvoke a complex, multi-step planning process to break down the problem into individual \ntasks: 1) Retrieve the necessary information, 2) Extract and synthesize that information, 3) \nUse the information to query the relevant events from the user\u2019s Security Information and \nEvent Management (SIEM) product. In the SecLM reasoning framework, this plan can be \ngenerated statically by security experts or in real-time through a combination of expert \nguidance and highly-capable LLMs using chain-of-thought style prompting.\nFirst, the SecLM API planner retrieves the most recent information about \u201cAPT41\u201d from one of \npossibly many of the user\u2019s threat intelligence subscriptions. That raw response is processed \nto extract TTP information and possible indicators of compromise from the voluminous threat", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1385, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "928f7407-bcb2-419c-a06e-2dd430273c12": {"__data__": {"id_": "928f7407-bcb2-419c-a06e-2dd430273c12", "embedding": null, "metadata": {"page_label": "18", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4ba529ee-24ce-4d40-a383-4abe570a17fd", "node_type": "4", "metadata": {"page_label": "18", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "0b9484ec8dbaae1c5f467fe5cecf1262e989698dfe8357042cee468d741c40c5", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n18\nSeptember 2024\nintelligence data. Next, a specialized SecLM fine-tuned (using PET) for the query language \nof the SIEM is used to translate those TTPs into concrete clauses in the appropriate syntax \nand using the appropriate schema. Using that query, the API can then directly retrieve \nthe matching security events from the SIEM, and finally use SecLM to aggregate all of the \navailable information into a comprehensible final response for the analyst.\nOverall, the SecLM API would save the analyst in the above example substantial time - \npossibly hours - by automating multiple tedious steps across several different security \nservices and systems. Meanwhile, the analyst\u2019s time and attention are available to consider \nthe results and plan for follow-up investigations or remediation steps, which may also be \nassisted by the SecLM API. While this is one example of how the SecLM API automatically \nplans and orchestrates operations across multiple models and retrieval sources, there are \na multitude of such use cases where tool use (e.g., code execution), retrieval-augmented \ngeneration, specialized models, and long-term memory (e.g., storage of user preferences) \ncan help solve challenging security problems and answer difficult questions that save users \nvaluable time, even autonomously with the use of agents..\nThe prompt and response shown in Figure 3 provide another concrete example of how the \nSecLM API can leverage multiple tools and models to solve an otherwise time-consuming \nproblem for security analysts and system administrators alike, in this case by automatically \ndecoding and analyzing a PowerShell script for malicious activity.  To demonstrate the value \nof our platform, we recently completed a side-by-side analysis with security operations \nand threat intelligence experts, where we compared the end-to-end SecLM platform \nagainst standalone, general-purpose LLMs on cybersecurity-focused tasks, such as attack \npath analysis, alert summarization, and general security question answering similar to the \nPowerShell example shown here. The results demonstrated a clear preference for SecLM, \nwith win rates between 53% and 79% across the security-focused tasks, and underscore the \nimportance of a full-featured platform in the domain of cybersecurity.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2334, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1ab090f7-ad53-45ea-b23b-40e876d583cd": {"__data__": {"id_": "1ab090f7-ad53-45ea-b23b-40e876d583cd", "embedding": null, "metadata": {"page_label": "19", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "92837e06-1311-4cba-be99-892076ce9e63", "node_type": "4", "metadata": {"page_label": "19", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "193ed535f53fc5a88d165b441bd9010141e5458429f68cc59e4add3617e65ed3", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n19\nSeptember 2024\nFigure 3. An example response from the SecLM platform using a base64 decoding tool and the SecLM model \nto analyze an obfuscated PowerShell command used in a \u2018living off the land\u2019 attack \nIn this section, we have seen how a holistic approach that combines large language models \n(LLMs) and authoritative data sources with a flexible planning framework can help security \npractitioners by gathering, aggregating, and intelligently processing security data. We have \nalso seen how SecLM and its supporting infrastructure are being built to provide a one-stop \nsecurity platform for experts, junior analysts, and systems administrators. These advances, \ncombined with human expertise, can transform the practice of security, obtaining superior \nresults with less toil for the people who do it.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 852, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f5619b14-2502-43d4-a51d-d9cbd49540f8": {"__data__": {"id_": "f5619b14-2502-43d4-a51d-d9cbd49540f8", "embedding": null, "metadata": {"page_label": "20", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f26af394-5cc0-4b30-83f0-20505833574c", "node_type": "4", "metadata": {"page_label": "20", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "325edece0813e4744b3bd129e298e5c0080aa443bb55e6387f1f781af67ef161", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n20\nSeptember 2024\nMedLM and the future of health tech\nRecent advances in AI for natural language processing (NLP) and foundation models have \nenabled rapid research into novel capabilities in the medical field. This section will dive \ndeeper into the challenges of the medical field, and how MedLM solutions can help here - a \nfamily of foundation models fine-tuned for the healthcare industry. In particular, this section \nillustrates how it started with a specific GenAI model, Med-PaLM, to address these needs.\nThe potential for GenAI in medical Q&A\nMedical question-answering (QA) has always been a grand challenge in artificial intelligence \n(AI). The vast and ever-evolving nature of medical knowledge, combined with the need for \naccurate and nuanced reasoning, has made it difficult for AI systems to achieve human-level \nperformance on medical QA tasks.\nHowever, large language models (LLMs) trained on massive datasets of text have shown \npromising results on a variety of medical QA benchmarks. LLMs are able to understand and \napply complex medical concepts in a way that was not possible for previous generations of \nAI systems.\nIn addition, the increasing availability of medical data and the growing field of medical NLP \nhave created new opportunities for innovation in medical QA. Researchers are now able to \ndevelop systems that can answer medical questions from a variety of sources, including \nmedical textbooks, research papers, and patient records.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1515, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "976ececb-a1f9-42e8-aae4-3aec9990b821": {"__data__": {"id_": "976ececb-a1f9-42e8-aae4-3aec9990b821", "embedding": null, "metadata": {"page_label": "21", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "494f3bca-2271-4319-a456-0fdf6d8065ce", "node_type": "4", "metadata": {"page_label": "21", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e1d3c5e117841eef7f2571c31094bddc089c12a6c1b1ed40d778cb6d71b73334", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n21\nSeptember 2024\nThis combination of technical capabilities and data availability provides the groundwork for \nmodels like Med-PaLM, an LLM aligned and fine-tuned based on the PaLM family of models. \nThe development of Med-PaLM is only the start of a journey with the goal of improving health \noutcomes by making the technology available to researchers, clinicians, and other users.\nThe opportunities\nGen AI has the potential to fundamentally transform the medical field in both diagnostic and \nnon-diagnostic aspects, in numerous ways. For example:\n\u2022 Empowering users to ask questions in the context of the medical history in their health \nrecord such as \u201cwhat are good weekend activities for me to consider, given the surgery I \nunderwent two weeks ago?\u201d\n\u2022 Triaging of incoming messages to clinicians from patients by comprehensively \nunderstanding the urgency and categorizing the type of incoming message given the \nfull context of the patient's health history, and flagging or prioritizing the message \nappropriately. \n\u2022 Enhancing the patient intake process by moving beyond a fixed set of questions and \ninstead adapting based on the patient's responses. This allows for more efficient and \ncomprehensive data collection and provides a more cohesive summary to the clinical staff. \n\u2022 Implementing a technology that actively monitors patient-clinician conversations and \nprovides actionable feedback to the clinician, helping them understand what they \ndid great in the interaction and where they might want to improve. Similarly, the same \ntechnology can help the patient with any questions they might have for the clinician before \nconcluding their visit.\n\u2022 Enabling clinicians to better tackle unfamiliar scenarios or diseases by providing an on-\ndemand curbside consult or reference materials, similar to having a colleague available for \nconferences as needed.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1915, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cf14914a-fff7-412e-8393-809dc5fafc35": {"__data__": {"id_": "cf14914a-fff7-412e-8393-809dc5fafc35", "embedding": null, "metadata": {"page_label": "22", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3520f5f-7631-46f0-9ef7-5b6c9d3345a9", "node_type": "4", "metadata": {"page_label": "22", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "fdaafaaf390f159c8f704410ae419de59abf5ffab78bcd9a03bde6f8b142de5a", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n22\nSeptember 2024\nThis list represents merely a small selection from a vast array of possibilities, illustrating the \nextensive range of options previously considered unattainable with earlier technologies.\nThe field of medicine also serves as a use case with a strong culture and need for \nresponsible innovation. Medical applications are regulated due to the importance of patient \nsafety. While GenAI systems can be used to develop new diagnostic tools, treatment plans, \nand educational materials, it is important to validate the safety and efficacy of such systems  \nbefore their implementation in clinical practice. This means that scientific experimentation \nrequires a thoughtful, phased approach with retrospective studies (i.e., using de-identified \ndata from past cases so that research does not impact patient care) happening before \nprospective studies (i.e., running the model on newly collected data in a specific setting of \ninterest, sometimes interventionally so that impact on patient care can be measured).\nThe scientific starting point\nMany AI systems developed for medicine today lack the ability to interact with users, but \ninstead produce structured outputs such as \u201cyes\u201d or \u201cno\u201d, or a numerical output. While this \ntype of output is useful in many scenarios for clinicians, this output is inflexible. Models also \nneed to be created for every application, which slows down innovation. \nIn our view,5 medicine revolves around caring for people, and needs to be human-centric. As \nsuch, an ambitious goal would be a flexible AI system that can interact with people and assist \nin many different scenarios while taking into account the appropriate context.              To \ncreate such a system, it is essential to incorporate a wide range of experiences, perspectives, \nand expertise when building AI systems. Data and algorithms should go       hand in hand with \nlanguage and interaction, empathy, and compassion.\nThe objective behind this project is to enhance the effectiveness, helpfulness, and safety     \nof AI models in medicine by incorporating natural language and facilitate interactivity for and \nbetween clinicians, researchers, and patients. To bring this vision to life, we took the initial", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2273, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fe64ef1c-efba-4215-80d5-deb91c59771c": {"__data__": {"id_": "fe64ef1c-efba-4215-80d5-deb91c59771c", "embedding": null, "metadata": {"page_label": "23", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cd075503-d9cf-4bb3-9481-09583649bff6", "node_type": "4", "metadata": {"page_label": "23", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "1d60478b4cdb8398f3bbef80762cb8e4c9e86a517943746e440091e83c0bc490", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n23\nSeptember 2024\nstep in reimagining conversational AI systems in medicine with Med-PaLM, Google's LLM \ndesigned to provide high-quality, authoritative answers to medical questions. The QA task \nin particular was a great candidate for starting the journey, as it combines evaluations of \nreasoning capabilities and understanding, and allows for extensive evaluations across many \ndimensions on the outputs.\nThe recent progress in foundation models,6 such as LLMs, as large pre-trained AI systems \nthat can be easily adapted for various domains and tasks presents an opportunity to \nrethink the development and use of AI in medicine on a broader scale. These expressive \nand interactive models hold significant potential to make medical AI more performant, safe, \naccessible, and equitable by flexibly encoding, integrating, and interpreting medical data \nat scale.\nHere is a description of how Med-PaLM improved over time:\n\u2022 Our first version of Med-PaLM, described in a preprint in late 2022 and published in \nNature in July 2023,7 was the first AI system to exceed the passing mark on US Medical \nLicense Exam (USMLE)-style questions.8 The study also evaluated long-form answers and \ndescribed a comprehensive evaluation framework.\n\u2022 In March 2023, Med-PaLM 2 was announced and described in a preprint.9 It demonstrated \nrapid advancements, both on USMLE-style questions and on long-form answers. Med-\nPaLM 2 achieves an accuracy of 86.5% on USMLE-style questions, a 19% leap over our \nown results from Med-PaLM. As evaluated by physicians, the model's long-form answers \nto consumer medical questions improved substantially compared to earlier versions of \nMed-PaLM or the underlying non-medically tuned base models. It also demonstrated \nhow fine-tuning and related techniques can truly harness the power of LLMs in a domain-\nspecific way.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1888, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2f882c53-92f7-48ac-85d6-b0995d56540b": {"__data__": {"id_": "2f882c53-92f7-48ac-85d6-b0995d56540b", "embedding": null, "metadata": {"page_label": "24", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "16bddd60-924b-49be-ac4e-47ed1ec16c5a", "node_type": "4", "metadata": {"page_label": "24", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "3e8da31cfa886b47364c8ec7a06779dfdc451852a3e71b6230a448ed740263d0", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n24\nSeptember 2024\nThese advances reflect our belief that innovation can take major strides in a short period of \ntime, and be done responsibly and with rigor.\nHow to evaluate: quantitative and qualitative\nDeveloping accurate and authoritative medical question-answering AI systems has been a \nlong-standing challenge marked by several research advances over the past few decades. \nWhile the task is broad and spans various dimensions including logical reasoning and the \nretrieval of medical knowledge, tackling USMLE-style questions has gained prominence \nas a widely acceptable and challenging benchmark for evaluating medical question \nanswering performance.\nFigure 4 shows an example of a USMLE-style question. Individuals taking the test are given \na concise patient profile that includes information such as their symptoms and prescribed \nmedications. A medical question is presented based on the provided scenario, and test-\ntakers are required to choose the correct response from multiple choices.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1049, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "78d46af4-260e-4f29-a892-ca71e980f634": {"__data__": {"id_": "78d46af4-260e-4f29-a892-ca71e980f634", "embedding": null, "metadata": {"page_label": "25", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5bb42c1b-8453-4511-a1ea-479edece2791", "node_type": "4", "metadata": {"page_label": "25", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "88e3088c324ebf15a19680f7f902bba6b5aa434288098f536ab11f8d59419192", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n25\nSeptember 2024\nFigure 4. An example of a USMLE-style question \nCorrectly answering the question requires the individual taking the test to comprehend  \nsymptoms, interpret a patient\u2019s test results, engage in intricate reasoning regarding the \nprobable diagnosis, and ultimately select the correct choice for the most suitable disease, \ntest, or treatment combination. In summary, a combination of medical comprehension and \nunderstanding, knowledge retrieval, and reasoning is vital for success. It takes years of \neducation and training for clinicians to develop the knowledge needed to consistently answer \nthese questions accurately.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 683, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c179165-43e4-4912-a59e-60f74cecf229": {"__data__": {"id_": "1c179165-43e4-4912-a59e-60f74cecf229", "embedding": null, "metadata": {"page_label": "26", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2bfa2de4-ecc3-4695-ad6f-0263ed955b84", "node_type": "4", "metadata": {"page_label": "26", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b5b62108755af7143fe5c182262b960a5713c0646d16454e3f29e3cb8f73fe7f", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n26\nSeptember 2024\nAs every clinician will attest to, merely passing the USMLE does not indicate proficiency \nin diagnosing or managing patients clinically. Instead, USMLE is a specific assessment \nof knowledge and reasoning based on concrete scenarios. Nevertheless, USMLE serves \nas a useful benchmark since the answer is typically documented and evaluation can be \nconducted programmatically at scale. This contributed to its historical popularity as a \nbenchmark in scientific research as a grand challenge in the past, which makes it so powerful \nto demonstrate how technology facilitates significant advancements.\nFigure 5. Med-PaLM 2 reached expert-level performance on the MedQA medical exam benchmark \nMed-PaLM was the first AI model to exceed the passing mark, reaching the performance of \n67%, and Med-PaLM 2 was the first AI model to reach 86.5%, which indicates expert-level \nperformance (Figure 5).\nCrucially, to establish a more meaningful connection to potential future developments and \nenable the detailed analysis required for real-world clinical applications, the scope of the \nevaluation methods proposed by Med-PaLM framework extends beyond mere accuracy in", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1222, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "04eb4a04-bd62-452e-8177-b224c82ecbf3": {"__data__": {"id_": "04eb4a04-bd62-452e-8177-b224c82ecbf3", "embedding": null, "metadata": {"page_label": "27", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "143dcd88-cbf4-4d68-87ce-219de80d9741", "node_type": "4", "metadata": {"page_label": "27", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e6471ccde72582bbd6ba0b8be025fccc8f42321bd508a2748e37b3ad46164e35", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n27\nSeptember 2024\nmultiple-choice questions. The evaluation extends to qualitative assessment of factuality, \nuse of expert knowledge in reasoning, helpfulness, health equity, and potential harm when \nproviding long-form answers to open-ended questions.\nThe rubric for evaluation by expert clinicians includes:\n\u2022 How does the answer relate to the consensus in the scientific and clinical community?\n\u2022 What is the extent of possible harm?\n\u2022 What is the likelihood of possible harm?\n\u2022 Does the answer contain any evidence of correct reading comprehension?\n\u2022 Does the answer contain any evidence of correct recall of knowledge?\n\u2022 Does the answer contain any evidence of correct reasoning steps?\n\u2022 Does the answer contain any evidence of incorrect reading comprehension?\n\u2022 Does the answer contain any evidence of incorrect recall of knowledge?\n\u2022 Does the answer contain any evidence of incorrect reasoning steps?\n\u2022 Does the answer contain any content it shouldn\u2019t?\n\u2022 Does the answer omit any content it shouldn\u2019t?\n\u2022 Does the answer contain info that is inapplicable or inaccurate for any particular \nmedical demographic?\n\u2022 How well does the answer address the intent of the question?\n\u2022 How helpful is this answer to the user? Does it enable them to draw a conclusion or help \nclarify next steps?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1335, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a54640b2-1f16-4f9f-8242-35f2c617dbc9": {"__data__": {"id_": "a54640b2-1f16-4f9f-8242-35f2c617dbc9", "embedding": null, "metadata": {"page_label": "28", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "950e1797-d9e2-406c-a9fd-336c75ad5cd3", "node_type": "4", "metadata": {"page_label": "28", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "eb7394867921647c54747a2c71c1da17a9bd80614d6f56a52261c5db07f23fab", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n28\nSeptember 2024\nFigure 6 shows the evaluation rubric applied to an example output by Med-PaLM 2.\nFigure 6. Example of clinician review of Med-PaLM 2", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 194, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "99f31f3f-c413-44d0-a886-a4d2496e01b3": {"__data__": {"id_": "99f31f3f-c413-44d0-a886-a4d2496e01b3", "embedding": null, "metadata": {"page_label": "29", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "691ba04c-059c-41f0-bef2-857f44adf8d8", "node_type": "4", "metadata": {"page_label": "29", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "a07956677524f6593d96dd9e855c943361d2753126d4f0d2e18fa041b75eb424", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n29\nSeptember 2024\nThe human evaluation for Med-PaLM follows this procedure:\n\u2022 Each question is presented to both Med-PaLM and a board-certified physician.\n\u2022 Both Med-PaLM and the physician independently provide their answers.\n\u2022 Those answers are then presented in a blinded way (i.e., who provided each answer is not \nindicated) to separate raters.\n\u2022 Additionally, direct side-by-side comparisons were conducted, such as determining which \nanswer is better between A and B (where A and B are blinded and could refer to physician-\nprovided or outputs from different AI models).\nIt is important to emphasize that the evaluation primarily focuses on the substance over the \nstyle / delivery. In certain instances, a clinician\u2019s response may be concise yet effectively \nmeets the evaluation criteria, while in other scenarios, a more detailed but verbose answer \nmay be more appropriate.\nOur human evaluation results as of May 2023 indicate that the answers provided by \nour models compare well to those from physicians across several critical clinically \nimportant axes.\nSince conducting evaluations with scientific rigor requires the involvement of expert laborers, \nsuch as board-certified physicians, the process is notably costlier than evaluating multiple-\nchoice questions. It is promising to see that other studies10 have adopted and expanded upon \nthe suggested framework for the purpose of being comparative and aligned with AI safety. \nThe expert evaluation plays a vital role critical in discerning style (i.e., delivery) and content \nas well as correctness.\nWe also learned that more work remains, including improvements along specific evaluation \naxes where physicians\u2019 performance remained superior.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1754, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ab692d28-8b81-4925-8edc-4f8b0de8d685": {"__data__": {"id_": "ab692d28-8b81-4925-8edc-4f8b0de8d685", "embedding": null, "metadata": {"page_label": "30", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4ce7e8f1-985a-40a3-8dd1-892821f504a1", "node_type": "4", "metadata": {"page_label": "30", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "17782143d18793dc1f1b583e6137aa6900e5580f2ad408b9217386b9e3cbdaca", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n30\nSeptember 2024\nThe detailed results are the cornerstone of understanding and identifying areas in need of  \nfuture scientific modeling and evaluation, as well as determining the feasibility of the next \nstep in our journey.\nAlthough quantitative and qualitative improvements can be made in order to achieve \nperfect performance on benchmarks, the technology can still provide practical value in \nreal-world settings.\nEvaluation in real clinical environments\nThe integration of technology into the clinical environment is a well-established area, and \nGoogle has gained its own expertise5 in the field through screening for diabetic retinopathy. \nOne of the main insights learned is that achieving high performance on retrospective \ndatasets does not automatically translate into clinical performance. It is imperative to \ncarefully validate AI solutions in real-world environments in a meticulous manner to ensure \ntheir robustness and reliability.\nEach technology integrated into a patient\u2019s journey, whether it falls under regulatory \noversight or not, is encouraged to adhere to these scientific steps:\n\u2022 Retrospective evaluation: Evaluate the technology against real-world data collected \nfrom past cases.\n\u2022 Prospective observational (non-interventional): Evaluate on newly collected real-world \ndata, but ensure that the outputs of the technology do not impact patient care or safety. \nAn example is feeding live data into the technology and then having the appropriate \nexperts evaluate the technology\u2019s output.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1564, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2d4163dd-dbba-4057-82eb-b34cfc879fa8": {"__data__": {"id_": "2d4163dd-dbba-4057-82eb-b34cfc879fa8", "embedding": null, "metadata": {"page_label": "31", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e9bca7a9-04c5-47c2-8287-8b47847248b5", "node_type": "4", "metadata": {"page_label": "31", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c3a3ea628c9fbe044d88409d4d42eb6fc4c71664ce95c086a1942048cdb20269", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n31\nSeptember 2024\n\u2022 Prospective interventional : Deploy the technology within a live clinical environment \nwith consented patients and influence patient care and potentially health outcomes. \nThis step requires a detailed and IRB-approved study protocol and care taken to ensure \npatient safety.\nThese steps are crucial not just for assessing the model's performance on new unseen data \nbut also, more significantly, for evaluating the effectiveness of the end-to-end system when \nintegrated into real workflows. Occasionally, the optimal way to use GenAI models like Med-\nPaLM may diverge from initial assumptions, and introducing a new tool into a clinical workflow \nmight require unexpected adjustments to the overall process.11,12 End-to-end assessment is \nessential for understanding the role and benefit of the technology and tailoring AI solutions \nto meet the needs effectively.\nTask- vs. domain-specific models\nMed-PaLM7 highlighted the significance and value of a specialized model for the medical \ndomain. Med-PaLM 2, an aligned and fine-tuned iteration of PaLM 2 tailored to medical \nknowledge, achieves a ninefold enhancement in precise reasoning compared to the \nbaseline.13 However, it's crucial to recognize that excelling in one medical domain task doesn't \nnecessarily guarantee and imply success in a different medical domain task. For instance, \ndoes a great general medical QA system also perform well on a mental health assessment \ntask? While it's reasonable to assume that a demonstrated understanding of clinical \nknowledge can generalize effectively to tasks heavily relying on this knowledge, each specific \ntask requires validation and possible adaptation, such as the measurement of psychiatric \nfunctioning,14 before proceeding further.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1810, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67f7504a-949f-4f0f-b6bf-c26743aa5840": {"__data__": {"id_": "67f7504a-949f-4f0f-b6bf-c26743aa5840", "embedding": null, "metadata": {"page_label": "32", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a858d197-a34b-4921-ab04-b8065b850724", "node_type": "4", "metadata": {"page_label": "32", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e3b7c00dc45ce364fac77959e55d5d89f3a97b1d8f150c3a374d1810e5c8ab40", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n32\nSeptember 2024\nThe medical domain also extends well beyond textual information. The practice of medicine is \ninherently multi-modal and incorporates information from images, electronic health records, \nsensors, wearables, genomics, and more. Multimodal versions15 of MedLM and related \napproaches16,17,18 are in early stages of research, and follow the same validation principles and \nworkflow integration approach. We will be observing the multimodal-enabled set of use-\ncases evaluated and deployed in the field.\nLastly, a medically specialized model can be applied not only to clinical use cases that relate \ndirectly to patient care, but also to use cases that benefit from leveraging medical knowledge \nin a flexible way. An example is in scientific discovery, where Med-PaLM can be used to \naccurately identify genes associated with biomedical traits.19 We'll be exploring a  breadth \nof possibilities with vertical-specific models, and we expect new applications and ideas to \nemerge in the field over the next few years. We\u2019re also exploring safe and responsible ways \nto bring these models to the healthcare industry. With MedLM, a suite of models fine-tuned \nfor healthcare use cases, built on Med-PaLM 2, we\u2019re making solutions commercially available \nso healthcare organizations can build GenAI use cases suitable for their workflows.\nTraining strategies for Med-PaLM 2\nMed-PaLM 2 is an advancement of the base LLM model PaLM 2, Google's enhanced LLM with \nsubstantial performance improvements on multiple LLM benchmark tasks. To tailor Med-\nPaLM 2 for medical applications, instruction fine-tuning7 was performed using MultiMedQA,7 \nincluding MedQA, MedMCQA, HealthSearchQA, LiveQA, and MedicationQA datasets. Dataset \nmixture ratios were empirically determined. \nTo enhance the specialized variant of Med-PaLM 2 focusing on multiple-choice questions, \na range of prompting strategies including few-shot prompting, chain-of-thought (CoT) \nprompting, and self-consistency were employed. CoT involves augmenting each few-shot \nexample in a prompt with a step-by-step explanation towards the final answer, allowing", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2171, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "74ab4b74-a611-472d-9cb6-4900cbde2238": {"__data__": {"id_": "74ab4b74-a611-472d-9cb6-4900cbde2238", "embedding": null, "metadata": {"page_label": "33", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a4111851-778f-4692-895e-a133d155d37c", "node_type": "4", "metadata": {"page_label": "33", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "71e67c36dee0c9417969cfc23e370cc86f30d236b88cdfc4f45e5992c60208db", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n33\nSeptember 2024\nthe language model to condition on its own intermediate outputs for multi-step problem-\nsolving. Self-consistency plays a role in enhancing the model's performance on multiple-\nchoice questions by sampling multiple explanations and answers from the model, with the \nfinal answer determined by a majority vote among the generated options. These strategies \ncollectively improve the model's ability to reason and provide more accurate responses to \ncomplex and multi-faceted queries.\nAnother noteworthy methodological improvement is the introduction of ensemble refinement \n(ER), which builds on other techniques that involve conditioning an LLM on its own \ngenerations before producing a final answer. In the first stage, multiple possible explanations \nand answers are stochastically generated via temperature sampling. In the second stage, \nthe model is conditioned on the original prompt, question, and generated contents from \nthe first stage, resulting in the production of a refined explanation and answer. This process \nfacilitated the effective aggregation of answers, extending its utility beyond questions with \na limited set of potential answers, thereby enhancing the overall performance of the model. \nThe overall mechanism of ensemble refinement is depicted in Figure 7.\nFigure 7. Ensemble refinement (ER) in Med-PaLM 2.  This approach involves conditioning an LLM on multiple \npotential reasoning pathways it generates, facilitating the answer refinement and improvement", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1546, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "60b90252-bf56-4632-8a14-93a4f5da636b": {"__data__": {"id_": "60b90252-bf56-4632-8a14-93a4f5da636b", "embedding": null, "metadata": {"page_label": "34", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1967f30a-098b-4cdf-a0ae-4d54a8ac90c9", "node_type": "4", "metadata": {"page_label": "34", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "4353aad51088ee1e58af797af747b7e0111e5920f52ee7379da17d7ae8f27d69", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n34\nSeptember 2024\nThe goal behind the inception of the Med-PaLM research effort was to improve health \noutcomes via using and advancing emerging AI technologies. Achieving expert-level \nperformance in medical QA tasks was the first step, with many more to follow in close \ncollaboration with the clinical community as we progress on this journey. \nOur health research experience at Google demonstrated repeatedly that technology is often \nnot the sole challenge in applying AI productively to healthcare. Instead, many other factors, \nincluding thoughtful evaluation strategies and working on clinically meaningful applications \nin partnership with clinicians and a broad cross-functional team, are pivotal to success.5 This \nvaluable insight is likely applicable to other vertical domains as well.\nAs AI technology matures and moves closer to practical use cases and real-world scenarios, \ncareful multi-step evaluations, including both retrospective and prospective assessments, \nare beneficial to better understand the real role and benefits of the technology in the whole \nworkflow. Guidance by a clinical partner improves the chances of building the right solution \nfor better health outcomes. Many promising applications lie in the collaboration of healthcare \nworkers and technology, combining the strengths of both. It is also important to use GenAI \nsystems in a way that is respectful of patients' autonomy and privacy.\nFor the foreseeable future, it is reasonable to assume that models customized for specific \napplications or domains will yield better results, and we are tracking trends and any \nconvergence in performance between general and specific models in the years ahead. For \nMed-PaLM specifically, our research progress will be tracked at the Med-PaLM research \nwebpage.20 We aim to make progress more broadly in the field of using AI and GenAI for the \nbetterment of patients, clinicians, and researchers.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1972, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "159a5968-49b6-4e7c-a4ae-5787380c9568": {"__data__": {"id_": "159a5968-49b6-4e7c-a4ae-5787380c9568", "embedding": null, "metadata": {"page_label": "35", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "852099c6-fea0-43d7-b14a-6e336894fcb8", "node_type": "4", "metadata": {"page_label": "35", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "571eb2cab020b6fb48c38db518805ab4128b87dddeaf254979e9c0fafb5f06e6", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n35\nSeptember 2024\nSummary\nThis whitepaper explores the potential of LLMs in tackling complex challenges within specific \ndomains, with a particular focus on healthcare and cybersecurity.\n\u2022 Cybersecurity: The ever-evolving landscape of cyber threats demands innovative \nsolutions. SecLM, an LLM designed for cybersecurity, acts as a force multiplier for \nsecurity professionals by intelligently processing vast amounts of data. This empowers \nthem to analyze and respond to threats more effectively. The vision for SecLM is to create \na comprehensive platform that caters to the diverse needs of security practitioners, \nregardless of their expertise. The combination of LLMs and human expertise has the \npotential to revolutionize the field of cybersecurity, achieving superior results with \nless effort.\n\u2022 Healthcare: Healthcare data is increasing in quantity and complexity, leading to a \nneed for innovative solutions to render medical information more helpful, useful, and \naccessible. MedLM, a family of models fine-tuned for the healthcare industry, can help \nunlock knowledge and make medicine more effective. MedLM is built on Med-PaLM, \nan LLM developed for medical applications. Med-PaLM has demonstrated expert-level \nperformance in medical question-and-answering tasks. This achievement is just the first \nstep in a journey towards improving health outcomes through the utilization of GenAI. The \nkey takeaway from this research is that technology alone is not enough. Collaboration \nwith the clinical community and careful multi-step evaluations are crucial for successful \napplication of LLMs in healthcare. Going forward, vertical-specific models like the MedLM \nfoundation models are expected to yield even better results for specific applications of \ninterest, furthering the potential of AI in healthcare.\nThis whitepaper showcases the possibilities of LLMs in solving domain-specific problems. By \nleveraging the power of these advanced models, combined with human expertise and careful \nimplementation, we can tackle complex challenges and achieve breakthrough advancements \nin various fields, for the benefit of peoples\u2019 lives.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2192, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa13aa1b-d84c-4f4f-ae84-7a3c5fe1da2b": {"__data__": {"id_": "aa13aa1b-d84c-4f4f-ae84-7a3c5fe1da2b", "embedding": null, "metadata": {"page_label": "36", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4cef32fc-428c-47d9-ae3e-61e06e3d1729", "node_type": "4", "metadata": {"page_label": "36", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "f762af0d26d6a10183619d3da749d2a809250ee012f26c3c575fe3d61720de79", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n36\nSeptember 2024\nEndnotes\n1. Cantos, J., et al., 2023. Threat Actors are Interested in Generative AI, but Use Remains Limited. [online] \nAvailable at: https://cloud.google.com/blog/topics/threat-intelligence/threat-actors-generative-ai-limited/ .\n2. Lin, C.Y., et al., 2003. Automatic Evaluation of Summaries Using n-gram Co-occurrence Statistics. [online] \nAvailable at: https://aclanthology.org/N03-1020.pdf .\n3. Papineni, K., et al., 2002. BLEU: A Method for Automatic Evaluation of Machine Translation. [online] Available \nat: https://aclanthology.org/P02-1040.pdf.\n4. Zhang, T., et al., 2019. BERTScore: Evaluating Text Generation with BERT. [online] Available at: https://\nopenreview.net/attachment?id=SkeHuCVFDr&name=original_pdf .\n5. Google, 2023. 5 myths about medical AI, debunked. [online] Available at: https://blog.google/technology/\nhealth/5-myths-about-medical-ai-debunked/ .\n6. Bommasani, R., et al., 2021. On the opportunities and risks of foundation models. arXiv preprint \narXiv:2108.07258. [online] Available at: https://arxiv.org/pdf/2108.07258 .\n7. Singhal, K., et al., 2023. Large language models encode clinical knowledge. Nature, 620(7972), pp.172-180. \n[online] Available at: https://www.nature.com/articles/s41586-023-06291-2 .\n8. Jin, D., et al., 2021. What disease does this patient have? a large-scale open domain question answering \ndataset from medical exams. Applied Sciences, 11(14), p.6421.\n9. Singhal, K., et al., 2023. Towards expert-level medical question answering with large language models. arXiv \npreprint arXiv:2305.09617. [online] Available at: https://arxiv.org/abs/2305.09617.\n10. Bernstein, I.A., et al., 2023. Comparison of ophthalmologist and large language model chatbot responses \nto online patient eye care questions. JAMA Network Open, 6(8), pp.e2330320-e2330320. [online] Available at: \nhttps://jamanetwork.com/journals/jamanetworkopen/fullarticle/2808557 .\n11. Beede, E., et al., 2019. A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the \nDetection of Diabetic Retinopathy. [online] Available at: https://dl.acm.org/doi/abs/10.1145/3313831.3376718 .\n12. Pedersen, S., et al., 2021. Redesigning Clinical Pathways for Immediate Diabetic Retinopathy Screening \nResults. NEJM Catalyst, July. [online] Available at: https://catalyst.nejm.org/doi/pdf/10.1056/CAT.21.0096 .\n13. Google, 2023. Google I/O Keynote 2023. [online] Available at:  https://www.youtube.com/live/\ncNfINi5CNbY?si=jQFi-Y3mG0rGD3Xd&t=810 .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2533, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4fa0f180-fb53-4b27-a505-517d28e90be8": {"__data__": {"id_": "4fa0f180-fb53-4b27-a505-517d28e90be8", "embedding": null, "metadata": {"page_label": "37", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "11317e73-6fbd-46f3-a5fa-da02b1275f86", "node_type": "4", "metadata": {"page_label": "37", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "0ade7d18676f4783d52ea03cbbecb7f7ec9012cc8f0227bd7c0404958d6dec13", "class_name": "RelatedNodeInfo"}}, "text": "Solving Domain-Specific Problems Using LLMs\n37\nSeptember 2024\n14. Galatzer-Levy, I.R., et al., 2023. The Capability of Large Language Models to Measure Psychiatric \nFunctioning. arXiv preprint arXiv:2308.01834. [online] Available at: https://arxiv.org/abs/2308.01834 .\n15. Tu, T., et al., 2023. Towards generalist biomedical AI. arXiv preprint arXiv:2307.14334. [online] Available at: \nhttps://arxiv.org/abs/2307.14334.\n16. Liu, X., et al., 2023. Large Language Models are Few-Shot Health Learners. arXiv:2305.15525. [online] \nAvailable at: https://arxiv.org/abs/2305.15525 .\n17. Belyaeva, A., et al., 2023. Multimodal LLMs for health grounded in individual-specific data. arXiv:2307.09018. \n[online] Available at: https://arxiv.org/abs/2307.09018 .\n18. Shawn, X., et al., 2022. ELIXR: Towards a general purpose X-ray artificial intelligence system through \nalignment of large language models and radiology vision encoders. arXiv:2308.01317. [online] Available at: \nhttps://arxiv.org/abs/2308.01317.\n19. Tu, T., et al., 2023. Genetic Discovery Enabled by a Large Language Model. [online] Available at: https://www.\nbiorxiv.org/content/10.1101/2023.11.09.566468v1.full.pdf .\n20. Med-PaLM, [n.d.]. Homepage. [online] Available at: https://g.co/research/medpalm .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1260, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bcd27c76-2798-4930-a81b-935decd072d9": {"__data__": {"id_": "bcd27c76-2798-4930-a81b-935decd072d9", "embedding": null, "metadata": {"page_label": "1", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2d3fe42c-4570-48e8-b9b7-c5203dcc2e21", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2245229c28266222a95dcb0b7f4d60e8fd39b901ede69f1eb242985f594a38ff", "class_name": "RelatedNodeInfo"}}, "text": "Contact\n2330 N Oliver Ave, Wichita, KS\n67220\n+1 3165597502 (Mobile)\nchitrakumarsai@gmail.com\nwww.linkedin.com/in/\nchitrakumarsai (LinkedIn)\nTop Skills\nAmazon Web Services (AWS)\nData Analysis\nStatistics\nLanguages\nHindi (Native or Bilingual)\nEnglish (Native or Bilingual)\nTelugu (Native or Bilingual)\nCertifications\nMicrosoft Certified Azure\nAdministrator Associate\nNeo4j Fundamentals\nMicrosoft Certified: Azure Data\nEngineer Associate.\nChitra Kumar Sai Chenuri\nVenkata\nData Scientist\nWichita, Kansas, United States\nSummary\nChitra Kumar Sai has graduated from Wichita State University, with\na degree emphasis in Computer Science. He is working as a Data\nScientist at Koch Industries (INVISTA).\nHe is an individual with 4 years of experience in Data Science,\nEngineering and Analytics in Manufacturing, Technology, Consulting,\nRetail and Supply Chain industries. He is well versed with tools\nand techniques essential for ETL, optimization, Machine Learning\nand Deep Learning along with an ability to tie the data together to\nexecute streamline operations effectively. \nDuring his professional career, he designed high performance\nETL, Machine Learning and Computer Vision solutions using\nexisting technique and packages, also enabled the real time\nsolutions focusing on performance and accuracy. He ensured\nstakeholders\u2019 success and aligned the team with his project goals\nby maintaining communication through quarterly presentations and\nquality visualizations using BI tools to help executives, reporters/\nanalysts. He also developed solutions by identifying underperforming\nproducts with the help of customer feedback eventually boosting the\nsales performance while ensuring customers satisfaction.  \nHe has positively impacted the customer experience by leveraging\nthe data/information from various sources and developed automated\nscripts to maintain a constant flow of data focusing on its accuracy\n& reliability. He worked in building a strong team that is focused on\nresolving manual tasks consuming large amount of man hours using\nautomation techniques through tools like Alteryx, Python, R, AWS\nand Azure. \nHe is passionate about exploring data science projects in\nTechnology, Manufacturing, Consulting, Software, Marketing &\n\u00a0 Page 1 of 3", "mimetype": "text/plain", "start_char_idx": 4, "end_char_idx": 2248, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "94c7d40f-86d9-411c-b875-61b5889256b8": {"__data__": {"id_": "94c7d40f-86d9-411c-b875-61b5889256b8", "embedding": null, "metadata": {"page_label": "2", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f6a6434-e5ff-4f29-acc3-643a67dee185", "node_type": "4", "metadata": {"page_label": "2", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "73560bc67e481a8f4179b599a7403718bf82d3dfb81ca6bcaa8e0c486fac21b0", "class_name": "RelatedNodeInfo"}}, "text": "Advertising, Consumer goods, Logistics & Supply domains by\nleveraging his industry knowledge developed from 4 years of\nprofessional experience.\nExperience\nKoch Industries\nData Scientist | INVISTA\nMay 2022\u00a0-\u00a0Present\u00a0(2 years 7 months)\nUnited States\nFractal\nData Engineer\nOctober 2021\u00a0-\u00a0April 2022\u00a0(7 months)\nUnited States\nClient: Google\nJohnson Controls\nData Science Analyst Intern\nJune 2021\u00a0-\u00a0August 2021\u00a0(3 months)\nUnited States\nCosmic Pet\nReporting and Analysis Intern\nSeptember 2020\u00a0-\u00a0May 2021\u00a0(9 months)\nUnited States\nWichita State University\nGraduate Research Assistant\nFebruary 2020\u00a0-\u00a0May 2021\u00a0(1 year 4 months)\nWichita, Kansas, United States\nMindtree\nJunior Engineer\nJuly 2017\u00a0-\u00a0June 2019\u00a0(2 years)\nHyderabad, Telangana, India\nClient: Microsoft \nEducation\n\u00a0 Page 2 of 3", "mimetype": "text/plain", "start_char_idx": 4, "end_char_idx": 780, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f5475c96-3faf-4689-8172-c7aaad81bb56": {"__data__": {"id_": "f5475c96-3faf-4689-8172-c7aaad81bb56", "embedding": null, "metadata": {"page_label": "3", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7d9ee3fa-d4f9-4298-a82d-1ee5fdab5153", "node_type": "4", "metadata": {"page_label": "3", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c99c9f86b1d6c8ecb43d81deb75eddb206e6ab8ce9a809d6a160a5a3a99ed5dc", "class_name": "RelatedNodeInfo"}}, "text": "Ottawa University\nDoctor's Degree,\u00a0Business Administration and Management, General\u00a0\u00b7\u00a0(May\n2024\u00a0-\u00a0June 2027)\nWichita State University\nMaster of Science - MS,\u00a0Computer Science\u00a0\u00b7\u00a0(2019\u00a0-\u00a02021)\nJawaharlal Nehru Technological University\nBachelor of Technology (B.Tech.),\u00a0Electronics and Communications\nEngineering\u00a0\u00b7\u00a0(2013\u00a0-\u00a02017)\n\u00a0 Page 3 of 3", "mimetype": "text/plain", "start_char_idx": 4, "end_char_idx": 342, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e6371bc5-f3cb-4919-952f-f4c84a1e33b4": {"__data__": {"id_": "e6371bc5-f3cb-4919-952f-f4c84a1e33b4", "embedding": null, "metadata": {"page_label": "1", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "674d6cf1-f41e-4203-b758-047caa4c2fd6", "node_type": "4", "metadata": {"page_label": "1", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "6f09adecf1d4669e3e8e8b6a9d58f2d5de3b6f3524f377c3b34ebb3bf98fc53c", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings  \n& Vector Stores\nAuthors: Anant Nawalgaria  \nand Xiaoqi Ren", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 71, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "174feabd-3013-4cc3-a6ad-01c1144c5630": {"__data__": {"id_": "174feabd-3013-4cc3-a6ad-01c1144c5630", "embedding": null, "metadata": {"page_label": "2", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e0c0164e-9d5d-4999-b1f9-f60343af5a1e", "node_type": "4", "metadata": {"page_label": "2", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "d715b61caabb03e1c6e675bdd1aaaa616fa38e303199ada947f014c33011eac0", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n2\nSeptember 2024\nReviewers and Contributors\nAntonio Gulli\nGrace Mollison\nRuiqi Guo\nIftekhar Naim\nJinhyuk Lee\nAlan Li\nPatricia Florissi\nAndrew Brook\nOmid Fatemieh\nZhuyun Dai\nLee Boonstra\nPer Jacobsson\nSiddhartha Reddy Jonnalagadda\nXi Cheng\nRaphael Hoffmann\nCurators and Editors\nAntonio Gulli\nAnant Nawalgaria\nGrace Mollison \nTechnical Writer\nJoey Haymaker\nDesigner\nMichael Lanning \nAcknowledgements", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 424, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "af78b862-d67c-4924-9dbf-2d0e8aa5c49a": {"__data__": {"id_": "af78b862-d67c-4924-9dbf-2d0e8aa5c49a", "embedding": null, "metadata": {"page_label": "3", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5d9b0070-aa7e-46b1-bf9d-56e017d16512", "node_type": "4", "metadata": {"page_label": "3", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "4d4a5caae9de1642c5e68bce7d45e98d7bc4cfc16e061289275aee3d27e6fe7e", "class_name": "RelatedNodeInfo"}}, "text": "Introduction 5\nWhy embeddings are important 6\n Types of embeddings 9\n  Text embeddings 9\n   Word embeddings 11\n   Document embeddings 15\n    Shallow BoW models 16\n    Deeper pretrained large language models 18\n  Image & multimodal embeddings 22\n  Structured data embeddings 24\n   General structured data  24\n   User/item structured data 25\n  Graph embeddings 25\n Training Embeddings 26\nTable of contents", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 403, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "323febd0-76a1-4912-a1f3-f1c5584f168c": {"__data__": {"id_": "323febd0-76a1-4912-a1f3-f1c5584f168c", "embedding": null, "metadata": {"page_label": "4", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a5a96faa-8bbf-47db-93c2-01d2e1bce5f3", "node_type": "4", "metadata": {"page_label": "4", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "eb39e8d8f7982d58921176ad6690bd82fc7d794cb4881faf92988da31653621d", "class_name": "RelatedNodeInfo"}}, "text": "Vector search 28\n Important vector search algorithms 29\n  Locality sensitive hashing & trees 30\n  Hierarchical navigable small worlds  33\n  ScaNN 34\nVector databases  37\n Operational considerations 39\nApplications 40\n Q & A with sources (retrieval augmented generation) 42\nSummary 47\nEndnotes 49", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 295, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "af435f87-179f-4c96-bd8d-952c3ec12b6f": {"__data__": {"id_": "af435f87-179f-4c96-bd8d-952c3ec12b6f", "embedding": null, "metadata": {"page_label": "5", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0bcaa809-efb2-4f19-a812-43f62fbcc4b6", "node_type": "4", "metadata": {"page_label": "5", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "717afd54e5d69e68f48f78949c84855f6f7acd08e77f25d4598f2f0c038d8927", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n5\nSeptember 2024\nIntroduction\nModern machine learning thrives on diverse data\u2014images, text, audio, and more. This \nwhitepaper explores the power of embeddings, which transform this heterogeneous data into \na unified vector representation for seamless use in various applications.\nWe'll guide you through:\n\u2022 Understanding Embeddings: Why they are essential for handling multimodal data and \ntheir diverse applications.\n\u2022 Embedding Techniques: Methods for mapping different data types into a common \nvector space.\nThese low-dimensional numerical \nrepresentations of real-world data \nsignificantly helps efficient large-\nscale data processing and storage \nby acting as means of lossy \ncompression of the original data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 742, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f930600d-145b-4d00-9ad7-410e427becd9": {"__data__": {"id_": "f930600d-145b-4d00-9ad7-410e427becd9", "embedding": null, "metadata": {"page_label": "6", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "014ec0a8-4bb1-46e6-a5ef-3381fd4030e6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "3fff70d90390577dd8f8c27d4adb6b9c7b899f90fb900987775e6d554d1cd45d", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n6\nSeptember 2024\n\u2022 Efficient Management: Techniques for storing, retrieving, and searching vast collections \nof embeddings.\n\u2022 Vector Databases: Specialized systems for managing and querying embeddings, \nincluding practical considerations for production deployment.\n\u2022 Real-World Applications: Concrete examples of how embeddings and vector databases \nare combined with large language models (LLMs) to solve real-world problems.\nThroughout the whitepaper, code snippets provide hands-on illustrations of key concepts.\nWhy embeddings are important\nIn essence, embeddings are numerical representations of real-world data such as text, \nspeech, image, or videos. They are expressed as low-dimensional vectors where the \ngeometric distances of two vectors in the vector space is a projection of the relationships \nbetween the two real-world objects that the vectors represent. In other words they help you \nwith providing compact representations of data of different types, while simultaneously also \nallowing you to compare two different data objects and tell how similar or different they are \non a numerical scale: for example: The word \u2018computer\u2019 has a similar meaning to the picture \nof a computer, as well as the word \u2019laptop\u2019 but not to the word \u2018car\u2019. These low-dimensional \nnumerical representations of real-world data significantly helps efficient large-scale data \nprocessing and storage by acting as means of lossy compression of the original data while \nretaining its important properties.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1523, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89ecb132-9ff1-4375-b187-c16d48599f6f": {"__data__": {"id_": "89ecb132-9ff1-4375-b187-c16d48599f6f", "embedding": null, "metadata": {"page_label": "7", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e1a2dac7-95cc-4a92-9de2-df35ab84b71b", "node_type": "4", "metadata": {"page_label": "7", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "5ce7ff15e01b38a9e133da7f4fa884242eccf9ba472fb1776b94f5f0311912e5", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n7\nSeptember 2024\nOne of the key applications for embeddings is retrieval and recommendations, where the \nresult is usually from a massive search space. For example, Google Search is a retrieval  with \nthe  search space of the whole internet. Today\u2019s retrieval and recommendation systems\u2019 \nsuccess depends on the following:\n1. Precomputing the embeddings for billions items of the search space.\n2. Mapping query embeddings to the same embedding space.\n3. Efficient computing and retrieving of the nearest neighbors of the query embeddings in \nthe search space.\nEmbeddings also shine in the world of multimodality. Most applications work with large \namounts of data of various modalities: text, speech, image, and videos to name a few. \nBecause every entity or object is represented in its own unique format, it\u2019s very difficult \nto project these objects into the same vector space that is both compact and informative. \nIdeally, such a representation would capture as much of the original object\u2019s characteristics \nas possible. An embedding refers to the projected vector of an object from an input space to \na relatively low-dimensional vector space. Each vector is a list of floating point numbers.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1226, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "085549ec-de43-4a7e-a24b-31e80ba97577": {"__data__": {"id_": "085549ec-de43-4a7e-a24b-31e80ba97577", "embedding": null, "metadata": {"page_label": "8", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "92b2b6cc-f932-4a78-8138-b0af129cdaae", "node_type": "4", "metadata": {"page_label": "8", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "54005cebf9027bcafccc537861d51fc41c83715cba69dd49c058e6373589cc42", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n8\nSeptember 2024\nFigure 1. Projecting objects/content into a joint vector space with semantic meaning\nIdeally the embeddings are created so they place objects with similar semantic properties \ncloser in the embedding space (a low-dimensional vector space where items can be \nprojected). The embeddings can then be used as a condensed, meaningful input in \ndownstream applications. For example, you can use them as features for ML models, \nrecommender systems, search engines, and many more. So your data not only gets a \ncompact numerical representation, but this representation also preserves the semantic \nmeanings for a specific task or across a variety of tasks. The fact that these representations \nare task-specific means you can generate different embeddings for the same object, \noptimized for the task at hand.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 846, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "24bef584-e2e9-4e62-99ec-f3ef82a17555": {"__data__": {"id_": "24bef584-e2e9-4e62-99ec-f3ef82a17555", "embedding": null, "metadata": {"page_label": "9", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4e68365f-068c-471c-8fa6-07aeca9c570a", "node_type": "4", "metadata": {"page_label": "9", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "3f4cc57709c3d31766bc1c4b6b84918e3d6e87732be82c30fe333982a023fd75", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n9\nSeptember 2024\nTypes of embeddings\nEmbeddings aim to obtain a low dimensional representation of the original data while \npreserving most of the \u2018essential information\u2019. The types of data an embedding represents \ncan be of various different forms.  Below you\u2019ll see some standard techniques used for \ndifferent types of data, including text and image.\nText embeddings\nText embeddings are used extensively as part of natural language processing (NLP). They \nare often used to embed the meaning of natural language in machine learning for processing \nin various downstream applications such as text generation, classification, sentiment \nanalysis, and more. These embeddings broadly fall into two categories: token/word and \ndocument embeddings.\nBefore diving deeper into these categories, it\u2019s important to understand the entire lifecycle \nof text: from its input by the user to its conversion to embeddings. \nFigure 2. The process of turning text into embeddings\nIt all starts with the input string which is split into smaller meaningful pieces called tokens.  \nThis process is called tokenization. Commonly, these tokens are wordpieces, characters, \nwords, numbers, and punctuations using one of the many existing tokenization techniques.1 \nAfter the string is tokenized, each of these tokens is then assigned a unique integer value", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2f062d25-af44-481e-9560-24681269fadc": {"__data__": {"id_": "2f062d25-af44-481e-9560-24681269fadc", "embedding": null, "metadata": {"page_label": "10", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6a06bdfb-3fe3-4b04-b4ec-9b1f1f2078ce", "node_type": "4", "metadata": {"page_label": "10", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "9b5e4abb9b9771c58f6ef778886249560d5382f8cf81aa182ebedb4db81825eb", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n10\nSeptember 2024\nusually in the the range: [0, cardinality of the total number of tokens in the corpus]. For \nexample, for a 16 word vocabulary the IDs would range between 0-15. This value is also \nreferred to as token ID. These tokens can be used to represent each string as a sparse \nnumerical vector representation of documents used for downstream tasks directly, or after \none-hot encoding. One-hot encoding is a binary representation of categorical values where \nthe presence of a word is represented by 1, and its absence by 0. This ensures that the token \nIDs are treated as categorical values as they are, but often results in a dense vector the size \nof the vocabulary of the corpus. Snippet 1 and Figure 3 show an example of how this can be \ndone using Tensorflow.\n# Tokenize the input string data\nfrom tensorflow.keras.preprocessing.text import Tokenizer\ndata = [\n  \"The earth is spherical.\",\n  \"The earth is a planet.\",\n  \"I like to eat at a restaurant.\"]\n# Filter the punctiations, tokenize the words and index them to integers  \ntokenizer = Tokenizer(num_words=15, filters=\"!\"#$%&()*+,-./:;<=>?[\\\\]^_'{|}~\\t\\n\", lower=True, \nsplit=' ')\ntokenizer.fit_on_texts(data)\n# Translate each sentence into its word-level IDs, and then one-hot encode those IDs \nID_sequences = tokenizer.texts_to_sequences(data)\nbinary_sequences = tokenizer.sequences_to_matrix(ID_sequences)\nprint(\"ID dictionary:\\n\", tokenizer.word_index)\nprint(\"\\nID sequences:\\n\", ID_sequences)\nprint(\"\\n One-hot encoded sequences:\\n\", binary_sequences )\nSnippet 1. Tokenizing,  indexing and one-hot encoding strings", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1616, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1f05b534-502c-4805-a7c2-b229dc6888a1": {"__data__": {"id_": "1f05b534-502c-4805-a7c2-b229dc6888a1", "embedding": null, "metadata": {"page_label": "11", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "848878d3-767e-4bd5-8f81-c6e24d94454b", "node_type": "4", "metadata": {"page_label": "11", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "387939c28281f43cfc96f1fd60ebb0256f1072b0ddfd0536040acff036f9342a", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n11\nSeptember 2024\nFigure 3. Output of Snippet 1\nHowever, since these Integer IDs (or their corresponding one-hot encoded vectors) are \nassigned randomly to words, they lack any inherent semantic meaning. This is where \nembeddings are much more useful. Although it\u2019s possible to embed character and sub-word \nlevel tokens as well, let us look at word and document embeddings to understand some of \nthe methods behind them.\nWord embeddings\nIn this section, you\u2019ll see a few word embedding techniques and algorithms to both train \nand use word embeddings. While there are many ML driven algorithms developed over \ntime optimized for different objectives, the most common ones are GloVe,2 SWIVEL,3 and \nWord2Vec.4 Word embeddings or sub-word embeddings can also be directly obtained from \nhidden layers of language models. However, the embeddings will be different for the same \nword in different contexts of the text. This section focuses on lightweight, context-free \nword embedding and leaves the context-aware document embeddings for the document \nembeddings section. Word embedding can be directly applied to downstream tasks like \nnamed entity extraction and topic modeling.\nWord2Vec is a family of model architectures that operates on the principle of \u201cthe semantic \nmeaning of a word is defined by its neighbors\u201d, or words that frequently appear close to each \nother in the training corpus. This method can be both used to train your own embeddings", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1479, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7eb01d40-6090-4f66-8428-c962e9b9e438": {"__data__": {"id_": "7eb01d40-6090-4f66-8428-c962e9b9e438", "embedding": null, "metadata": {"page_label": "12", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3a2303d-f8b7-4b94-a948-e8620f8df25e", "node_type": "4", "metadata": {"page_label": "12", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "d450bb019f95920c1148b5436ddad11e459f23b42c481c2d1fdeffb6035e8f82", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n12\nSeptember 2024\nfrom large datasets or be quickly integrated through one of the readily available pre-trained \nembeddings available online.5 The embeddings for each word - which are essentially fixed \nlength vectors - are randomly initialized to kick off the process, resulting in a matrix of shape \n(size_of_vocabulary, size_of_each_embedding). This matrix can be used as a lookup table \nafter the training process is completed using one of the following methods (see Figure 4). \n\u2022 The Continuous bag of words (CBOW) approach: Tries to predict the middle word, using \nthe embeddings of the surrounding words as input. This method is agnostic to the order \nof the surrounding words in the context. This approach is fast to train and is slightly more \naccurate for frequent words.\n\u2022 The skip-gram approach: The setup is inverse of that of CBOW, with the middle word \nbeing used to predict the surrounding words within a certain range. This approach is \nslower to train but works well with small data and is more accurate for rare words.\nFigure 4. Diagram explaining how CBOW and Skip-Gram methods work", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1129, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81f6823d-ffd1-4dd0-be23-269209cff20d": {"__data__": {"id_": "81f6823d-ffd1-4dd0-be23-269209cff20d", "embedding": null, "metadata": {"page_label": "13", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b966e51-a0fb-4d86-b725-c295c01d8805", "node_type": "4", "metadata": {"page_label": "13", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "b194558fb9feba080f527affead974b73a7eaa43abd4cac6c650599441bcdfeb", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n13\nSeptember 2024\nThe Word2Vec algorithms can also be extended to the sub-word level, which has been the \ninspiration for algorithms such as FastText.6 However, one of the major caveats of Word2Vec \nis that although it accounts well for local statistics of words within a certain sliding window, it \ndoes not capture the global statistics (words in the whole corpus). This shortcoming is what \nmethods like the GloVe algorithm address.\nGloVe is a word embedding technique that leverages both global and local statistics of words. \nIt does this by first creating a co-occurrence matrix, which represents the relationships \nbetween words. GloVe then uses a factorization technique to learn word representations \nfrom the co-occurrence matrix. The resulting word representations are able to capture both \nglobal and local information about words, and they are useful for a variety of NLP tasks.\nIn addition to GloVE, SWIVEL is another approach which leverages the co-occurrence \nmatrix to learn word embeddings. SWIVEL stands for Skip-Window Vectors with Negative \nSampling. Unlike GloVE, it uses local windows to learn the word vectors by taking into \naccount the co-occurrence of words within a fixed window of its neighboring words. \nFurthermore, SWIVEL also considers unobserved co-occurrences and handles it using a \nspecial piecewise loss, boosting its performance with rare words. It is generally considered \nonly slightly less accurate than GloVe on average, but is considerably faster to train. This is \nbecause it leverages distributed training by subdividing the Embedding vectors into smaller \nsub-matrices and executing matrix factorization in parallel on multiple machines. Snippet 2 \nbelow demonstrates loading pre-trained word embeddings for both Word2Vec and GloVe and \nvisualizing them in a 2D space, and computing nearest neighbors.\nWord embeddings can be directly used in some downstream tasks like Named Entity \nRecognition (NER).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1975, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7b25335-3fac-43e5-932d-d2b3eddf3ffe": {"__data__": {"id_": "b7b25335-3fac-43e5-932d-d2b3eddf3ffe", "embedding": null, "metadata": {"page_label": "14", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f649d7cb-da8e-4430-8f01-b07785cb5b59", "node_type": "4", "metadata": {"page_label": "14", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "eff0789d9ebe76728a637bf8eee57caa618710a4094ecb4c5d26a57b0c6e38d7", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n14\nSeptember 2024\nfrom gensim.models import Word2Vec \nimport gensim.downloader as api\nimport pprint\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nimport numpy as np\ndef tsne_plot(models, words, seed=23):\n  \"Creates a TSNE models & plots for multiple word models for the given words\"\n  plt.figure(figsize=(len(models)*30, len(models)*30))\n  model_ix = 0\n  for model in models:\n    labels = []\n    tokens = []\n    for word in words:\n      tokens.append(model[word])\n      labels.append(word)\n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=seed) \n    new_values = tsne_model.fit_transform(np.array(tokens))\n    x = []\n    y = []\n    for value in new_values:\n      x.append(value[0])\n      y.append(value[1])\n    model_ix +=1\n    plt.subplot(10, 10, model_ix)\n    for i in range(len(x)):\n      plt.scatter(x[i],y[i])\n      plt.annotate(labels[i],\n            xy=(x[i], y[i]),\n            xytext=(5, 2),\n            textcoords='offset points',\n            ha='right',\n            va='bottom')\n  plt.tight_layout()\n  plt.show()\nv2w_model = api.load('word2vec-google-news-300')\nglove_model = api.load('glove-twitter-25')\nprint(\"words most similar to 'computer' with word2vec and glove respectively:\")\npprint.pprint( v2w_model.most_similar(\"computer\")[:3])\npprint.pprint( glove_model.most_similar(\"computer\")[:3]) \npprint.pprint(\"2d projection of some common words of both models\")\nsample_common_words= list(set(v2w_model.index_to_key[100:10000]) \n                        & set(glove_model.index_to_key[100:10000]))[:100]\ntsne_plot([v2w_model, glove_model], sample_common_words)\nSnippet 2. Loading and plotting GloVe and Word2Vec embeddings in 2D", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1729, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d4dbde06-721c-47e0-8351-ddde51925f92": {"__data__": {"id_": "d4dbde06-721c-47e0-8351-ddde51925f92", "embedding": null, "metadata": {"page_label": "15", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "47ec847a-d874-422f-9290-5a75a11ead92", "node_type": "4", "metadata": {"page_label": "15", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "f7ffc3ce9ee947ac8ac1f0621265996751aa653852b1a4de0a92f33a3e7364b9", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n15\nSeptember 2024\nFigure 5 Shows semantically similar words are clustered differently for the two algorithms\nFigure 5. 2D visualization of pre-trained GloVe and Word2Vec word embeddings\nDocument embeddings\nEmbedding documents to low-dimensional dense embedding has attracted long-lasting \ninterests since the 1980s. Document embeddings can be used in various applications, \nincluding semantic search, topic discovery, classification, and clustering to embed \nthe meaning of a series of words in paragraphs and documents and use it for various", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 569, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bf8782af-c80f-4cff-8189-80e6df5d311a": {"__data__": {"id_": "bf8782af-c80f-4cff-8189-80e6df5d311a", "embedding": null, "metadata": {"page_label": "16", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3cd1d469-0aa5-4360-921a-6e163e88ecd3", "node_type": "4", "metadata": {"page_label": "16", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "119cc25552d1fbff60c34cda25a5fbfbd8294b08c43e884d3b77871556bb8453", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n16\nSeptember 2024\ndownstream applications. The evolution of the embeddings models can mainly be \ncategorized into two stages: shallow Bag-of-words (BoW) models and deeper pretrained \nlarge language models.\nShallow BoW models\nEarly document embedding works follow the bag-of-words (BoW) paradigm, assuming a \ndocument is an unordered collection of words. These early works include latent semantic \nanalysis (LSA)7 and latent dirichlet allocation (LDA).8 Latent semantic analysis (LSA) uses \na co-occurrence matrix of words in documents and latent dirichlet allocation (LDA) uses a \nbayesian network to model the document embeddings. Another famous bag-of-words family \nof document embeddings is TF-IDF (term frequency-inverse document frequency) based \nmodels, which are statistical models that use the word frequency to represent the document \nembedding. TF-IDF-based models can either be a sparse embedding, which represents the \nterm-level importance, or can be combined with word embeddings as a weighting factor to \ngenerate a dense embedding for the documents. For example, BM25, a TF-IDF-based bag-\nof-words model, is still a strong baseline in today\u2019s retrieval benchmarks.9\nHowever,  the bag-of-words paradigm also has two major weaknesses: both the word \nordering and the semantic meanings are ignored. BoW models fail to capture the sequential \nrelationships between words, which are crucial for understanding meaning and context. \nInspired by Word2Vec, Doc2Vec10 was proposed in 2014 for generating document \nembeddings using (shallow) neural networks. The Doc2Vec model adds an additional \n\u2018paragraph\u2019 embedding or, in other words, document embedding in the model of Word2Vec \nas illustrated in Figure 6. The paragraph embedding is concatenated or averaged with other \nword embeddings to predict a random word in the paragraph. After training, for existing \nparagraphs or documents, the learned embeddings can be directly used in downstream \ntasks. For a new paragraph or document, extra inference steps need to be performed to \ngenerate the paragraph or document embedding.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2113, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5349a12-718a-468e-aca0-40d4da55262b": {"__data__": {"id_": "b5349a12-718a-468e-aca0-40d4da55262b", "embedding": null, "metadata": {"page_label": "17", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "943b2ac0-1402-4f8d-bc3e-d097667f2c12", "node_type": "4", "metadata": {"page_label": "17", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "8843c50d5e35f4412fd79b1c67164ea87d488bd9005fdf849e121a17eea295fa", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n17\nSeptember 2024\nFigure 6. Doc2vec CBOW model\nSnippet 3 below shows how you can train your own doc2Vec models on a custom corpus:\nfrom gensim.test.utils import common_texts\nfrom gensim.models.Doc2Vec import Doc2Vec, TaggedDocument\nfrom gensim.test.utils import get_tmpfile\n#train model on a sequence of documents tagged with their IDs\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\nmodel = Doc2Vec(documents, vector_size=8, window=3, min_count=1, workers=6)\n# persist model to disk, and load it to infer on new documents\nmodel_file = get_tmpfile(\"Doc2Vec_v1\")\nmodel.save(model_file)\nmodel = Doc2Vec.load(model_file)  \nmodel.infer_vector([\"human\", \"interface\"])\nSnippet 3. Self-supervised Training and inference using Doc2Vec on private corpus", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 800, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ec2e131b-f548-4d2d-b377-57ccd972b590": {"__data__": {"id_": "ec2e131b-f548-4d2d-b377-57ccd972b590", "embedding": null, "metadata": {"page_label": "18", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0772d767-1d71-42e1-bd43-ec2a8be42c10", "node_type": "4", "metadata": {"page_label": "18", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "d2861fee150d199bc55712f045fbbd5c75226244bb907e66f1c702448e701221", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n18\nSeptember 2024\nThe success of applying neural networks in the embedding world inspired an increasing \ninterest in using deep neural networks to generate embeddings. \nDeeper pretrained large language models\nMotivated by the development of deep neural networks, different embedding models and \ntechniques were proposed, and the state-of-the-art models are refreshed frequently. Main \nchanges of the models include: \n1. Using more complex learning models, especially bi-directional deep neural network \nmodels. \n2. The use of massive pre-training on unlabeled text. \n3. The use of a subword tokenizer. \n4. Using fine-tuning for various downstream NLP tasks. \nIn 2018, BERT11 - which stands for bidirectional encoder representations from transformers - \nwas proposed with groundbreaking results on 11 NLP tasks. Transformer, the model paradigm \nBERT based on, has become the mainstream model paradigm until today. Besides using a \ntransformer as the model backbone, another key of BERT\u2019s success is from pre-training with \na massive unlabeled corpus. In pretraining, BERT utilized masked language model (MLM) as \nthe pre-training objective. It did this by randomly masking some tokens of the input and using \nthe masked token id as the prediction objective. This allows the model to utilize both the \nright and left context to pretrain a deep bidirectional transformer. BERT also utilizes the next \nsentence prediction task in pretraining. BERT outputs a contextualized embedding for every \ntoken in the input. Typically, the embedding of the first token (a special token named [CLS]) is \nused as the embedding for the whole input.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1657, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "26829735-c188-489e-8fdf-7611e06d40eb": {"__data__": {"id_": "26829735-c188-489e-8fdf-7611e06d40eb", "embedding": null, "metadata": {"page_label": "19", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dbcf648e-d7e7-4d21-b83b-594b1bfc3f5c", "node_type": "4", "metadata": {"page_label": "19", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "baa66f754dd4f9376713859d2ffa28048a848ee71d1c03b7fe06f12a43dc2633", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n19\nSeptember 2024\nFigure 7. The BERT architecture\nBERT became the base model for multiple embedding models, including Sentence-\nBERT,12 SimCSE,13 and E5.14 Meanwhile, the evolution of language models - especially large \nlanguage models - never stops. T5 was proposed in 2019 with up to 11B parameters. PaLM \nwas proposed in 2022 to push the large language model to a surprising 540B parameters. \nModels like Gemini from Google, GPT models from OpenAI and Llama models from Meta are \nalso evolving to newer generations at astonishing speed. Please refer to the whitepaper on \nFoundational models for more information about some common LLMs.\nNew embedding models based on large language models have been proposed. For example, \nGTR and Sentence-T5 show better performance on retrieval and sentence similarity \n(respectively) than BERT family models.\nAnother approach to new embeddings models development is generating multi-vector \nembeddings instead of a single vector to enhance the representational power of the models. \nEmbedding models in this family include ColBERT15 and XTR.16", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1109, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3603433-f187-4fcf-a983-387e6ef35919": {"__data__": {"id_": "f3603433-f187-4fcf-a983-387e6ef35919", "embedding": null, "metadata": {"page_label": "20", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "343e85f1-500a-40b2-9d47-a2beacc38e58", "node_type": "4", "metadata": {"page_label": "20", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "efd62d66a7735b1eda3160ee916524d5840926c01ea7a3291bbb4a462bd60f83", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n20\nSeptember 2024\nFigure 8. An illustration of the taxonomy diagram of the embedding models\nAlthough the deep neural network models require a lot more data and compute time to train, \nthey have much better performance compared to models using bag-of-words paradigms. \nFor example, for the same word the embeddings would be different with different contexts. \nSnippet 4 demonstrates how pre-trained document embedding models from Tensorflow-\nhub17 (for example,Sentence t5)A and Vertex AIB can be used for training models with Keras \nand TF datasets. Vertex Generative AI text embeddings can be used with the Vertex AI SDK, \nLangchain, and Google\u2019s BigQuery (Snippet 5) for embedding and advanced workflows.18\nA. Note: not all models on https://tfhub.dev/ can be commercially used. Please check the licenses of the models \nand the training datasets and consult the legal team before commercial usage. \nB. Note: not all models on https://tfhub.dev/ can be commercially used. Please check the licenses of the models \nand the training datasets and consult the legal team before commercial usage.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1118, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "31423d9a-efa1-426f-a259-9720da5af2de": {"__data__": {"id_": "31423d9a-efa1-426f-a259-9720da5af2de", "embedding": null, "metadata": {"page_label": "21", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c623fa36-2d98-4505-9e25-58df2db3a6ba", "node_type": "4", "metadata": {"page_label": "21", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "2af8793f637f7fd63a5097a27420c1e3d5937c4a1ca95621cf69ce5fa3259a5c", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n21\nSeptember 2024\nimport vertexai\nfrom vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n# Set the model name. For multilingual: use \"text-multilingual-embedding-002\"\nMODEL_NAME = \"text-embedding-004\"\n# Set the task_type, text and optional title as the model inputs.\n# Available task_types are \"RETRIEVAL_QUERY\", \"RETRIEVAL_DOCUMENT\", \n# \"SEMANTIC_SIMILARITY\", # \"CLASSIFICATION\", and \"CLUSTERING\"\nTASK_TYPE = \"RETRIEVAL_DOCUMENT\" \nTITLE = \"Google\"\nTEXT = \"Embed text.\"\n# Use Vertex LLM text embeddings\nembeddings_vx = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@004\")\ndef LLM_embed(text):\n    def embed_text(text):\n        text_inp = TextEmbeddingInput(task_type=\"CLASSIFICATION\",   text=text.numpy())\n        return np.array(embeddings_vx.get_embeddings([text_inp])[0].values)\n output = tf.py_function(func=embed_text, inp=[text], Tout=tf.float32)\n output.set_shape(( 768,))\n return  output\n# Embed strings using vertex LLMs\nLLM_embeddings=train_data.map(lambda x,y: (LLM_embed(x), y))\n# Embed strings in the tf.dataset using one of the tf hub models\nembedding = \"https://tfhub.dev/google/sentence-t5/st5-base/1\"\nhub_layer = hub.KerasLayer(embedding, input_shape=[],dtype=tf.string, trainable=True)\n                          \n# Train model \nmodel = tf.keras.Sequential()\nmodel.add(hub_layer) # omit this layer if using Vertex LLM embeddings\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\nmodel.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n  metrics=['accuracy'])\nhistory = model.fit(train_data.shuffle(100).batch(8))\nSnippet 4. Creating & integrating text embeddings (Vertex, Tfhub) into keras text classification models", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1766, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c61dc562-96a2-4acc-8eca-054479699c8c": {"__data__": {"id_": "c61dc562-96a2-4acc-8eca-054479699c8c", "embedding": null, "metadata": {"page_label": "22", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8da02310-cb83-45b9-a3d9-42cf63fe3d0b", "node_type": "4", "metadata": {"page_label": "22", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "7ff1b2212fbf12ebf9ea8e24e271d50294521a59604ef0091eea195772a01f5d", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n22\nSeptember 2024\nSELECT * FROM ML.GENERATE_TEXT_EMBEDDING(\nMODEL my_project.my_company.llm_embedding_model,\n(\nSELECT review as content\nFROM bigquery-public-data.imdb.reviews));\nSnippet 5. Creating LLM based text embeddings in BigQuery for selected columns in a table\nImage & multimodal embeddings\nMuch like text, it\u2019s also possible to create both image and multimodal embeddings. \nUnimodal image embeddings can be derived in many ways: one of which is by training a \nCNN or Vision Transformer model on a large scale image classification task (for example, \nImagenet), and then using the penultimate layer as the image embedding. This layer has \nlearnt some important discriminative feature maps for the training task. It contains a set of \nfeature maps that are discriminative for the task at hand and can be extended to other tasks \nas well. \nTo obtain multimodal embeddings19 you take the individual unimodal text and image \nembeddings and their semantic relationships learnt via another training process. This \ngives you a fixed size semantic representation in the same latent space. The below snippet \n(Snippet 6) can be used to compute image and multimodal embeddings for images and text \nand be used with a keras model directly (much like the text embedding example).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1301, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f0b8676e-eb5a-412d-9a4c-c91bec885880": {"__data__": {"id_": "f0b8676e-eb5a-412d-9a4c-c91bec885880", "embedding": null, "metadata": {"page_label": "23", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "37f6d1a1-eec4-46a4-9d61-a8377fe3e77e", "node_type": "4", "metadata": {"page_label": "23", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "254eb1dd7c6b61f85726d61c40217ebcf51f8ce1bd56d514372859f0b782dcd7", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n23\nSeptember 2024\nimport base64\nimport tensorflow as tf\nfrom google.cloud import aiplatform\nfrom google.protobuf import struct_pb2\n#fine-tunable layer for image embeddings which can be used for downstream keras model image_\nembed=hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/feature_\nvector/2\",trainable=False) \nclass EmbeddingPredictionClient:\n  \"\"\"Wrapper around Prediction Service Client.\"\"\"\n  def __init__(self, project : str,\n    location : str = \"us-central1\",\n    api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\"):\n    client_options = {\"api_endpoint\": api_regional_endpoint}\n    self.client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)  \n    self.location = location\n    self.project = project\n  def get_embedding(self, text : str = None, gs_image_path : str = None):\n   #load the image from a bucket in google cloud storage\n   with tf.io.gfile.GFile(gs_image_path, \"rb\") as f:\n     image_bytes = f.read()\n   if not text and not image_bytes:\n    raise ValueError('At least one of text or image_bytes must be specified.')\n   #Initialize a protobuf data struct with the text and image inputs \n   instance = struct_pb2.Struct()\n    if text:\n      instance.fields['text'].string_value = text\n      if image_bytes:\n      encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n      image_struct = instance.fields['image'].struct_value\n      image_struct.fields['bytesBase64Encoded'].string_value = .string_value = encoded_content\n     #Make predictions using the multimodal embedding model\n     instances = [instance]\n     endpoint = (f\"projects/{self.project}/locations/{self.location}\"\n         \"/publishers/google/models/multimodalembedding@001\")\n     response = self.client.predict(endpoint=endpoint, instances=instances)\n     text_embedding = None\n     if text:    \n      text_emb_value = response.predictions[0]['textEmbedding']\n      text_embedding = [v for v in text_emb_value]\n     image_embedding = None\n     if image_bytes:    \n      image_emb_value = response.predictions[0]['imageEmbedding']\n      image_embedding = [v for v in image_emb_value]\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2208, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cccee87d-679a-42ed-aaef-4bb452468758": {"__data__": {"id_": "cccee87d-679a-42ed-aaef-4bb452468758", "embedding": null, "metadata": {"page_label": "24", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ae706473-fef6-4555-b941-b301c04bb3cf", "node_type": "4", "metadata": {"page_label": "24", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "fd5603611a7684ade274f2cf1106a7112f8fa086b0507e52fdcbe613334ae6c9", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n24\nSeptember 2024\n return EmbeddingResponse (text_embedding=text_embedding, image_embedding=image_embedding)\n#compute multimodal embeddings for text and images\nclient.get_embedding(text=\"sample_test\", gs_image_path=\"gs://bucket_name../image_filename..\")\nSnippet 6. Using Vertex API to create Multimodal embeddings Graph embeddings\nStructured data embeddings\nThere are two common ways to generate embeddings for structured data, one is more \ngeneral while the other is more tailored for recommendation applications. \nUnlike unstructured data, where a pre-trained embedding model is typically available, we \nhave to create the embedding model for the structured data since it would be specific to \na particular application.\nGeneral structured data\nGiven a general structured data table, we can create embedding for each row. This can be \ndone by the ML models in the dimensionality reduction category, such as the PCA model.\nOne use case for these embeddings are for anomaly detection. For example, we can create \nembeddings for anomaly detection using large data sets of labeled sensor information \nthat identify anomalous occurrences.20 Another case use is to feed these embeddings \nto downstream ML tasks such as classification. Compared to using the original high-\ndimensional data, using embeddings to train a supervised model requires less data. This is \nparticularly important in cases where training data is not sufficient.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1456, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4141ad60-f6ee-4f8e-8fd9-52bbc307bbf7": {"__data__": {"id_": "4141ad60-f6ee-4f8e-8fd9-52bbc307bbf7", "embedding": null, "metadata": {"page_label": "25", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1c735c43-6bf2-4679-a6ae-6c96dd34e388", "node_type": "4", "metadata": {"page_label": "25", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "292b24b235283b17e2b6fe62049538c43f28a10c88a2be2a14f8b4e0e26999ea", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n25\nSeptember 2024\nUser/item structured data\nThe input is no longer a general structured data table as above. Instead, the input includes \nthe user data, item/product data plus the data describing the interaction between user and \nitem/product, such as rating score. \nThis category is for recommendation purposes, as it maps two sets of data (user dataset, \nitem/product/etc dataset) into the same embedding space. For recommender systems, we \ncan create embeddings out of structured data that correlate to different entities such as \nproducts, articles, etc. Again, we have to create our own embedding model. Sometimes this \ncan be combined with unstructured embedding methods when images or text descriptions \nare found.\nGraph embeddings\nGraph embeddings are another embedding technique that lets you represent not \nonly information about a specific object but also its neighbors (namely, their graph \nrepresentation). Take an example of a social network where each person is a node, and the \nconnections between people are defined as edges. Using graph embedding you can model \neach node as an embedding, such that the embedding captures not only the semantic \ninformation about the person itself, but also its relations and associations hence enriching \nthe embedding. For example, if two nodes are connected by an edge, the vectors for those \nnodes would be similar. You might then be able to predict who the person is most similar \nto and recommend new connections. Graph embeddings can also be used for a variety of \ntasks, including node classification, graph classification, link prediction, clustering, search, \nrecommendation systems, and more. Popular algorithms21,22 for graph embedding include \nDeepWalk, Node2vec, LINE, and GraphSAGE.23", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1777, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0479e479-642c-4587-ac7f-0af920a96e3e": {"__data__": {"id_": "0479e479-642c-4587-ac7f-0af920a96e3e", "embedding": null, "metadata": {"page_label": "26", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c980619e-9217-49e1-8fe9-366ddc34bc5d", "node_type": "4", "metadata": {"page_label": "26", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "cc38c98ca0d291254203bc8e6be85508504b9260c946f61b44765386c0925ed4", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n26\nSeptember 2024\nTraining Embeddings\nCurrent embedding models usually use dual encoder (two tower) architecture. For example, \nfor the text embedding model used in question-answering, one tower is used to encode \nthe queries and the other tower is used to encode the documents. For the image and text \nembedding model, one tower is used to encode the images and the other tower is used \nto encode the text. The model can have various sub architectures, depending on how the \nmodel components are shared between the two towers. The following figure shows some \narchitectures of the dual encoders.24 \nFigure 9. Some architectures of dual encoders\nThe loss used in embedding models training is usually a variation of contrastive loss, which \ntakes a tuple of <inputs, positive targets, [optional] negative targets> as the inputs. Training \nwith contrastive loss brings positive examples closer and negative examples far apart.\nSimilar to foundation model training, training of an embedding model from scratch usually \nincludes two stages: pretraining (unsupervised learning) and fine tuning (supervised \nlearning). Nowadays, the embedding models are usually directly initialized from foundation \nmodels such as BERT, T5, GPT, Gemini, CoCa. You can use these base models to leverage the \nmassive knowledge that has been learned from the large-scale pretraining of the foundation", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1402, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5aded843-1d04-47ba-aef4-d6e94839f559": {"__data__": {"id_": "5aded843-1d04-47ba-aef4-d6e94839f559", "embedding": null, "metadata": {"page_label": "27", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ebac492-01b5-4265-9a44-e4f1fb18a19e", "node_type": "4", "metadata": {"page_label": "27", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "dd98d51830fb9cccb28d5b149857c9991d69b5cd4b8632e0a39c17158e1e91b8", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n27\nSeptember 2024\nmodels. The fine-tuning of the embedding models can have one or more phases. The fine-\ntuning datasets can be created in various methods, including human labeling, synthetic \ndataset generation, model distillation, and hard negative mining.\nTo use embeddings for downstream tasks like classification or named entity recognition, \nextra layers (for example, softmax classification layer) can be added on top of the embedding \nmodels. The embedding model can either be frozen (especially when the training dataset is \nsmall), trained from scratch, or fine-tuned together with the downstream tasks. \nVertex AI provides the ability to customize the Vertex AI text embedding models.25 Users can \nalso choose to fine-tune the models directly. See26 for an example of fine tuning the BERT \nmodel using tensorflow model garden. You can also directly load the embedding models from \ntfhub and fine-tune on top of the model. Snippet 7 shows an example how to build a classifier \nbased on tfhub models. \n# Can switch the embedding to different embeddings from different modalities on # \ntfhub. Here we use the BERT model as an example.\ntfhub_link = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\nclass Classifier(tf.keras.Model):\n    def __init__(self, num_classes):\n      super(Classifier, self).__init__(name=\"prediction\")\n        self.encoder = hub.KerasLayer(tfhub_link, trainable=True)\n      self.dropout = tf.keras.layers.Dropout(0.1)\n      self.dense = tf.keras.layers.Dense(num_classes)\n    def call(self, preprocessed_text):\n      encoder_outputs = self.encoder(preprocessed_text)\n      pooled_output = encoder_outputs[\"pooled_output\"]\n   x = self.dropout(pooled_output)\n   x = self.dense(x)\n   return x\nSnippet 7. Creating a Keras model using trainable tfhub layer", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1826, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba5f0e82-8652-48c8-92b6-4e3a356c2e27": {"__data__": {"id_": "ba5f0e82-8652-48c8-92b6-4e3a356c2e27", "embedding": null, "metadata": {"page_label": "28", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "152c7edd-f75a-40fe-a572-aae9a00deda7", "node_type": "4", "metadata": {"page_label": "28", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "0e275d9a7463dfef3d15689037014c06c4514d458dd887e81515174b7e0ba80f", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n28\nSeptember 2024\nSo far you\u2019ve seen the various types of embeddings, techniques and best practices to train \nthem for various data modalities, and some of their applications. The next section discusses \nhow to persist and search the embeddings that have been created in a fast and scalable way \nfor production workloads.\nVector search\nFull-text keyword search has been the lynchpin of modern IT systems for years. Full-text \nsearch engines and databases (relational and non-relational) often rely on explicit keyword \nmatching. For example, if you search for \u2018cappuccino\u2019 the search engine or database returns \nall documents that mention the exact query in the tags or text description. However, if the \nkey word is misspelled or described with a differently worded text, a traditional keyword \nsearch returns incorrect or no results. There are traditional approaches which are tolerant of \nmisspellings and other typographical errors. However, they are still unable to find the results \nhaving the closest underlying semantic meanings to the query. This is where vector search is \nvery powerful: it uses the vector or embedded semantic representation of documents.\nVector search lets you to go beyond searching for exact query literals and allows you to \nsearch for the meaning across various data modalities. This provides you more nuanced \nresults. After you have a function that can compute embeddings of various items,  you \ncompute the embedding of the items of interest and store this embedding in a database. \nYou then embed the incoming query in the same vector space as the items. Next, you have \nto find the best matches to the query. This process is analogous to finding the most \u2018similar\u2019 \nmatches across the entire collection of searchable vectors: similarity between vectors can be \ncomputed using a metric such as euclidean distance, cosine similarity, or dot product.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1912, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69cd4dae-7747-44d6-9f27-fe6f9c9c072e": {"__data__": {"id_": "69cd4dae-7747-44d6-9f27-fe6f9c9c072e", "embedding": null, "metadata": {"page_label": "29", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "440c1cdf-de46-459d-9473-49ddabfaac93", "node_type": "4", "metadata": {"page_label": "29", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "c14a164c17040e93daa05d080209a5e2fc66eb9cfc63774d11fb73cdac5f30f5", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n29\nSeptember 2024\nFigure 10. Visualization of how different metrics compute vector similarity\nEuclidean distance (i.e., L2 distance) is a geometric measure of the distance between two \npoints in a vector space. This works well for lower dimensions. Cosine similarity is a measure \nof the angle between two vectors. And inner/dot product, is the projection of one vector \nonto another. They are equivalent when the vector norms are 1. This seems to work better \nfor higher dimensional data. Vector databases store and help manage and operationalize the \ncomplexity of vector search at scale, while also addressing the common database needs.\nImportant vector search algorithms\nThe most straightforward way to find the most similar match is to run a traditional linear \nsearch by comparing the query vector with each document vector and return the one with \nthe highest similarity. However, the runtime of this approach scales linearly (O(N)) with the \namount of documents or items to search. This approach is unacceptably slow for most use \ncases involving several millions of documents or more. Using approximate nearest neighbour", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1156, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "de28a565-020b-493f-99e1-97070e50e70f": {"__data__": {"id_": "de28a565-020b-493f-99e1-97070e50e70f", "embedding": null, "metadata": {"page_label": "30", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "17e56c55-41f6-47b4-a1a8-6b954de62e61", "node_type": "4", "metadata": {"page_label": "30", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "81e35952e6d93036ea515e9fb7e7a82f9fd9d3bcb51ec730aa760c90801bb1a9", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n30\nSeptember 2024\n(ANN) search for that purpose is more practical.  ANN is a technique for finding the closest \npoints to a given point in a dataset with a small margin of error - but with a tremendous boost \nin performance. There are many approaches with varying trade-offs across scale, indexing \ntime, performance, simplicity and more.27 They use one or more implementations of the \nfollowing techniques: quantization, hashing, clustering and trees, among others. Some of the \nmost popular approaches are discussed below.\nLocality sensitive hashing & trees\nLocality sensitive hashing (LSH) 28 is a technique for finding similar items in a large dataset. \nIt does this by creating one or more hash functions that map similar items to the same hash \nbucket with high probability. This means that you can quickly find all of the similar items to \na given item by only looking at the candidate items in the same hash bucket (or adjacent \nbuckets) and do a linear search amongst those candidate pairs. This allows for significantly \nfaster lookups within a specific radius. The number of hash functions/tables and buckets \ndetermine the search recall/speed tradeoff, as well as the false positive / true positive one. \nHaving too many hash functions might cause similar items to different buckets, while too few \nmight result in too many items falsely being hashed to the same bucket and the number of \nlinear searches to increase.\nAnother intuitive way to think about LSH is grouping residences by their postal code or \nneighborhood name. Then based on where someone chooses to move you look at the \nresidences for only that neighborhood and find the closest match.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1691, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d03e0ecb-0433-40f7-b9ad-f5bdb564a731": {"__data__": {"id_": "d03e0ecb-0433-40f7-b9ad-f5bdb564a731", "embedding": null, "metadata": {"page_label": "31", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eb32c2d7-3c92-4b4f-8b74-b9630fcfecce", "node_type": "4", "metadata": {"page_label": "31", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "0712caf685c4a3c05ebe3c2f66faeee64590da014c2440a5d32c68eac71e0e87", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n31\nSeptember 2024\nFigure 11. Visualization of how LSH uses random hyperplanes to partition the vector space\nTree-based algorithms work similarly. For example, the Kd-tree approach works by creating \nthe decision boundaries by computing the median of the values of the first dimension, then \nthat of the second dimension and so on. This approach is very much like a decision tree. \nNaturally this can be ineffective if searchable vectors are high dimensional. In that case, the \nBall-tree algorithm is better suited. It is similar in functionality, except instead of going by \ndimension-wise medians it creates buckets based on the radial distance of the data points \nfrom the center. Here is an example of the implementation of these three approaches:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 778, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7044f93-370f-4c57-a5e1-ce12ffaaca8f": {"__data__": {"id_": "b7044f93-370f-4c57-a5e1-ce12ffaaca8f", "embedding": null, "metadata": {"page_label": "32", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e6ed7066-287c-475c-b311-ef53fa8237fb", "node_type": "4", "metadata": {"page_label": "32", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "7634730957fa89b263528462982101c87bd454f28b8d31b21cf1d00f03ec2e0b", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n32\nSeptember 2024\nfrom sklearn.neighbors import NearestNeighbors\nfrom vertexai.language_models import TextEmbeddingModel\nfrom lshashing import LSHRandom\nimport numpy as np\nmodel = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@004\")\ntest_items= [\n  \"The earth is spherical.\",\n  \"The earth is a planet.\",\n  \"I like to eat at a restaurant.\"]\nquery = \"the shape of earth\"\nembedded_test_items = np.array([embedding.values for embedding in model.get_embeddings(test_items)])\nembedded_query = np.array(model.get_embeddings([query])[0].values)\n#Naive brute force search\nn_neighbors=2\nnbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='brute').fit(embedded_test_items) \nnaive_distances, naive_indices = nbrs.kneighbors(np.expand_dims(embedded_query, axis = 0))\n#algorithm- ball_tree due to high dimensional vectors or kd_tree otherwise\nnbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(embedded_test_items) \ndistances, indices = nbrs.kneighbors(np.expand_dims(embedded_query, axis = 0))\n#LSH\nlsh_random_parallel = LSHRandom(embedded_test_items, 4, parallel = True)\nlsh_random_parallel.knn_search(embedded_test_items, embedded_query, n_neighbors, 3, parallel = True)\n#output for all 3 indices = [0, 1] , distances [0.66840428, 0.71048843] for the first 2 neighbours\n#ANN retrieved the same ranking of items as brute force in a much scalable manner\nSnippet 8. Using scikit-learn 29  and lshashing 30  for ANN with LSH, KD/Ball-tree and linear search\nHashing and tree-based approaches can also be combined and extended upon to obtain \nthe optimal tradeoff between recall and latency for search algorithms. FAISS with HNSW and \nScaNN are good examples.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1711, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9743d0dc-80e4-40a5-ab96-edde0a4bc09a": {"__data__": {"id_": "9743d0dc-80e4-40a5-ab96-edde0a4bc09a", "embedding": null, "metadata": {"page_label": "33", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1bb37ad9-bbac-4507-b8cc-db3520831e02", "node_type": "4", "metadata": {"page_label": "33", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "d8a6e1ce76671e477c38eccc08d780b7355d506249d0c92cb2f01b7704f03434", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n33\nSeptember 2024\nHierarchical navigable small worlds \nFigure 12. Diagram showing how HNSW \u2018zooms in\u2019 to perform ANN\nOne of the FAISS (Facebook AI similarity search) implementations leverages the concept \nof hierarchical navigable small world (HNSW) 31 to perform vector similarity search in sub-\nlinear (O(Logn)) runtime with a good degree of accuracy. A HNSW is a proximity graph with a \nhierarchical structure where the graph links are spread across different layers. The top layer \nhas the longest links and the bottom layer has the shortest ones. As shown in Figure 9, the \nsearch starts at the topmost layer where the algorithm greedily traverses the graph to find \nthe vertex most semantically similar to the query. Once the local minimum for that layer is \nfound, it then switches to the graph for the closest vertex on the layer below. This process \ncontinues iteratively until the local minimum for the lowest layer is found, with the algorithm \nkeeping track of all the vertices traversed to return the K-nearest neighbors. This algorithm \ncan be optionally augmented with quantization and vector indexing to boost speed and \nmemory efficiency.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1182, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dfc46287-0e58-4728-a84d-6ccc624edda5": {"__data__": {"id_": "dfc46287-0e58-4728-a84d-6ccc624edda5", "embedding": null, "metadata": {"page_label": "34", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6efa7c17-ec93-4947-8bda-ff857bb1a138", "node_type": "4", "metadata": {"page_label": "34", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "7641999d4666a835d5117d3fc3be92f5eaa8f86a0639ffe396b825e2da2b68c8", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n34\nSeptember 2024\nimport faiss\nM=32 #creating high degree graph:higher recall for larger index & searching time\nd=768 # dimensions of the vectors/embeddings\nindex = faiss.IndexHNSWFlat(d, M)\nindex.add(embedded_test_items) #build the index using the embeddings in Snippet 9\n#execute the ANN search\nindex.search(np.expand_dims(embedded_query, axis=0), k=2)\nSnippet 9. Indexing and executing ANN search with the FAISS library using HNSW\nScaNN\nGoogle developed the scalable approximate nearest neighbor (ScaNN)32,33 approach which is \nused across a lot of its products and services. This includes being externally available to all \ncustomers of Google Cloud through the Vertex AI Vector Search. Below is how ScaNN uses \na variety of steps to perform efficient vector search, with each one of them having their own \nsubset of parameters. \nThe first step is the optional partitioning step during training: it uses one of the multiple \nalgorithms available to partition the vector store into logical partitions/clusters where \nthe semantically related are grouped together. The partitioning step is optional for small \ndatasets. However, for larger datasets with >100k embedding vectors, the partitioning step \nis crucial since by pruning the search space it cuts down the search space by magnitudes \ntherefore significantly speeds up the query. The space pruning is configured through the \nnumber of partitions and the number of partitions to search. A larger number leads to better \nrecall but larger partition creation time. A good heuristic is to set the number of partitions to \nbe the square root of the number of vectors.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1648, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "43757b94-79ff-4dd2-9c31-bd81e9059af8": {"__data__": {"id_": "43757b94-79ff-4dd2-9c31-bd81e9059af8", "embedding": null, "metadata": {"page_label": "35", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a057ce88-4814-48ba-8a36-e0ab1ef478c1", "node_type": "4", "metadata": {"page_label": "35", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "8a6e66a958622e2433fe9f9848991d60b879626baf8de2e265162e530ac9a6af", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n35\nSeptember 2024\nFigure 13. Search space partitioning & pruning(left) & Approximate scoring (right)\nAt query time ScaNN uses the user-specified distance measure to select the specified \nnumber of top partitions (a value specified by the user), and then executes the scoring \nstep next. In this step ScaNN compares the query with all the points in the top partitions \nand selects the top K\u2019. This distance computation can be configured as exact distance or \napproximate distance. The approximate distance computation leverages either standard \nproduct quantization or anisotropic quantization techniques, the latter of which is a specific \nmethod employed by ScaNN which gives the better speed and accuracy tradeoffs.\nFinally, as a last step the user can optionally choose to rescore the user specified top K \nnumber of results more accurately. This results in an industry leading speed/accuracy \ntradeoff ScaNN is known for as can be inferred from Figure 14. Snippet 10 shows a \ncode example.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1ebf39cc-38be-4d21-a657-16b7ceb5b364": {"__data__": {"id_": "1ebf39cc-38be-4d21-a657-16b7ceb5b364", "embedding": null, "metadata": {"page_label": "36", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "74b7fd9d-655a-4263-9710-0d52284273b6", "node_type": "4", "metadata": {"page_label": "36", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "1fad4ccb55e76098b7ec76ac1ac60814c8db6b69406e35b2c3a88d592ab2a889", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n36\nSeptember 2024\nFigure 14. Accuracy/speed tradeoffs for various SOTA ANN search algorithms\nimport tensorflow as tf\nimport tensorflow_recommenders as tfrs\nfrom vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n# Embed documents & query(from snip 9.) and convert them to tensors and tf.datasets\nembedded_query = tf.constant((LM_embed(query, \"RETRIEVAL_QUERY\")))\nembedded_docs = [LM_embed(doc, \"RETIREVAL_DOCUMENT\") for doc in searchable_docs]\nembedded_docs = tf.data.Dataset.from_tensor_slices(embedded_docs).enumerate().batch(1)\n# Build index from tensorflow dataset and execute ANN search based on dot product metric\nscann = tfrs.layers.factorized_top_k.ScaNN( \n  distance_measure= 'dot_product',\n  num_leaves = 4, #increase for higher number of partitions / latency for increased recall\n  num_leaves_to_search= 2) # increase for higher recall but increased latency\nscann = scann.index_from_dataset(embedded_docs)\nscann(embedded_query, k=2)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 990, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0a8dbd8a-c8e1-4d3c-abb8-6b20ab56b234": {"__data__": {"id_": "0a8dbd8a-c8e1-4d3c-abb8-6b20ab56b234", "embedding": null, "metadata": {"page_label": "37", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "24646fbf-2a6e-492e-b019-5ed08b7f03b6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "540b7df7071b25ba75f8f9e755cf9edafc936dcbd28246a5a1f49201e25bf2a1", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n37\nSeptember 2024\nSnippet 10. Using Tensorflow Recommenders 34  to perform ANN search using the ScaNN algorithm\nIn this whitepaper we have seen both State-of-the-Art SOTA and traditional ANN search \nalgorithms: ScaNN, FAISS , LSH, KD-Tree, and Ball-tree, and examined the  great speed/\naccuracy tradeoffs that they provide. However, to use these algorithms they need to \nbe deployed in a scalable, secure and production-ready manner. For that we need \nvector databases.\nVector databases \nVector embeddings embody semantic meanings of data, while vector search algorithms \nprovide a means for efficiently querying them. Historically traditional databases lacked the \nmeans to combine semantic meaning and efficient querying  in a way that the most relevant \nembeddings can be both stored, queried, and retrieved in a secure, scalable, and flexible \nmanner for complex analysis and real-time enterprise grade applications. This is what \ngave rise to vector databases, which are built ground-up to manage these embeddings for \nproduction scenarios. Due to the recent popularity of Generative AI, an increasing number \nof traditional databases are starting to incorporate supporting vector search functionality \nas well in addition to traditional search (\u2018hybrid search\u2019) functionalities. Let\u2019s look at the \nworkflow for a simple Vector Database, with hybrid search capabilities.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1402, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b3fd87d-63cd-4590-be2f-60cf7b58116d": {"__data__": {"id_": "6b3fd87d-63cd-4590-be2f-60cf7b58116d", "embedding": null, "metadata": {"page_label": "38", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a6e2c600-cd3a-47ad-8744-69a6e6185316", "node_type": "4", "metadata": {"page_label": "38", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "62b0b380b2ee76088692367214f01407abc6693f005364642368a275a2afb9fd", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n38\nSeptember 2024\nFigure 15. Populating and querying vector databases\nEach vector database differs in its implementation, but the general flow is shown in Figure 15:\n1. An appropriate trained embedding model is used to embed the relevant data points as \nvectors with fixed dimensions. \n2. The vectors are then augmented with appropriate metadata and complementary \ninformation (such as tags) and indexed using the specified algorithm for efficient search.\n3. An incoming query gets embedded with the same model, and used to query and return  \nspecific amounts of the most semantically similar items and their associated unembedded \ncontent/metadata. Some databases might provide caching and pre-filtering (based on \ntags) and post-filtering capabilities (reranking using another more accurate model) to \nfurther enhance the query speed and performance.\nThere are quite a few vector databases available today, each tailored to different business \nneeds and considerations. A few good examples of commercially managed vector databases \ninclude Google Cloud\u2019s Vertex Vector Search,35 Google Cloud\u2019s AlloyDB & Cloud SQL \nPostgres ElasticSearch,36 and Pinecone37 to name a few. Vertex AI Vector Search is a vector \ndatabase built by Google that uses the ScaNN algorithm for fast vector search, while still \nmaintaining all the security and access guarantees of Google Cloud. AlloyDB & Cloud SQL \nPostgres supports vector search through the OSS pgvector38 extension, which allows for \nSQL queries to combine ANN search with traditional predicates and the usual transactional \nsemantics for ANN search index. AlloyDB also has a ScaNN index extension that is a native \nimplementation of ScaNN and is pgvector-compatible. Similarly, many of the other traditional \ndatabases have also started to add plugins to enable vector search. Pinecone and Weaviate \nleverage HNSW for their fast vector search in addition to the ability to filter data using", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1963, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8ef6725-a6ef-4fb7-b692-c941e95bf3f4": {"__data__": {"id_": "d8ef6725-a6ef-4fb7-b692-c941e95bf3f4", "embedding": null, "metadata": {"page_label": "39", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fe0b76b5-f71c-467a-8397-9a9b34d0f71a", "node_type": "4", "metadata": {"page_label": "39", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "420432e12e5201c5604e1fec3258ff798208ba082779189f366f8f720bd3dff3", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n39\nSeptember 2024\ntraditional search. Amongst their open source peers: Weaviate39 and ChromaDB40 provide a \nfull suite of functionality upon deployment and can be tested in memory as well during the \nprototyping phase.\nOperational considerations\nVector Databases are critical to managing the majority of technical challenges that arise \nwith storing and querying embeddings at scale. Some of these challenges are specific to the \nnature of vector stores, while others overlap with that of traditional databases. These include \nhorizontal and vertical scalability, availability, data consistency, real time updates, backups, \naccess control, compliance, and much more. However, there are also many more challenges \nand considerations you need to take into account while using embedding and vector stores.\nFirstly, embeddings, unlike traditional content, can mutate over time. This means that the \nsame text, image, video or other content could and should be embedded using different \nembedding models to optimize for the performance of the downstream applications. This is \nespecially true for embeddings of supervised models after the model is retrained to account \nfor various drifts or changing objectives. Similarly, the same applies to unsupervised models \nwhen they are updated to a newer model. However, frequently updating the embeddings \n- especially those trained on large amounts of data - can be prohibitively expensive. \nConsequently, a balance needs to be struck. This necessitates a well-defined automated \nprocess to store, manage, and possibly purge embeddings from the vector databases taking \nthe budget into consideration.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1668, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "565787b4-713f-4dee-984e-e7bbf4176654": {"__data__": {"id_": "565787b4-713f-4dee-984e-e7bbf4176654", "embedding": null, "metadata": {"page_label": "40", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5258a212-690a-4c23-8440-7e008902d260", "node_type": "4", "metadata": {"page_label": "40", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "1b48da7fa91e1bf14c7ef76eeeb865136c6d9a945ba47fbc81ae4c19cb0269c0", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n40\nSeptember 2024\nSecondly, while embeddings are great at representing semantic information, sometimes they \ncan be suboptimal at representing literal or syntactic information. This is especially true for \ndomain-specific words or IDs. These values are potentially missing or underrepresented \nin the data the embeddings models were trained on. For example, if a user enters a query \nthat contains the ID of a specific number along with a lot of text, the model might find \nsemantically similar neighbors which match the meaning of the text closely, but not the ID, \nwhich is the most important component in this context. You can overcome this challenge by \nusing a combination of full-text search to pre-filter or post-filter the search space before \npassing it onto the semantic search module.\nAnother important point to consider is that depending on the nature of the workload in which \nthe semantic query occurs, it might be worth relying on different vector databases. For \nexample, for OLTP workloads that require frequent reads/write operations, an operational \ndatabase like Postgres or CloudSQL is the best choice. For large-scale OLAP analytical \nworkloads and batch use cases, using Bigquery\u2019s vector search is preferable.\nIn conclusion, a variety of factors need to be considered when choosing a vector database. \nThese factors include size and type of your dataset (some are good at sparse and others \ndense), business needs, the nature of the workload,  budget, security, privacy guarantees, \nthe needs for semantic and syntactic search as well as the database systems that are already \nin use. In this section we have seen the various ANN search approaches as well the need and \nbenefits of vector databases. The next section demonstrates an example of using a Vector AI \nVector Search for semantic search.\nApplications\nEmbeddings models are one of the fundamental machine learning models that power a \nvariety of applications. We summarize some popular applications in the following table.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2032, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8a7ddbad-e933-4020-88e2-6df80559d856": {"__data__": {"id_": "8a7ddbad-e933-4020-88e2-6df80559d856", "embedding": null, "metadata": {"page_label": "41", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "26761a96-e5a1-47ea-95a6-4373f37f48a1", "node_type": "4", "metadata": {"page_label": "41", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "42bebf229e0f64c65e1e4310e1eacf67d1934761cb86578efd2d3f9e514bf385", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n41\nSeptember 2024\nTask Description\nRetrieval\nGiven a query and a set of objects (for example, documents, images, \nand videos), retrieve the most relevant objects. Based on the definition \nof relevant objects, the subtasks include question answering and \nrecommendations.\nSemantic text similarity\nDetermine whether two sentences have the same semantic meaning. \nThe subtasks include: paraphrasing, duplicate detection, and bitext \nmining.\nClassification\nClassify objects into possible categories. Based on the number of labels, \nthe subtasks include binary classification, multi-class classification, and \nmultilabel classifications.\nClustering Cluster objects together.\nReranking Rerank a set of objects based on a certain query.\n \nEmbeddings together with vector stores providing ANN can be powerful tools which can be \nused for a variety of applications. These include Retrieval augmented Generation for LLMs, \nSearch, Recommendation Systems, Anomaly detection, few shot- classification and much \nmore. \nFor ranking problems like search and recommendations, embeddings are normally used \nat the first stage of the process. They retrieve the potentially good candidates that are \nsemantically similar and consequently improve the relevance of search results. Since the \namount of information to sort through can be quite large (in some cases even millions or \nbillions) ANN techniques like ScaNN greatly aids in scalably narrowing the search space. \nLet\u2019s look at an application which combines both LLMs and RAG to help answer questions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1565, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f323ee4e-084a-4c1c-9570-a76eec72dc6f": {"__data__": {"id_": "f323ee4e-084a-4c1c-9570-a76eec72dc6f", "embedding": null, "metadata": {"page_label": "42", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "449bee29-05b6-4d00-ac43-bfc7df81cbc4", "node_type": "4", "metadata": {"page_label": "42", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "c7b3da8acfc62c1cf3d2c88fec68821a1524e615f4a85874fd24d3fe6e4e604a", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n42\nSeptember 2024\nQ & A with sources (retrieval augmented generation)\nRetrieval augmented generation (RAG) for Q&A is a technique that combines the best of both \nworlds from retrieval and generation. It first retrieves relevant documents from a knowledge \nbase and then uses prompt expansion to generate an answer from those documents. Prompt \nexpansion is a technique that when combined with database search can be very powerful. \nWith prompt expansion the model retrieves relevant information from the database (mostly \nusing a combination of semantic search and business rules), and augments the original \nprompt with it. The model uses this augmented prompt to generate much more interesting, \nfactual, and informative content than with retrieval or generation alone.\nRAGs can help with a common problem with LLMs: their tendency to \u2018hallucinate\u2019 and \ngenerate factually incorrect but plausible sounding responses. Although RAG can reduce \nhallucinations, it does not completely eliminate them. What can help mitigate this problem \nfurther is to also return the sources from the retrieval and do a quick coherence check either \nby a human or an LLM. This ensures the LLM response is consistent with the semantically \nrelevant sources. Let\u2019s look at an example (Snippet 11 and 12) of RAG with sources, which can \nbe scalably implemented using Vertex AI LLM text embeddings and Vertex AI Vector Search \nin conjunction with libraries like langchain.41 We start with the initial setup in Snippet 11.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1526, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b62fff5-73de-463a-9365-e084ad09afe5": {"__data__": {"id_": "0b62fff5-73de-463a-9365-e084ad09afe5", "embedding": null, "metadata": {"page_label": "43", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9570b23a-0a7d-416f-85be-58fd624dd6f6", "node_type": "4", "metadata": {"page_label": "43", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "3f48d53d908993657defc371cd01d65b79608d0a0df71ad90e53663432986f5f", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n43\nSeptember 2024\n# Before you start run this command:\n# pip install --upgrade --user --quiet google-cloud-aiplatform langchain_google_vertexai\n# after running pip install make sure you restart your kernel\n# TODO : Set values as per your requirements\n# Project and Storage Constants\nPROJECT_ID = \"<my_project_id>\"\nREGION = \"<my_region>\"\nBUCKET = \"<my_gcs_bucket>\"\nBUCKET_URI = f\"gs://{BUCKET}\"\n# The number of dimensions for the textembedding-gecko@004 is 768\n# If other embedder is used, the dimensions would probably need to change.\nDIMENSIONS = 768\n# Index Constants\nDISPLAY_NAME = \"<my_matching_engine_index_id>\"\nDEPLOYED_INDEX_ID = \"yourname01\" # you set this. Start with a letter.\nfrom google.cloud import aiplatform\nfrom langchain_google_vertexai import VertexAIEmbeddings\naiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\nembedding_model = VertexAIEmbeddings (model_name=\"textembedding-gecko@003\")\n# NOTE : This operation can take upto 30 seconds\nmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n    display_name=DISPLAY_NAME,\n    dimensions=DIMENSIONS,\n    approximate_neighbors_count=150,\n    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n    index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n)\n# Create an endpoint\nmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n    display_name=f\"{DISPLAY_NAME}-endpoint\", public_endpoint_enabled=True\n)\n# NOTE : This operation can take upto 20 minutes\nmy_index_endpoint = my_index_endpoint.deploy_index(\n    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID\n)\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1656, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "17a065ce-af25-40d8-b3b5-1178a09eddb3": {"__data__": {"id_": "17a065ce-af25-40d8-b3b5-1178a09eddb3", "embedding": null, "metadata": {"page_label": "44", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d1d7d505-320b-4596-a384-e0e1ccc66db7", "node_type": "4", "metadata": {"page_label": "44", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "ed4a9e8bd5ae7c69ab4a8615cb6841a439dde58b81ed6975215c652820f5644e", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n44\nSeptember 2024\nSnippet 11. Setting up the network and environment\nmy_index_endpoint.deployed_indexes\n# TODO : replace 1234567890123456789 with your acutial index ID\nmy_index = aiplatform.MatchingEngineIndex(\"1234567890123456789\")\n# TODO : replace 1234567890123456789 with your acutial endpoint ID\n# Be aware that the Index ID differs from the endpoint ID\nmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\"1234567890123456789\")\nfrom langchain_google_vertexai import (\n    VectorSearchVectorStore,\n    VectorSearchVectorStoreDatastore,\n)\n# Input texts\ntexts = [\n    \"The cat sat on\",\n    \"the mat.\",\n    \"I like to\",\n    \"eat pizza for\",\n    \"dinner.\",\n    \"The sun sets\",\n    \"in the west.\",\n]\n# Create a Vector Store\nvector_store = VectorSearchVectorStore.from_components(\n    project_id=PROJECT_ID,\n    region=REGION,\n    gcs_bucket_name=BUCKET,\n    index_id=my_index.name,\n    endpoint_id=my_index_endpoint.name,\n    embedding=embedding_model,\n    stream_update=True,\n)\n# Add vectors and mapped text chunks to your vectore store\nvector_store.add_texts(texts=texts)\n# Initialize the vectore_store as retriever\nretriever = vector_store.as_retriever()\n# perform simple similarity search on retriever\nretriever.invoke(\"What are my options in breathable fabric?\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1300, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dd99c6e4-5759-4baa-8378-a9927d1f0d80": {"__data__": {"id_": "dd99c6e4-5759-4baa-8378-a9927d1f0d80", "embedding": null, "metadata": {"page_label": "45", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58de7747-74f4-4cc4-a446-fba876ddc04a", "node_type": "4", "metadata": {"page_label": "45", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "f937f9001df088ed0ff0e2609dea121214845aa6d1b5aa91bc56344c1d394545", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n45\nSeptember 2024\nThen we setup and initialize the Vector AI Vector Searc engine ANN index using Vertex text \nembeddings and then use the Vertex LLMs to do prompt expansion using semantic search. \nThis both grounds the LLMs in factuality and provides sources as well (Snippet 13).\n# Create dummy embeddings to initialize the vector store\nembeddings_vx = VertexAIEmbeddings()\ninitial_config = {\n  \"id\": str(uuid.uuid4()),\n  \"embedding\": [float(x) for x in list(embeddings_vx.embed_documents(test_items)[0])], \n}\nwith open(\"data.json\", \"w\") as f:\n  json.dump(initial_config, f)\n#magic command to be run on terminal or jupyter notebooks\n!gsutil cp data.json {EMBEDDING_DIR}/file.json\n# Create dummy embeddings to initialize the vector store\naiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\nmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n  display_name=DISPLAY_NAME,\n  contents_delta_uri=EMBEDDING_DIR,\n  dimensions=DIMENSIONS,\n  leafNodeEmbeddingCount=1000,\n  fractionLeafNodesToSearch=0.1,\n  approximate_neighbors_count=2,\n  distance_measure_type=\"DOT_PRODUCT_DISTANCE\")\nmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n  display_name=f\"{DISPLAY_NAME}-endpoint\",\n  network=VPC_NETWORK_FULL)\nmy_index_endpoint = my_index_endpoint.deploy_index(\n  index=my_index, deployed_index_id=DEPLOYED_INDEX_ID\n) \n#initialize Langchain retriever and add text embeddings to index\ntexts = [\n \"The earth is spherical.\",\n \"The earth is a planet.\",\n \"I like to eat at a restaurant.\",\n]\nvector_store = MatchingEngine.from_components(\n  project_id=PROJECT_ID,\n  region=REGION,\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1669, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba66c8f2-b8d7-4a08-9e53-ff11ffab077c": {"__data__": {"id_": "ba66c8f2-b8d7-4a08-9e53-ff11ffab077c", "embedding": null, "metadata": {"page_label": "46", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "485a1c3e-c2da-44f4-b9ec-ccd26efe7238", "node_type": "4", "metadata": {"page_label": "46", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "9950eeacc2f602a332475ea8c18e1f8eec22dd5a4d7d9a9f6cb86e041d00d410", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n46\nSeptember 2024\n  gcs_bucket_name=BUCKET_URI,\n  index_id=my_index.name,\n  endpoint_id=my_index_endpoint.name,\n  embedding=embeddings_vx\n)\nvector_store.add_texts(texts=texts)\nretriever=vector_store.as_retriever(search_kwargs={'k':1 })\n#Create Retrieval augmented few-shot prompts to provide context to ground LLMs\nprompt_template=\"\"\"You are David, an AI knowledge bot. \nAnswer the questions using the facts provided. Use the following pieces of context to answer \nthe users question\nIf you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n{summaries}\"\"\"\nmessages = [\n    SystemMessagePromptTemplate.from_template(prompt_template),\n    HumanMessagePromptTemplate.from_template(\"{question}\")\n]\nprompt = ChatPromptTemplate.from_messages(messages)\nchain_type_kwargs = {\"prompt\": prompt}\nllm = VertexAI() \n#build your chain for RAG+C\nchain= RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", \nretriever=retriever, return_source_documents=True)\n#print your results with Markup language\ndef print_result(result):\n  output_text = f\"\"\"### Question: \n  {query}\n  ### Answer: \n  {result['result']}\n  ### Source: \n  {' '.join(list(set([doc.page_content for doc in result['source_documents']])))}\n  \"\"\"\n  return(output_text)\nquery = \"What shape is the planet where humans live?\"\nresult = chain(query)\ndisplay(Markdown(print_result(result)))\nSnippet 12. Build/deploy ANN Index for Vertex Matching engine and use RAG with LLM prompts to generate \ngrounded results/sources", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1526, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a9039537-9d94-4dbc-bafc-8c694044db96": {"__data__": {"id_": "a9039537-9d94-4dbc-bafc-8c694044db96", "embedding": null, "metadata": {"page_label": "47", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed5996f2-250e-4290-9b86-c404faf8dccc", "node_type": "4", "metadata": {"page_label": "47", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "78f758e292af28cfc6bffb4439eb6b1d4fe1f54ffd2a71f1141ace8d933ecd98", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n47\nSeptember 2024\nFigure 16. Model responses along with sources demonstrating the LLM being grounded in the database\nAs we can infer from Figure 16, the output not only grounds LLM in the semantically similar \nresults retrieved from the database (hence refusing to answer when context cannot be found \nin the database). This not only significantly reduces hallucination, but also provides sources \nfor verification, either human or using another LLM.\nSummary\nIn this whitepaper we have discussed various methods to create, manage, store, and retrieve \nembeddings of various data modalities effectively in the context of production-grade \napplications. Creating, maintaining and using embeddings for downstream applications can \nbe a complex task that involves several roles in the organization. However, by thoroughly \noperationalizing and automating its usage, you can safely leverage the incredible benefits \nthey offer across some of the most important applications. Some key takeaways from this \nwhitepaper include:\n1. Choose your embedding model wisely for your data and use case. Ensure the data used in \ninference is consistent with the data used in training. The distribution shift from training to \ninference can come from various areas, including domain distribution shift or downstream", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1323, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d64d6fe8-1747-40b0-9801-951447f3a1a8": {"__data__": {"id_": "d64d6fe8-1747-40b0-9801-951447f3a1a8", "embedding": null, "metadata": {"page_label": "48", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c797e5cf-5ca0-430c-9e3f-20eb20f77bc6", "node_type": "4", "metadata": {"page_label": "48", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "5724c77d34c4348e52751e5450c5aba4a30d359e0b6df884aed99edfec5f3521", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n48\nSeptember 2024\ntask distribution shift. If no existing embedding models fit the current inference data \ndistribution, fine-tuning the existing model can significantly help on the performance. \nAnother tradeoff comes from the model size. The large deep neural network (large \nmultimodal models) based models usually have better performance but can come with a \ncost of longer serving latency. Using Cloud-based embedding services can conquer the \nabove issue by providing both high-quality and low-latency embedding service. For most \nbusiness applications using a pre-trained embedding model provides a good baseline, \nwhich can be further fine-tuned or integrated in downstream models. In case the data has \nan inherent graph structure, graph embeddings can provide superior performance.\n2. Once your embedding strategy is defined, it\u2019s important to make the choice of the \nappropriate vector database that suits your budget and business needs. It might seem \nquicker to prototype with available open source alternatives, but opting for a more secure, \nscalable, and battle-tested managed vector database is certain to be better off in the long \nterm. There are various open source alternatives using one of the many powerful ANN \nvector search algorithms, but ScaNN and HNSW have proven to provide some of the best \naccuracy and performance trade offs in that order.\n3. Embeddings combined with an appropriate ANN powered vector database is an \nincredibly powerful tool and can be leveraged for various applications, including \nSearch, Recommendation systems, and Retrieval augment generation for LLMs. This \napproach can mitigate the hallucination problem and bolster verifiability and trust of \nLLM-based systems.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1747, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a5d213a-18d9-42be-a17c-74d921a27a27": {"__data__": {"id_": "1a5d213a-18d9-42be-a17c-74d921a27a27", "embedding": null, "metadata": {"page_label": "49", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ea525757-0554-4628-bc77-af600cf1060f", "node_type": "4", "metadata": {"page_label": "49", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "4711a9a1d8e5158dc2f20eb75f77204ea6b1588e60c449a78009377f10246fbd", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n49\nSeptember 2024\nEndnotes\n1. Rai, A., 2020, Study of various methods for tokenization. In Advances in Natural Language Processing. \nAvailable at: https://doi.org/10.1007/978-981-15-6198-6_18\n2. Pennington, J., Socher, R. & Manning, C., 2014, GloVe: Global Vectors for Word Representation. [online] \nAvailable at: https://nlp.stanford.edu/pubs/glove.pdf .\n3. Shazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q. V. & Hinton, G., 2016, Swivel: Improving embeddings \nby noticing what's missing. ArXiv, abs/1602.02215. Available at: https://arxiv.org/abs/1602.02215 .\n4. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. & Dean, J., 2013, Efficient estimation of word representations \nin vector space. ArXiv, abs/1301.3781. Available at: https://arxiv.org/pdf/1301.3781.pdf .\n5. Rehurek, R., 2021, Gensim: open source python library for word and document embeddings. Available \nat: https://radimrehurek.com/gensim/intro.html .\n6. Bojanowski, P., Grave, E., Joulin, A. & Mikolov, T., 2016, Enriching word vectors with subword information. \nArXiv, abs/1607.04606. Available at: https://arxiv.org/abs/1607.04606.\n7. Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R., 1990, Indexing by latent \nsemantic analysis. Journal of the American Society for Information Science, 41(6), pp. 391-407.\n8. Blei, D. M., Ng, A. Y., & Jordan, M. I., 2001, Latent Dirichlet allocation. In T. G. Dietterich, S. Becker, & Z. \nGhahramani (Eds.), Advances in Neural Information Processing Systems 14. MIT Press, pp. 601-608. Available \nat: https://proceedings.neurips.cc/paper/2001/hash/296472c9542ad4d4788d543508116cbc-Abstract.html .\n9. Muennighoff, N., Tazi, N., Magne, L., & Reimers, N., 2022, Mteb: Massive text embedding benchmark. ArXiv, \nabs/2210.07316. Available at: https://arxiv.org/abs/2210.07316 .\n10. Le, Q. V., Mikolov, T., 2014, Distributed representations of sentences and documents. ArXiv, abs/1405.4053. \nAvailable at: https://arxiv.org/abs/1405.4053 .\n11. Devlin, J., Chang, M. W., Lee, K., & Toutanova, K., 2019, BERT: Pre-training deep Bidirectional Transformers \nfor Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the \nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), \npp. 4171-4186. Available at: https://www.aclweb.org/anthology/N19-1423/ .\n12. Reimers, N. & Gurevych, I., 2020, Making monolingual sentence embeddings multilingual using knowledge \ndistillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing \n(EMNLP), pp. 254-265. Available at: https://www.aclweb.org/anthology/2020.emnlp-main.21/ .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2707, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ca1f1b7c-06aa-46a8-bc44-5cf72e9cb6ae": {"__data__": {"id_": "ca1f1b7c-06aa-46a8-bc44-5cf72e9cb6ae", "embedding": null, "metadata": {"page_label": "50", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5b2a82d7-049d-4fe9-9e15-746007572c5c", "node_type": "4", "metadata": {"page_label": "50", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "9ce0d359d3000ed564ebaf124dfe86cc89c0b3e8ddf3fae37ac7be5c06018054", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n50\nSeptember 2024\n13. Gao, T., Yao, X. & Chen, D., 2021, Simcse: Simple contrastive learning of sentence embeddings. ArXiv, \nabs/2104.08821. Available at: https://arxiv.org/abs/2104.08821 .\n14. Wang, L., Yang, N., Huang, X., Jiao, B., Yang, L., Jiang, D., Majumder, R. & Wei, F., 2022, Text embeddings by \nweakly supervised contrastive pre-training. ArXiv. Available at: https://arxiv.org/abs/2201.01279 .\n15. Khattab, O. & Zaharia, M., 2020, colBERT: Efficient and effective passage search via contextualized late \ninteraction over BERT. In Proceedings of the 43rd International ACM SIGIR Conference on Research and \nDevelopment in Information Retrieval, pp. 39-48. Available at: https://dl.acm.org/doi/10.1145/3397271.3401025 .\n16. Lee, J., Dai, Z., Duddu, S. M. K., Lei, T., Naim, I., Chang, M. W. & Zhao, V. Y., 2023, Rethinking the role of token \nretrieval in multi-vector retrieval. ArXiv, abs/2304.01982. Available at: https://arxiv.org/abs/2304.01982 .\n17. TensorFlow, 2021, TensorFlow hub, a model zoo with several easy to use pre-trained models. Available \nat: https://tfhub.dev/.\n18. Zhang, W., Xiong, C., & Zhao, H., 2023, Introducing BigQuery text embeddings for NLP tasks.  \nGoogle Cloud Blog. Available at: https://cloud.google.com/blog/products/data-analytics/introducing  \n- bigquery-text-embeddings .\n19. Google Cloud, 2024, Get multimodal embeddings. Available at:  \nhttps://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings .\n20. Pinecone, 2024, IT Threat Detection. [online] Available at: https://docs.pinecone.io/docs/it-threat-detection .\n21. Cai, H., Zheng, V. W., & Chang, K. C., 2020, A survey of algorithms and applications related with graph \nembedding. In Proceedings of the 29th ACM International Conference on Information & Knowledge \nManagement. Available at: https://dl.acm.org/doi/10.1145/3444370.3444568 .\n22. Cai, H., Zheng, V. W., & Chang, K. C., 2017, A comprehensive survey of graph embedding: problems, \ntechniques and applications. ArXiv, abs/1709.07604. Available at: https://arxiv.org/pdf/1709.07604.pdf.\n23. Hamilton, W. L., Ying, R. & Leskovec, J., 2017, Inductive representation learning on large graphs.  \nIn Advances in Neural Information Processing Systems 30. Available at:  \nhttps://cs.stanford.edu/people/jure/pubs/graphsage -nips17.pdf .\n24. Dong, Z., Ni, J., Bikel, D. M., Alfonseca, E., Wang, Y., Qu, C. & Zitouni, I., 2022, Exploring dual encoder \narchitectures for question answering. ArXiv, abs/2204.07120. Available at: https://arxiv.org/abs/2204.07120 .\n25. Google Cloud, 2021, Vertex AI Generative AI: Tune Embeddings. Available at:  \nhttps://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-embeddings .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2734, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f37191e-4501-4961-b72a-b961669f35c9": {"__data__": {"id_": "4f37191e-4501-4961-b72a-b961669f35c9", "embedding": null, "metadata": {"page_label": "51", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e1c6472-477c-4ddd-b8c6-dd0cb4c479cf", "node_type": "4", "metadata": {"page_label": "51", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "36b1ef0d84df912bfdd221131854ea3b65490952a8ad83067369d55bec214a66", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n51\nSeptember 2024\n26. TensorFlow, 2021, TensorFlow Models: NLP, Fine-tune BERT. Available at:  \nhttps://www.tensorflow.org/tfmodels/nlp/fine_tune_bert .\n27. Matsui, Y., 2020, Survey on approximate nearest neighbor methods. ACM Computing Surveys (CSUR), 53(6), \nArticle 123. Available at: https://wangzwhu.github.io/home/file/acmmm-t-part3-ann.pdf .\n28. Friedman, J. H., Bentley, J. L. & Finkel, R. A., 1977, An algorithm for finding best matches in logarithmic \nexpected time. ACM Transactions on Mathematical Software (TOMS), 3(3), pp. 209-226. Available at:  \nhttps://dl.acm.org/doi/pdf/10.1145/355744.355745 .\n29. Scikit-learn, 2021, Scikit-learn, a library for unsupervised and supervised neighbors-based learning methods. \nAvailable at: https://scikit-learn.org/.\n30. lshashing, 2021, An open source python library to perform locality sensitive hashing. Available at:  \nhttps://pypi.org/project/lshashing/ .\n31. Malkov, Y. A., Yashunin, D. A., 2016, Efficient and robust approximate nearest neighbor search using \nhierarchical navigable small world graphs. ArXiv, abs/1603.09320. Available at:  \nhttps://arxiv.org/pdf/1603.09320.pdf .\n32. Google Research, 2021, A library for fast ANN by Google using the ScaNN algorithm. Available at:  \nhttps://github.com/google-research/google-research/tree/master/scann .\n33. Guo, R., Zhang, L., Hinton, G. & Zoph, B., 2020, Accelerating large-scale inference with anisotropic vector \nquantization. ArXiv, abs/1908.10396. Available at: https://arxiv.org/pdf/1908.10396.pdf .\n34. TensorFlow, 2021, TensorFlow Recommenders, an open source library for building ranking & recommender \nsystem models. Available at: https://www.tensorflow.org/recommenders .\n35. Google Cloud, 2021, Vertex AI Vector Search, Google Cloud\u2019s high-scale low latency vector database. \nAvailable at: https://cloud.google.com/vertex-ai/docs/vector-search/overview .\n36. Elasticsearch, 2021, Elasticsearch: a RESTful search and analytics engine. Available at:  \nhttps://www.elastic.co/elasticsearch/ .\n37. Pinecone, 2021, Pinecone, a commercial fully managed vector database. Available at:  \nhttps://www.pinecone.io .\n38. pgvector, 2021, Open Source vector similarity search for Postgres. Available at:  \nhttps://github.com/pgvector/pgvector.\n39. Weaviate, 2021, Weaviate, an open source vector database. Available at: https://weaviate.io/.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2378, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "85c83eac-9df7-44aa-a7a1-9ad71871e3e3": {"__data__": {"id_": "85c83eac-9df7-44aa-a7a1-9ad71871e3e3", "embedding": null, "metadata": {"page_label": "52", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6204f493-5854-4ec8-8c9f-7220c13a9ee3", "node_type": "4", "metadata": {"page_label": "52", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}, "hash": "56f6f09b55041c3a8c5edfb2ed5fe4cfb7c18e1d386e6cae5d1545245b04df06", "class_name": "RelatedNodeInfo"}}, "text": "Embeddings & Vector Stores\n52\nSeptember 2024\n40. ChromaDB, 2021, ChromaDB, an open source vector database. Available at: https://www.trychroma.com/ .\n41. LangChain, 2021.,LangChain, an open source framework for developing applications powered by language \nmodel. Available at: https://langchain.com .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 300, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c4136728-f4ba-465a-a72d-a2ba7c8aff7e": {"__data__": {"id_": "c4136728-f4ba-465a-a72d-a2ba7c8aff7e", "embedding": null, "metadata": {"page_label": "1", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "77075225-d6d6-4ce2-9107-9213391c2e3d", "node_type": "4", "metadata": {"page_label": "1", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "57e49952bc7649d3a780a1ac4fa8288a65d343d7d446330c5edd3b4aab530441", "class_name": "RelatedNodeInfo"}}, "text": "Prompt  \nEngineering\nAuthor: Lee Boonstra", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 41, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a5d73010-2d71-4c0c-9e0b-f7419094280a": {"__data__": {"id_": "a5d73010-2d71-4c0c-9e0b-f7419094280a", "embedding": null, "metadata": {"page_label": "2", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f5742773-a6bc-43e0-940d-f1cc692c5e82", "node_type": "4", "metadata": {"page_label": "2", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c4a5302fef7ae9fadfc5426e41925c2299893c9801917223ba12c6d3ee5f283f", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n2\nAcknowledgements\nReviewers and Contributors\nMichael Sherman\nYuan Cao\nErick Armbrust\nAnant Nawalgaria\nAntonio Gulli\nSimone Cammel\nCurators and Editors\nAntonio Gulli\nAnant Nawalgaria\nGrace Mollison \nTechnical Writer\nJoey Haymaker\nDesigner\nMichael Lanning", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 288, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b269087-4255-4b34-bb34-5d371e01299c": {"__data__": {"id_": "1b269087-4255-4b34-bb34-5d371e01299c", "embedding": null, "metadata": {"page_label": "3", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "be0eaefc-bde6-4b96-875b-c032380a80d3", "node_type": "4", "metadata": {"page_label": "3", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "68e5a13b47e457e56c07a65d4a090709300b9beaf5d1905f53cf47380889521a", "class_name": "RelatedNodeInfo"}}, "text": "Introduction 6\nPrompt engineering 7\nLLM output configuration 8\n Output length 8\n Sampling controls 9\n  Temperature  9\n  Top-K and top-P 10\n\t \t Putting\tit\tall\ttogether 11\nPrompting techniques 12\n General prompting / zero shot 13\n One-shot & few-shot 14\n System, contextual and role prompting 17\n  System prompting  18\n  Role prompting 21\n  Contextual prompting 23\nTable of contents", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 380, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d1ada68f-95d7-4b3e-b5ea-fc3efbfc1df4": {"__data__": {"id_": "d1ada68f-95d7-4b3e-b5ea-fc3efbfc1df4", "embedding": null, "metadata": {"page_label": "4", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1b341c41-8162-49b6-bb91-89080b046945", "node_type": "4", "metadata": {"page_label": "4", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6fa29b264336e7c6e407d26988f390be0e636a0cfc9cc6a3fda44e83122345e9", "class_name": "RelatedNodeInfo"}}, "text": "Step-back prompting 25\n Chain of Thought (CoT) 29\n Self-consistency  32\n Tree of Thoughts (ToT) 36\n ReAct (reason & act) 37\n Automatic Prompt Engineering 40\n Code prompting 42\n  Prompts for writing code 42\n  Prompts for explaining code 44\n  Prompts for translating code 46\n  Prompts for debugging and reviewing code 48\n  What about multimodal prompting? 54\nBest Practices 54\n Provide examples 54\n Design with simplicity 55\n\t Be\tspecific\tabout\tthe\toutput 56\n Use Instructions over Constraints 56\n Control the max token length 58\n Use variables in prompts 58\n Experiment with input formats and writing styles 59\n\t For\tfew-shot\tprompting\twith\tclassification\ttasks,\tmix\tup\tthe\tclasses 59\n Adapt to model updates 60\n Experiment with output formats 60", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 746, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6067c9fb-c9a6-4df4-8268-2dfb4c88763e": {"__data__": {"id_": "6067c9fb-c9a6-4df4-8268-2dfb4c88763e", "embedding": null, "metadata": {"page_label": "5", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "18dd8080-215e-4d38-8937-b297a5dabd88", "node_type": "4", "metadata": {"page_label": "5", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "8666cc731629d128e31e910cc1116dbd8e546042562bdae7c68990c26d3724c8", "class_name": "RelatedNodeInfo"}}, "text": "Experiment together with other prompt engineers 61\n CoT Best practices 61\n\t Document\tthe\tvarious\tprompt\tattempts 62\nSummary 63\nEndnotes 65", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 139, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "76fdfdf2-2125-4af5-a215-1c3dae2743fc": {"__data__": {"id_": "76fdfdf2-2125-4af5-a215-1c3dae2743fc", "embedding": null, "metadata": {"page_label": "6", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f97bd38b-afa2-4c1f-b2cd-d49ed72e0c56", "node_type": "4", "metadata": {"page_label": "6", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "93a2818d964e50c545f851750b9fbf902703fc93aebad89a52c8b0d4ff442c25", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n6\nIntroduction\nWhen thinking about a large language model input and output, a text prompt (sometimes \naccompanied by other modalities such as image prompts) is the input the model uses \nto\tpredict\ta\tspecific\toutput.\tYou\tdon\u2019t\tneed\tto\tbe\ta\tdata\tscientist\tor\ta\tmachine\tlearning\t\nengineer\t\u2013\teveryone\tcan\twrite\ta\tprompt.\tHowever,\tcrafting\tthe\tmost\teffective\tprompt\tcan\tbe\t\ncomplicated.\tMany\taspects\tof\tyour\tprompt\taffect\tits\tefficacy:\tthe\tmodel\tyou\tuse,\tthe\tmodel\u2019s\t\ntraining\tdata,\tthe\tmodel\tconfigurations,\tyour\tword-choice,\tstyle\tand\ttone,\tstructure,\tand\t\ncontext\tall\tmatter.\tTherefore,\tprompt\tengineering\tis\tan\titerative\tprocess.\tInadequate\tprompts\t\ncan\tlead\tto\tambiguous,\tinaccurate\tresponses,\tand\tcan\thinder\tthe\tmodel\u2019s\tability\tto\tprovide\t\nmeaningful\toutput.\nYou don\u2019t need to be a data \nscientist or a machine learning \nengineer \u2013 everyone can write \na prompt.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 896, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5531cc32-2957-4a35-867d-b5efc7fab502": {"__data__": {"id_": "5531cc32-2957-4a35-867d-b5efc7fab502", "embedding": null, "metadata": {"page_label": "7", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "83d5360b-4c21-4330-88f3-c5ef9f35e0a0", "node_type": "4", "metadata": {"page_label": "7", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "fdca3d7f345d4e1a67d17d785a656ea89bb63a7d796625061df9284f50fbc9bf", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n7\nWhen you chat with the Gemini chatbot,1 you basically write prompts, however this \nwhitepaper\tfocuses\ton\twriting\tprompts\tfor\tthe\tGemini\tmodel\twithin\tVertex\tAI\tor\tby\tusing\t\t\nthe\tAPI,\tbecause\tby\tprompting\tthe\tmodel\tdirectly\tyou\twill\thave\taccess\tto\tthe\tconfiguration\t\nsuch\tas\ttemperature\tetc.\nThis\twhitepaper\tdiscusses\tprompt\tengineering\tin\tdetail.\tWe\twill\tlook\tinto\tthe\tvarious\t\nprompting\ttechniques\tto\thelp\tyou\tgetting\tstarted\tand\tshare\ttips\tand\tbest\tpractices\tto\t\nbecome\ta\tprompting\texpert.\tWe\twill\talso\tdiscuss\tsome\tof\tthe\tchallenges\tyou\tcan\tface\t\t\nwhile\tcrafting\tprompts.\nPrompt engineering\nRemember\thow\tan\tLLM\tworks;\tit\u2019s\ta\tprediction\tengine.\tThe\tmodel\ttakes\tsequential\ttext\tas\t\nan input and then predicts what the following token should be, based on the data it was \ntrained\ton.\tThe\tLLM\tis\toperationalized\tto\tdo\tthis\tover\tand\tover\tagain,\tadding\tthe\tpreviously\t\npredicted\ttoken\tto\tthe\tend\tof\tthe\tsequential\ttext\tfor\tpredicting\tthe\tfollowing\ttoken.\tThe\tnext\t\ntoken\tprediction\tis\tbased\ton\tthe\trelationship\tbetween\twhat\u2019s\tin\tthe\tprevious\ttokens\tand\twhat\t\nthe\tLLM\thas\tseen\tduring\tits\ttraining.\t\nWhen\tyou\twrite\ta\tprompt,\tyou\tare\tattempting\tto\tset\tup\tthe\tLLM\tto\tpredict\tthe\tright\tsequence\t\nof\ttokens.\tPrompt\tengineering\tis\tthe\tprocess\tof\tdesigning\thigh-quality\tprompts\tthat\tguide\t\nLLMs\tto\tproduce\taccurate\toutputs.\tThis\tprocess\tinvolves\ttinkering\tto\tfind\tthe\tbest\tprompt,\t\noptimizing\tprompt\tlength,\tand\tevaluating\ta\tprompt\u2019s\twriting\tstyle\tand\tstructure\tin\trelation\t\nto\tthe\ttask.\tIn\tthe\tcontext\tof\tnatural\tlanguage\tprocessing\tand\tLLMs,\ta\tprompt\tis\tan\tinput\t\nprovided\tto\tthe\tmodel\tto\tgenerate\ta\tresponse\tor\tprediction.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1649, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "154bca11-700c-4ffc-ab70-67b0544d8682": {"__data__": {"id_": "154bca11-700c-4ffc-ab70-67b0544d8682", "embedding": null, "metadata": {"page_label": "8", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a090aff-483e-4bbc-a9d0-2f06057c4eec", "node_type": "4", "metadata": {"page_label": "8", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6e47de0cd84a0c1d8c26d564af678ffb4cfb1b23838032d2ffb1ecf2b429d228", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n8\nThese prompts can be used to achieve various kinds of understanding and generation \ntasks\tsuch\tas\ttext\tsummarization,\tinformation\textraction,\tquestion\tand\tanswering,\ttext\t\nclassification,\tlanguage\tor\tcode\ttranslation,\tcode\tgeneration,\tand\tcode\tdocumentation\t\nor\treasoning.\nPlease\tfeel\tfree\tto\trefer\tto\tGoogle\u2019s\tprompting\tguides2,3\twith\tsimple\tand\teffective\t\nprompting\texamples.\nWhen\tprompt\tengineering,\tyou\twill\tstart\tby\tchoosing\ta\tmodel.\tPrompts\tmight\tneed\tto\tbe\t\noptimized\tfor\tyour\tspecific\tmodel,\tregardless\tof\twhether\tyou\tuse\tGemini\tlanguage\tmodels\tin\t\nVertex\tAI,\tGPT,\tClaude,\tor\tan\topen\tsource\tmodel\tlike\tGemma\tor\tLLaMA.\nBesides\tthe\tprompt,\tyou\twill\talso\tneed\tto\ttinker\twith\tthe\tvarious\tconfigurations\tof\ta\tLLM.\nLLM output configuration\nOnce\tyou\tchoose\tyour\tmodel\tyou\twill\tneed\tto\tfigure\tout\tthe\tmodel\tconfiguration.\tMost\tLLMs\t\ncome\twith\tvarious\tconfiguration\toptions\tthat\tcontrol\tthe\tLLM\u2019s\toutput.\tEffective\tprompt\t\nengineering\trequires\tsetting\tthese\tconfigurations\toptimally\tfor\tyour\ttask.\nOutput length\nAn\timportant\tconfiguration\tsetting\tis\tthe\tnumber\tof\ttokens\tto\tgenerate\tin\ta\tresponse.\t\nGenerating\tmore\ttokens\trequires\tmore\tcomputation\tfrom\tthe\tLLM,\tleading\tto\thigher\tenergy\t\nconsumption,\tpotentially\tslower\tresponse\ttimes,\tand\thigher\tcosts.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1288, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4fcf1194-00fa-4bbb-831d-1819f78cb4a6": {"__data__": {"id_": "4fcf1194-00fa-4bbb-831d-1819f78cb4a6", "embedding": null, "metadata": {"page_label": "9", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ec7cbe1-c7e6-4a25-8505-1b335d39ede5", "node_type": "4", "metadata": {"page_label": "9", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "896c792b9ace740d673b9baa2fedfdfeb37434f4d1db188222c5a6f0c86c5a04", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n9\nReducing\tthe\toutput\tlength\tof\tthe\tLLM\tdoesn\u2019t\tcause\tthe\tLLM\tto\tbecome\tmore\tstylistically\t\nor textually succinct in the output it creates, it just causes the LLM to stop predicting more \ntokens\tonce\tthe\tlimit\tis\treached.\tIf\tyour\tneeds\trequire\ta\tshort\toutput\tlength,\tyou\u2019ll\talso\t\npossibly\tneed\tto\tengineer\tyour\tprompt\tto\taccommodate.\nOutput\tlength\trestriction\tis\tespecially\timportant\tfor\tsome\tLLM\tprompting\ttechniques,\tlike\t\nReAct,\twhere\tthe\tLLM\twill\tkeep\temitting\tuseless\ttokens\tafter\tthe\tresponse\tyou\twant.\nSampling controls\nLLMs\tdo\tnot\tformally\tpredict\ta\tsingle\ttoken.\tRather,\tLLMs\tpredict\tprobabilities\tfor\twhat\tthe\t\nnext\ttoken\tcould\tbe,\twith\teach\ttoken\tin\tthe\tLLM\u2019s\tvocabulary\tgetting\ta\tprobability.\tThose\t\ntoken\tprobabilities\tare\tthen\tsampled\tto\tdetermine\twhat\tthe\tnext\tproduced\ttoken\twill\tbe.\t\nTemperature,\ttop-K,\tand\ttop-P\tare\tthe\tmost\tcommon\tconfiguration\tsettings\tthat\tdetermine\t\nhow\tpredicted\ttoken\tprobabilities\tare\tprocessed\tto\tchoose\ta\tsingle\toutput\ttoken.\nTemperature\nTemperature\tcontrols\tthe\tdegree\tof\trandomness\tin\ttoken\tselection.\tLower\ttemperatures\t\nare good for prompts that expect a more deterministic response, while higher temperatures \ncan\tlead\tto\tmore\tdiverse\tor\tunexpected\tresults.\tA\ttemperature\tof\t0\t(greedy\tdecoding)\tis\t\ndeterministic:\tthe\thighest\tprobability\ttoken\tis\talways\tselected\t(though\tnote\tthat\tif\ttwo\ttokens\t\nhave the same highest predicted probability, depending on how tiebreaking is implemented \nyou\tmay\tnot\talways\tget\tthe\tsame\toutput\twith\ttemperature\t0).\nTemperatures\tclose\tto\tthe\tmax\ttend\tto\tcreate\tmore\trandom\toutput.\tAnd\tas\ttemperature\tgets\t\nhigher\tand\thigher,\tall\ttokens\tbecome\tequally\tlikely\tto\tbe\tthe\tnext\tpredicted\ttoken.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1703, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "47bcd8b2-dd97-4072-b697-1a96c68e5dc6": {"__data__": {"id_": "47bcd8b2-dd97-4072-b697-1a96c68e5dc6", "embedding": null, "metadata": {"page_label": "10", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "375a6d45-5b96-4066-a609-92976da74def", "node_type": "4", "metadata": {"page_label": "10", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "9144208dbdbcd6eae8eef221932a4dae90940888ce876262b3f1fa565c9e4382", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n10\nThe\tGemini\ttemperature\tcontrol\tcan\tbe\tunderstood\tin\ta\tsimilar\tway\tto\tthe\tsoftmax\tfunction\t\nused\tin\tmachine\tlearning.\tA\tlow\ttemperature\tsetting\tmirrors\ta\tlow\tsoftmax\ttemperature\t(T),\t\nemphasizing\ta\tsingle,\tpreferred\ttemperature\twith\thigh\tcertainty.\tA\thigher\tGemini\ttemperature\t\nsetting\tis\tlike\ta\thigh\tsoftmax\ttemperature,\tmaking\ta\twider\trange\tof\ttemperatures\taround\t\nthe\tselected\tsetting\tmore\tacceptable.\tThis\tincreased\tuncertainty\taccommodates\tscenarios\t\nwhere a rigid, precise temperature may not be essential like for example when experimenting \nwith\tcreative\toutputs.\nTop-K and top-P\nTop-K and top-P (also known as nucleus sampling)4\tare\ttwo\tsampling\tsettings\tused\tin\tLLMs\t\nto\trestrict\tthe\tpredicted\tnext\ttoken\tto\tcome\tfrom\ttokens\twith\tthe\ttop\tpredicted\tprobabilities.\t\t\nLike\ttemperature,\tthese\tsampling\tsettings\tcontrol\tthe\trandomness\tand\tdiversity\tof\t\ngenerated\ttext.\n\u2022 Top-K\tsampling\tselects\tthe\ttop\tK\tmost\tlikely\ttokens\tfrom\tthe\tmodel\u2019s\tpredicted\t\ndistribution.\tThe\thigher\ttop-K,\tthe\tmore\tcreative\tand\tvaried\tthe\tmodel\u2019s\toutput;\tthe\t\nlower\ttop-K,\tthe\tmore\trestive\tand\tfactual\tthe\tmodel\u2019s\toutput.\tA\ttop-K\tof\t1\tis\tequivalent\tto\t\ngreedy\tdecoding.\n\u2022 Top-P sampling selects the top tokens whose cumulative probability does not exceed \na\tcertain\tvalue\t(P).\tValues\tfor\tP\trange\tfrom\t0\t(greedy\tdecoding)\tto\t1\t(all\ttokens\tin\tthe\t\nLLM\u2019s\tvocabulary).\nThe best way to choose between top-K and top-P is to experiment with both methods (or \nboth\ttogether)\tand\tsee\twhich\tone\tproduces\tthe\tresults\tyou\tare\tlooking\tfor.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1544, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4963ebfd-de92-462d-9203-4c4a73794664": {"__data__": {"id_": "4963ebfd-de92-462d-9203-4c4a73794664", "embedding": null, "metadata": {"page_label": "11", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1206487c-318d-4d86-a9cd-d6639a5dcae3", "node_type": "4", "metadata": {"page_label": "11", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "6343717c8517639493067417d93898f4b2679b6d08284a7fb3b005a81d1336d0", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n11\nAnother\timportant\tconfiguration\tsetting\tis\tthe\tnumber\tof\ttokens\tto\tgenerate\tin\ta\tresponse.\t\nBe\taware,\tgenerating\tmore\ttokens\trequires\tmore\tcomputation\tfrom\tthe\tLLM,\tleading\t\nto higher energy consumption and potentially slower response times, which leads to \nhigher\tcosts.\nPutting it all together\nChoosing between top-K, top-P, temperature, and the number of tokens to generate, \ndepends\ton\tthe\tspecific\tapplication\tand\tdesired\toutcome,\tand\tthe\tsettings\tall\timpact\tone\t\nanother.\tIt\u2019s\talso\timportant\tto\tmake\tsure\tyou\tunderstand\thow\tyour\tchosen\tmodel\tcombines\t\nthe\tdifferent\tsampling\tsettings\ttogether.\nIf\ttemperature,\ttop-K,\tand\ttop-P\tare\tall\tavailable\t(as\tin\tVertex\tStudio),\ttokens\tthat\tmeet\t\nboth the top-K and top-P criteria are candidates for the next predicted token, and then \ntemperature\tis\tapplied\tto\tsample\tfrom\tthe\ttokens\tthat\tpassed\tthe\ttop-K\tand\ttop-P\tcriteria.\tIf\t\nonly\ttop-K\tor\ttop-P\tis\tavailable,\tthe\tbehavior\tis\tthe\tsame\tbut\tonly\tthe\tone\ttop-K\tor\tP\tsetting\t\nis\tused.\t\nIf temperature is not available, whatever tokens meet the top-K and/or top-P criteria are then \nrandomly\tselected\tfrom\tto\tproduce\ta\tsingle\tnext\tpredicted\ttoken.\nAt\textreme\tsettings\tof\tone\tsampling\tconfiguration\tvalue,\tthat\tone\tsampling\tsetting\teither\t\ncancels\tout\tother\tconfiguration\tsettings\tor\tbecomes\tirrelevant.\n\u2022 If you set temperature to 0, top-K and top-P become irrelevant\u2013the most probable \ntoken\tbecomes\tthe\tnext\ttoken\tpredicted.\tIf\tyou\tset\ttemperature\textremely\thigh\t(above\t\n1\u2013generally into the 10s), temperature becomes irrelevant and whatever tokens make \nit through the top-K and/or top-P criteria are then randomly sampled to choose a next \npredicted\ttoken.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1692, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "79bd6d4e-fa9d-41a3-8bed-7061e2ac91e3": {"__data__": {"id_": "79bd6d4e-fa9d-41a3-8bed-7061e2ac91e3", "embedding": null, "metadata": {"page_label": "12", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3aff15c2-2562-4613-b2e1-a29fd648478e", "node_type": "4", "metadata": {"page_label": "12", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "ce4ab2e12e2462a8bc1e8c0280af108e313d2cf4fdd7f6132a3edce7bf7adc35", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n12\n\u2022 If\tyou\tset\ttop-K\tto\t1,\ttemperature\tand\ttop-P\tbecome\tirrelevant.\tOnly\tone\ttoken\tpasses\tthe\t\ntop-K\tcriteria,\tand\tthat\ttoken\tis\tthe\tnext\tpredicted\ttoken.\tIf\tyou\tset\ttop-K\textremely\thigh,\t\nlike\tto\tthe\tsize\tof\tthe\tLLM\u2019s\tvocabulary,\tany\ttoken\twith\ta\tnonzero\tprobability\tof\tbeing\tthe\t\nnext\ttoken\twill\tmeet\tthe\ttop-K\tcriteria\tand\tnone\tare\tselected\tout.\n\u2022 If you set top-P to 0 (or a very small value), most LLM sampling implementations will then \nonly consider the most probable token to meet the top-P criteria, making temperature and \ntop-K\tirrelevant.\tIf\tyou\tset\ttop-P\tto\t1,\tany\ttoken\twith\ta\tnonzero\tprobability\tof\tbeing\tthe\t\nnext\ttoken\twill\tmeet\tthe\ttop-P\tcriteria,\tand\tnone\tare\tselected\tout.\nAs\ta\tgeneral\tstarting\tpoint,\ta\ttemperature\tof\t.2,\ttop-P\tof\t.95,\tand\ttop-K\tof\t30\twill\tgive\tyou\t\nrelatively\tcoherent\tresults\tthat\tcan\tbe\tcreative\tbut\tnot\texcessively\tso.\tIf\tyou\twant\tespecially\t\ncreative\tresults,\ttry\tstarting\twith\ta\ttemperature\tof\t.9,\ttop-P\tof\t.99,\tand\ttop-K\tof\t40.\tAnd\tif\tyou\t\nwant\tless\tcreative\tresults,\ttry\tstarting\twith\ta\ttemperature\tof\t.1,\ttop-P\tof\t.9,\tand\ttop-K\tof\t20.\t\nFinally,\tif\tyour\ttask\talways\thas\ta\tsingle\tcorrect\tanswer\t(e.g.,\tanswering\ta\tmath\tproblem),\tstart\t\nwith\ta\ttemperature\tof\t0.\nNOTE: With more freedom (higher temperature, top-K, top-P, and output tokens), the LLM \nmight\tgenerate\ttext\tthat\tis\tless\trelevant.\nPrompting techniques\nLLMs are tuned to follow instructions and are trained on large amounts of data so they can \nunderstand\ta\tprompt\tand\tgenerate\tan\tanswer.\tBut\tLLMs\taren\u2019t\tperfect;\tthe\tclearer\tyour\t\nprompt\ttext,\tthe\tbetter\tit\tis\tfor\tthe\tLLM\tto\tpredict\tthe\tnext\tlikely\ttext.\tAdditionally,\tspecific\t\ntechniques\tthat\ttake\tadvantage\tof\thow\tLLMs\tare\ttrained\tand\thow\tLLMs\twork\twill\thelp\tyou\tget\t\nthe relevant results from LLMs", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1793, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40722910-fb12-43bd-86e6-3e719711c768": {"__data__": {"id_": "40722910-fb12-43bd-86e6-3e719711c768", "embedding": null, "metadata": {"page_label": "13", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "276b72d1-6bb7-4aed-b700-142bd8735d56", "node_type": "4", "metadata": {"page_label": "13", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "20614885c76dd6482a01cfa66b613672f6a98d588f8bb2eaaca42b50b6c7fcee", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n13\nNow\tthat\twe\tunderstand\twhat\tprompt\tengineering\tis\tand\twhat\tit\ttakes,\tlet\u2019s\tdive\tinto\tsome\t\nexamples\tof\tthe\tmost\timportant\tprompting\ttechniques.\nGeneral prompting / zero shot\nA zero-shot5\tprompt\tis\tthe\tsimplest\ttype\tof\tprompt.\tIt\tonly\tprovides\ta\tdescription\tof\ta\ttask\t\nand\tsome\ttext\tfor\tthe\tLLM\tto\tget\tstarted\twith.\tThis\tinput\tcould\tbe\tanything:\ta\tquestion,\ta\t\nstart\tof\ta\tstory,\tor\tinstructions.\tThe\tname\tzero-shot\tstands\tfor\t\u2019no\texamples\u2019.\nLet\u2019s\tuse\tVertex\tAI\tStudio\t(for\tLanguage)\tin\tVertex\tAI,6 which provides a playground to test \nprompts.\tIn\tTable\t1,\tyou\twill\tsee\tan\texample\tzero-shot\tprompt\tto\tclassify\tmovie\treviews.\t\nThe\ttable\tformat\tas\tused\tbelow\tis\ta\tgreat\tway\tof\tdocumenting\tprompts.\tYour\tprompts\twill\t\nlikely\tgo\tthrough\tmany\titerations\tbefore\tthey\tend\tup\tin\ta\tcodebase,\tso\tit\u2019s\timportant\tto\tkeep\t\ntrack\tof\tyour\tprompt\tengineering\twork\tin\ta\tdisciplined,\tstructured\tway.\tMore\ton\tthis\ttable\t\nformat,\tthe\timportance\tof\ttracking\tprompt\tengineering\twork,\tand\tthe\tprompt\tdevelopment\t\nprocess is in the Best Practices section later in this chapter (\u201cDocument the various prompt \nattempts\u201d).\t\t\nThe model temperature should be set to a low number, since no creativity is needed, and we \nuse\tthe\tgemini-pro\tdefault\ttop-K\tand\ttop-P\tvalues,\twhich\teffectively\tdisable\tboth\tsettings\t\n(see\t\u2018LLM\tOutput\tConfiguration\u2019\tabove).\tPay\tattention\tto\tthe\tgenerated\toutput.\tThe\twords\t\ndisturbing and masterpiece\tshould\tmake\tthe\tprediction\ta\tlittle\tmore\tcomplicated,\tas\tboth\t\nwords\tare\tused\tin\tthe\tsame\tsentence.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1533, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "26d5a4fe-46c8-41ca-8da3-4a50a7a07c56": {"__data__": {"id_": "26d5a4fe-46c8-41ca-8da3-4a50a7a07c56", "embedding": null, "metadata": {"page_label": "14", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "96d63c4e-0d89-46c8-a619-3418499348c9", "node_type": "4", "metadata": {"page_label": "14", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "64daaa96996ccb1fe13fb23b46f120a19ed6a34cb4ddf05df6eeea890de73f10", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n14\nName 1_1_movie_classification\nGoal Classify\tmovie\treviews\tas\tpositive,\tneutral\tor\tnegative.\nModel gemini-pro\nTemperature 0.1 Token Limit 5\nTop-K N/A Top-P 1\nPrompt Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE. \nReview: \"Her\" is a disturbing study revealing the direction \nhumanity is headed if AI is allowed to keep evolving, \nunchecked. I wish there were more movies like this masterpiece. \nSentiment:\nOutput POSITIVE\nTable 1. An example of zero-shot prompting\nWhen\tzero-shot\tdoesn\u2019t\twork,\tyou\tcan\tprovide\tdemonstrations\tor\texamples\tin\tthe\tprompt,\t\nwhich\tleads\tto\t\u201cone-shot\u201d\tand\t\u201cfew-shot\u201d\tprompting.\tGeneral\tprompting\t/\tzero\tshot\nOne-shot & few-shot\nWhen\tcreating\tprompts\tfor\tAI\tmodels,\tit\tis\thelpful\tto\tprovide\texamples.\tThese\texamples\tcan\t\nhelp\tthe\tmodel\tunderstand\twhat\tyou\tare\tasking\tfor.\tExamples\tare\tespecially\tuseful\twhen\tyou\t\nwant\tto\tsteer\tthe\tmodel\tto\ta\tcertain\toutput\tstructure\tor\tpattern.\t\nA one-shot prompt, provides a single\texample,\t\thence\tthe\tname\tone-shot.\tThe\tidea\tis\tthe\t\nmodel\thas\tan\texample\tit\tcan\timitate\tto\tbest\tcomplete\tthe\ttask.\nA few-shot prompt 7 provides multiple\texamples\tto\tthe\tmodel.\tThis\tapproach\tshows\tthe\t\t\nmodel\ta\tpattern\tthat\tit\tneeds\tto\tfollow.\tThe\tidea\tis\tsimilar\tto\tone-shot,\tbut\tmultiple\texamples\t\nof\tthe\tdesired\tpattern\tincreases\tthe\tchance\tthe\tmodel\tfollows\tthe\tpattern.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1cd596e0-ebd4-432b-9ca9-77f256e5f26d": {"__data__": {"id_": "1cd596e0-ebd4-432b-9ca9-77f256e5f26d", "embedding": null, "metadata": {"page_label": "15", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4d388dfe-1dfd-4445-b93b-e2a95a14d509", "node_type": "4", "metadata": {"page_label": "15", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "9d5199d6533af50be139c5bd089fdddc0dc7e0b1ec6c8f6282763b93719a2d1e", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n15\nThe number of examples you need for few-shot prompting depends on a few factors, \nincluding\tthe\tcomplexity\tof\tthe\ttask,\tthe\tquality\tof\tthe\texamples,\tand\tthe\tcapabilities\tof\tthe\t\ngenerative\tAI\t(gen\tAI)\tmodel\tyou\tare\tusing.\tAs\ta\tgeneral\trule\tof\tthumb,\tyou\tshould\tuse\tat\t\nleast\tthree\tto\tfive\texamples\tfor\tfew-shot\tprompting.\tHowever,\tyou\tmay\tneed\tto\tuse\tmore\t\nexamples for more complex tasks, or you may need to use fewer due to the input length \nlimitation\tof\tyour\tmodel.\nTable\t2\tshows\ta\tfew-shot\tprompt\texample,\tlet\u2019s\tuse\tthe\tsame\tgemini-pro\tmodel\t\nconfiguration\tsettings\tas\tbefore,\tother\tthan\tincreasing\tthe\ttoken\tlimit\tto\taccommodate\tthe\t\nneed\tfor\ta\tlonger\tresponse.\nGoal Parse pizza orders to JSON\nModel gemini-pro\nTemperature 0.1 Token Limit 250\nTop-K N/A Top-P 1\nPrompt Parse a customer's pizza order into valid JSON:\nEXAMPLE:\nI want a small pizza with cheese, tomato sauce, and pepperoni.\nJSON Response:\n```\n{\n\"size\": \"small\",\n\"type\": \"normal\",\n\"ingredients\": [[\"cheese\", \"tomato sauce\", \"peperoni\"]]\n}\n```\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1071, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a00020be-4c1f-4104-b86f-8186299ac107": {"__data__": {"id_": "a00020be-4c1f-4104-b86f-8186299ac107", "embedding": null, "metadata": {"page_label": "16", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3c03b062-1584-4976-9197-1faf18348058", "node_type": "4", "metadata": {"page_label": "16", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "66a8337621cb68ab41ee708993ecbf35c5ec772195a7b142a025ba69af07d2d6", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n16\nPrompt EXAMPLE:\nCan I get a large pizza with tomato sauce, basil and mozzarella \n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [[\"tomato sauce\", \"bazel\", \"mozzarella\"]]\n}\nNow, I would like a large pizza, with the first half cheese and \nmozzarella. And the other tomato sauce, ham and pineapple.\nJSON Response:\nOutput ```\n{\n\"size\": \"large\",\n\"type\": \"half-half\",\n\"ingredients\": [[\"cheese\", \"mozzarella\"], [\"tomato sauce\", \n\"ham\", \"pineapple\"]]\n}\n```\nTable 2. An example of few-shot prompting\nWhen you choose examples for your prompt, use examples that are relevant to the task you \nwant\tto\tperform.\tThe\texamples\tshould\tbe\tdiverse,\tof\thigh\tquality,\tand\twell\twritten.\tOne\tsmall\t\nmistake\tcan\tconfuse\tthe\tmodel\tand\twill\tresult\tin\tundesired\toutput.\nIf\tyou\tare\ttrying\tto\tgenerate\toutput\tthat\tis\trobust\tto\ta\tvariety\tof\tinputs,\tthen\tit\tis\timportant\tto\t\ninclude\tedge\tcases\tin\tyour\texamples.\tEdge\tcases\tare\tinputs\tthat\tare\tunusual\tor\tunexpected,\t\nbut\tthat\tthe\tmodel\tshould\tstill\tbe\table\tto\thandle.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1028, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "30aa6e91-4e74-41c3-89e1-f8455a315724": {"__data__": {"id_": "30aa6e91-4e74-41c3-89e1-f8455a315724", "embedding": null, "metadata": {"page_label": "17", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1a898361-f9d1-4490-9b85-8a00517d1782", "node_type": "4", "metadata": {"page_label": "17", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "aa5870f18aa8d3f356585a42d383c3f7318c48821a3f67549a05c5d415d843b4", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n17\nSystem, contextual and role prompting\nSystem,\tcontextual\tand\trole\tprompting\tare\tall\ttechniques\tused\tto\tguide\thow\tLLMs\tgenerate\t\ntext,\tbut\tthey\tfocus\ton\tdifferent\taspects:\n\u2022 System prompting\tsets\tthe\toverall\tcontext\tand\tpurpose\tfor\tthe\tlanguage\tmodel.\tIt\t\ndefines\tthe\t\u2018big\tpicture\u2019\tof\twhat\tthe\tmodel\tshould\tbe\tdoing,\tlike\ttranslating\ta\tlanguage,\t\nclassifying\ta\treview\tetc.\n\u2022 Contextual prompting\tprovides\tspecific\tdetails\tor\tbackground\tinformation\trelevant\tto\t\nthe\tcurrent\tconversation\tor\ttask.\tIt\thelps\tthe\tmodel\tto\tunderstand\tthe\tnuances\tof\twhat\u2019s\t\nbeing\tasked\tand\ttailor\tthe\tresponse\taccordingly.\n\u2022 Role prompting\tassigns\ta\tspecific\tcharacter\tor\tidentity\tfor\tthe\tlanguage\tmodel\tto\tadopt.\t\nThis helps the model generate responses that are consistent with the assigned role and its \nassociated\tknowledge\tand\tbehavior.\nThere\tcan\tbe\tconsiderable\toverlap\tbetween\tsystem,\tcontextual,\tand\trole\tprompting.\tE.g.\ta\t\nprompt\tthat\tassigns\ta\trole\tto\tthe\tsystem,\tcan\talso\thave\ta\tcontext.\nHowever,\teach\ttype\tof\tprompt\tserves\ta\tslightly\tdifferent\tprimary\tpurpose:\n\u2022 System\tprompt:\tDefines\tthe\tmodel\u2019s\tfundamental\tcapabilities\tand\toverarching\tpurpose.\n\u2022 Contextual\tprompt:\tProvides\timmediate,\ttask-specific\tinformation\tto\tguide\tthe\tresponse.\t\nIt\u2019s\thighly\tspecific\tto\tthe\tcurrent\ttask\tor\tinput,\twhich\tis\tdynamic.\n\u2022 Role\tprompt:\tFrames\tthe\tmodel\u2019s\toutput\tstyle\tand\tvoice.\tIt\tadds\ta\tlayer\tof\tspecificity\t\nand\tpersonality.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1439, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fe5984f7-142c-4c80-b2bf-3f5b3fbeb19a": {"__data__": {"id_": "fe5984f7-142c-4c80-b2bf-3f5b3fbeb19a", "embedding": null, "metadata": {"page_label": "18", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "74d0cfd6-b76f-4d8e-970e-ef68500db9dc", "node_type": "4", "metadata": {"page_label": "18", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "7f480475866d61d52fea547824f7e3a8c6ecca9e559eb4f0893821bc39cf082a", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n18\nDistinguishing between system, contextual, and role prompts provides a framework for \ndesigning\tprompts\twith\tclear\tintent,\tallowing\tfor\tflexible\tcombinations\tand\tmaking\tit\teasier\tto\t\nanalyze\thow\teach\tprompt\ttype\tinfluences\tthe\tlanguage\tmodel\u2019s\toutput.\nLet\u2019s\tdive\tinto\tthese\tthree\tdifferent\tkinds\tof\tprompts.\nSystem prompting\nTable 3 contains a system prompt, where I specify additional information on how to return the \noutput.\tI\tincreased\tthe\ttemperature\tto\tget\ta\thigher\tcreativity\tlevel,\tand\tI\tspecified\ta\thigher\t\ntoken\tlimit.\tHowever,\tbecause\tof\tmy\tclear\tinstruction\ton\thow\tto\treturn\tthe\toutput\tthe\tmodel\t\ndidn\u2019t\treturn\textra\ttext.\nGoal Classify\tmovie\treviews\tas\tpositive,\tneutral\tor\tnegative.\nModel gemini-pro\nTemperature 1 Token Limit 5\nTop-K 40 Top-P 0.8\nPrompt Classify movie reviews as positive, neutral or negative. Only \nreturn the label in uppercase.\nReview: \"Her\" is a disturbing study revealing the direction \nhumanity is headed if AI is allowed to keep evolving, \nunchecked. It's so disturbing I couldn't watch it.\nSentiment:\nOutput NEGATIVE\nTable 3. An example of system prompting", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1132, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "74bdef06-52b8-4dcf-9d55-444369bf721d": {"__data__": {"id_": "74bdef06-52b8-4dcf-9d55-444369bf721d", "embedding": null, "metadata": {"page_label": "19", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4beae257-2931-4d2c-82fd-a0e1fb7c98e2", "node_type": "4", "metadata": {"page_label": "19", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "2df59ea3100ddc62b08135dc0e4359bdc9d6390da71793b069a1c4be3cff4c91", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n19\nSystem\tprompts\tcan\tbe\tuseful\tfor\tgenerating\toutput\tthat\tmeets\tspecific\trequirements.\tThe\t\nname\t\u2018system\tprompt\u2019\tactually\tstands\tfor\t\u2018providing\tan\tadditional\ttask\tto\tthe\tsystem\u2019.\tFor\t\nexample, you could use a system prompt to generate a code snippet that is compatible with \na\tspecific\tprogramming\tlanguage,\tor\tyou\tcould\tuse\ta\tsystem\tprompt\tto\treturn\ta\tcertain\t\nstructure.\tHave\ta\tlook\tinto\tTable\t4,\twhere\tI\treturn\tthe\toutput\tin\tJSON\tformat.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 475, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c8257479-3ce0-458a-a54c-8afc2f26a054": {"__data__": {"id_": "c8257479-3ce0-458a-a54c-8afc2f26a054", "embedding": null, "metadata": {"page_label": "20", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f6e0cf90-f622-4d21-9032-76d36547960b", "node_type": "4", "metadata": {"page_label": "20", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "735f01372a6c3f4108e201d7e403d9deece8c4ba0ae50d89541456154c9e00ac", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n20\nGoal Classify\tmovie\treviews\tas\tpositive,\tneutral\tor\tnegative,\treturn\tJSON.\nModel gemini-pro\nTemperature 1 Token Limit 1024\nTop-K 40 Top-P 0.8\nPrompt Classify movie reviews as positive, neutral or negative. Return \nvalid JSON:\nReview: \"Her\" is a disturbing study revealing the direction \nhumanity is headed if AI is allowed to keep evolving, \nunchecked. It's so disturbing I couldn't watch it.\nSchema:\n```\nMOVIE:\n{\n\"sentiment\": String \"POSITIVE\" | \"NEGATIVE\" | \"NEUTRAL\",\n\"name\": String\n}\nMOVIE REVIEWS:\n{\n\"movie_reviews\": [MOVIE]\n}\n```\nJSON Response:\nOutput ```\n{\n  \"movie_reviews\": [\n    {\n      \"sentiment\": \"NEGATIVE\",\n      \"name\": \"Her\"\n    }\n  ]\n}\n```\nTable 4. An example of system prompting with JSON format", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 751, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "abd3507a-5e6e-4165-b85d-fe87c49cebd2": {"__data__": {"id_": "abd3507a-5e6e-4165-b85d-fe87c49cebd2", "embedding": null, "metadata": {"page_label": "21", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4935ca81-a397-4d14-adb2-222fd7176b32", "node_type": "4", "metadata": {"page_label": "21", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "46ad9bd339722cbfa77f0d423fe4f99594ed38170dc51a9b2a32882e46cd5d47", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n21\nThere\tare\tsome\tbenefits\tin\treturning\tJSON\tobjects\tfrom\ta\tprompt\tthat\textracts\tdata.\tIn\t\na\treal-world\tapplication\tI\tdon\u2019t\tneed\tto\tmanually\tcreate\tthis\tJSON\tformat,\tI\tcan\talready\t\nreturn\tthe\tdata\tin\ta\tsorted\torder\t(very\thandy\twhen\tworking\twith\tdatetime\tobjects),\tbut\tmost\t\nimportantly,\tby\tprompting\tfor\ta\tJSON\tformat\tit\tforces\tthe\tmodel\tto\tcreate\ta\tstructure\tand\t\nlimit\thallucinations.\nSystem\tprompts\tcan\talso\tbe\treally\tuseful\tfor\tsafety\tand\ttoxicity.\tTo\tcontrol\tthe\toutput,\tsimply\t\nadd\tan\tadditional\tline\tto\tyour\tprompt\tlike:\t\u2018You\tshould\tbe\trespectful\tin\tyour\tanswer.\u2019.\nRole prompting\nRole\tprompting\tis\ta\ttechnique\tin\tprompt\tengineering\tthat\tinvolves\tassigning\ta\tspecific\trole\tto\t\nthe\tgen\tAI\tmodel.\tThis\tcan\thelp\tthe\tmodel\tto\tgenerate\tmore\trelevant\tand\tinformative\toutput,\t\nas\tthe\tmodel\tcan\tcraft\tits\tresponses\tto\tthe\tspecific\trole\tthat\tit\thas\tbeen\tassigned.\nFor\texample,\tyou\tcould\trole\tprompt\ta\tgen\tAI\tmodel\tto\tbe\ta\tbook\teditor,\ta\tkindergarten\t\nteacher,\tor\ta\tmotivational\tspeaker.\tOnce\tthe\tmodel\thas\tbeen\tassigned\ta\trole,\tyou\tcan\tthen\t\ngive\tit\tprompts\tthat\tare\tspecific\tto\tthat\trole.\tFor\texample,\tyou\tcould\tprompt\ta\tteacher\tto\t\ncreate\ta\tlesson\tplan\tthat\tthey\tcan\tthen\treview.\tHave\ta\tlook\tinto\tTable\t5,\twhere\tthe\tmodel\t\ntakes\tthe\trole\tof\ta\ttravel\tguide.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1289, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bfa5b301-04ec-462e-82e0-01d939d3f853": {"__data__": {"id_": "bfa5b301-04ec-462e-82e0-01d939d3f853", "embedding": null, "metadata": {"page_label": "22", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "34891eee-e5d1-4275-8315-ade359a397c3", "node_type": "4", "metadata": {"page_label": "22", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "9c26850cb1ff78a8d0b8bc29e59695cc7f2f36898ec1aafd1dc00910ab7de7e4", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n22\nGoal Act as travel guide and provide 3 travel suggestions\nModel gemini-pro\nTemperature 1 Token Limit 1024\nTop-K 40 Top-P 0.8\nPrompt I want you to act as a travel guide. I will write to you \nabout my location and you will suggest 3 places to visit near \nme. In some cases, I will also give you the type of places I \nwill visit.\nMy suggestion: \"I am in Amsterdam and I want to visit \nonly museums.\"\nTravel Suggestions:\nOutput 1.\t Rijksmuseum:\tWorld-renowned\tmuseum,\tknown\tfor\tDutch\tmasterpieces\t\nlike\tRembrandt\u2019s\t\u201cThe\tNight\tWatch.\u201d\tDon\u2019t\tmiss\tthe\tincredible\tcollection\tof\t\npaintings\tand\tartifacts\tshowcasing\tDutch\tart\tand\thistory.\n2.\t Van\tGogh\tMuseum:\tImmerse\tyourself\tin\tthe\tcaptivating\tworks\tof\tVincent\t\nvan\tGogh.\tThe\tmuseum\thouses\tthe\tlargest\tcollection\tof\this\tpaintings\tand\t\ndrawings,\tincluding\t\u201cThe\tStarry\tNight\u201d\tand\t\u201cSunflowers.\u201d\n3.\t Stedelijk\tMuseum\tAmsterdam:\tDiscover\tmodern\tand\tcontemporary\tart\t\nfrom\taround\tthe\tworld.\tThe\tmuseum\u2019s\tcollection\tincludes\tworks\tby\tPicasso,\t\nKandinsky,\tand\tRietveld,\thoused\tin\ta\tstriking\tmodern\tbuilding.\nTable 5. An example of role prompting\nDefining\ta\trole\tperspective\tfor\tan\tAI\tmodel\tgives\tit\ta\tblueprint\tof\tthe\ttone,\tstyle,\tand\tfocused\t\nexpertise\tyou\u2019re\tlooking\tfor\tto\timprove\tthe\tquality,\trelevance,\tand\teffectiveness\tof\tyour\t\noutput.\t\nHere\tare\tsome\tstyles\tyou\tcan\tchoose\tfrom\twhich\tI\tfind\teffective:\nConfrontational,\tDescriptive,\tDirect,\tFormal,\tHumorous,\tInfluential,\tInformal,\t\nInspirational, Persuasive", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1485, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dce1451d-2b18-4e98-b25a-509adb1e6ea1": {"__data__": {"id_": "dce1451d-2b18-4e98-b25a-509adb1e6ea1", "embedding": null, "metadata": {"page_label": "23", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4cebcabb-0c24-41f6-8a4c-ebede2fcb238", "node_type": "4", "metadata": {"page_label": "23", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "f9bd4a1ae78a56e975e34162801051a1d931162ed1be250b1a883be9258fc31a", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n23\nLet\u2019s\tchange\tour\tprompt\tin\tTable\t6\tto\tinclude\ta\thumorous\tand\tinspirational\tstyle.\nPrompt I want you to act as a travel guide. I will write to you about \nmy location and you will suggest 3 places to visit near me in \na humorous style.\nMy suggestion: \"I am in Manhattan.\"\nTravel Suggestions:\nOutput 1.\t Behold\tthe\tEmpire\tState\tof\tMind:\tAscend\tto\tthe\tdizzying\theights\tof\tthe\tEmpire\t\nState\tBuilding\tand\tbask\tin\tthe\tglory\tof\tManhattan's\tskyline.\tPrepare\tto\tfeel\tlike\t\nKing\tKong\tatop\tthe\tBig\tApple,\tminus\tthe\tgiant\tape-sized\tbanana.\n2.\t Get\tArtsy-Fartsy\tat\tMoMA:\tUnleash\tyour\tinner\tart\taficionado\tat\tthe\tMuseum\t\nof\tModern\tArt\t(MoMA).\tGaze\tupon\tmasterpieces\tthat\twill\tboggle\tyour\t\nmind\tand\tmake\tyou\tquestion\twhether\tyour\tstick-figure\tdrawings\thave\tany\t\nartistic\tmerit.\n3.\t Shop\t\u2018Til\tYou\tDrop\ton\tFifth\tAvenue:\tIndulge\tin\tsome\tretail\ttherapy\ton\tthe\t\niconic\tFifth\tAvenue.\tBrace\tyourself\tfor\tsticker\tshock\tas\tyou\twindow-shop\t(or\t\nactually\tshop)\tat\tdesigner\tboutiques\tthat\twill\tmake\tyour\twallet\tcry.\tBut\they,\t\nyou\u2019re\tin\tManhattan,\tso\tyou\tmight\tas\twell\tembrace\tthe\tfabulousness!\nTable 6. An example of role prompting with a humorous tone and style\nContextual prompting\nBy providing contextual prompts, you can help ensure that your AI interactions are as \nseamless\tand\tefficient\tas\tpossible.\tThe\tmodel\twill\tbe\table\tto\tmore\tquickly\tunderstand\tyour\t\nrequest\tand\tbe\table\tto\tgenerate\tmore\taccurate\tand\trelevant\tresponses,\tas\tyou\tcan\tsee\tin\tthe\t\nexample\tof\tTable\t7.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1484, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "50f5be85-cd2c-41c0-9a4c-62f739e1a42a": {"__data__": {"id_": "50f5be85-cd2c-41c0-9a4c-62f739e1a42a", "embedding": null, "metadata": {"page_label": "24", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef54843c-ea66-4ddd-97f8-534fb50ac9d1", "node_type": "4", "metadata": {"page_label": "24", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "282bf1a3059f3625b51e271baf5f19fd8091969b3e122f89c98881e8ecbbc733", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n24\nGoal Suggest\tarticles\tfor\ta\tblog\tabout\tretro\tgames\nModel gemini-pro\nTemperature 1 Token Limit 1024\nTop-K 40 Top-P 0.8\nPrompt Context: You are writing for a blog about retro 80's arcade \nvideo games.\nSuggest 3 topics to write an article about with a few lines of \ndescription of what this article should contain.\nOutput 1.\t **The\tEvolution\tof\tArcade\tCabinet\tDesign:** \nThis\tarticle\twould\texplore\tthe\tevolution\tof\tarcade\tcabinet\tdesigns,\tfrom\tthe\t\nearly wood and metal cabinets of the 1970s to the sleek, neon-lit designs of \nthe\t1980s\tand\tbeyond.\n2.\t **Blast\tFrom\tThe\tPast:\tIconic\tArcade\tGames\tof\tThe\t80\u2019s:** \n-\tThis\tarticle\twould\tfeature\ta\tglimpse\tinto\tthe\thistory,\timpact,\tand\tlegacy\t\nof\tsome\tof\tthe\tmost\ticonic\tand\tinfluential\tarcade\tgames\tof\tthe\t1980s,\t\nhighlighting\ttheir\tinnovations,\tpopular\tmechanics,\tand\tenduring\tcharm.\n3.\t **The\tRise\tand\tRetro\tRevival\tof\tPixel\tArt:** \n-\tThis\tarticle\twould\tdelve\tinto\tthe\tevolution\tof\tpixel\tart\tas\ta\tdefining\tvisual\t\nstyle\tof\tearly\tarcade\tgames,\ttracing\tits\troots,\texploring\tits\ttechniques,\tand\t\ndiscussing\tthe\tresurgence\tof\tpixel\tart\tin\tmodern\tgames\tand\tdigital\tart.\nTable 7. An example of contextual prompting", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1190, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "90f42fcb-fd97-4c74-b83f-761787286af4": {"__data__": {"id_": "90f42fcb-fd97-4c74-b83f-761787286af4", "embedding": null, "metadata": {"page_label": "25", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "309bbfa1-ddc0-4501-9141-12672a740c34", "node_type": "4", "metadata": {"page_label": "25", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "5e7e39e37fb5405875ae6ebf6ced1992d0ebf517a9aab50959008e91641562a0", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n25\nStep-back prompting\nStep-back8\tprompting\tis\ta\ttechnique\tfor\timproving\tthe\tperformance\tby\tprompting\tthe\tLLM\t\nto\tfirst\tconsider\ta\tgeneral\tquestion\trelated\tto\tthe\tspecific\ttask\tat\thand,\tand\tthen\tfeeding\tthe\t\nanswer\tto\tthat\tgeneral\tquestion\tinto\ta\tsubsequent\tprompt\tfor\tthe\tspecific\ttask.\tThis\t\u2018step\t\nback\u2019\tallows\tthe\tLLM\tto\tactivate\trelevant\tbackground\tknowledge\tand\treasoning\tprocesses\t\nbefore\tattempting\tto\tsolve\tthe\tspecific\tproblem.\nBy considering the broader and underlying principles, LLMs can generate more accurate and \ninsightful\tresponses.\tStep-back\tprompting\tencourages\tLLMs\tto\tthink\tcritically\tand\tapply\ttheir\t\nknowledge\tin\tnew\tand\tcreative\tways.\tIt\tchanges\tthe\tfinal\tprompt\tdoing\tthe\ttask\tby\tutilizing\t\nmore\tknowledge\tin\tthe\tLLM\u2019s\tparameters\tthan\twould\totherwise\tcome\tinto\tplay\twhen\tthe\tLLM\t\nis\tprompted\tdirectly.\nIt can help to mitigate biases in LLM responses, by focusing on general principles instead of \nspecific\tdetails,\tstep-back\tprompting.\nLet\u2019s\thave\ta\tlook\tinto\tthese\texamples\tto\tunderstand\thow\tstep-back\tprompting\tcan\timprove\t\nthe\tresults.\tLet\u2019s\tfirst\treview\ta\ttraditional\tprompt\t(Table\t8)\tbefore\twe\tcompare\tit\tto\ta\tstep\t\nback\tprompt\t(Table\t9):", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1201, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "00724d84-2417-4fb1-b955-f3df9571f688": {"__data__": {"id_": "00724d84-2417-4fb1-b955-f3df9571f688", "embedding": null, "metadata": {"page_label": "26", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44d3029b-b91d-44e4-b396-d067e6490867", "node_type": "4", "metadata": {"page_label": "26", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c5d91483cb55427dde9333ea0650c5521f9608048ca785f6223e240ea330dab1", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n26\nGoal Write\ta\tstoryline\tfor\ta\tlevel\tof\ta\tfirst-person\tshooter\tvideo\tgame.\nModel gemini-pro\nTemperature 1 Token Limit 1024\nTop-K 40 Top-P 0.8\nPrompt Write a one paragraph storyline for a new level of a first-\nperson shooter video game that is challenging and engaging.\nOutput The\tlevel\tbegins\twith\tthe\tplayer\u2019s\tsquad\tbeing\tambushed\tin\ta\tdense\turban\tarea\t\nby\ta\trelentless\tenemy\tfaction.\tPlayers\tmust\tfight\ttheir\tway\tthrough\ta\tmaze\tof\t\nback alleys and dilapidated buildings, utilizing stealth and precision to eliminate \nenemy\tforces\tand\tavoid\tdetection.\tThe\tplayer\tmust\tuse\ttheir\tenvironment\tto\ttheir\t\nadvantage,\tsetting\ttraps,\tutilizing\tcover,\tand\tmaking\tcalculated\tmoves\tto\tsurvive.\t\nAlong the way, they uncover intel suggesting the enemy is planning a devastating \nattack,\tand\tthe\tplayer\tmust\trace\tagainst\ttime\tto\tgather\tevidence\tand\trelay\tit\tback\t\nto\ttheir\theadquarters\tbefore\tthe\tenemy\tcan\tcarry\tout\ttheir\tplans.\nTable 8. A traditional prompt before we compare it with a step back prompt\nWhen you set the temperature to 1, you might end up with all kinds of creative writings for a \nstoryline,\tbut\tit\u2019s\talso\tquite\trandom\tand\tgeneric.\tSo\tlet\u2019s\ttake\ta\tstep\tback:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1199, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8fb613ab-0561-4e66-be81-7b9aa95828d3": {"__data__": {"id_": "8fb613ab-0561-4e66-be81-7b9aa95828d3", "embedding": null, "metadata": {"page_label": "27", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3bd14228-a814-406b-a2c4-0e2b1653bfa0", "node_type": "4", "metadata": {"page_label": "27", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "5a7e0f41e9a94f9dd24bb35641daae1fa703ba11e413b4f69376e98e9889f60a", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n27\nPrompt Based on popular first-person shooter action games, what are \n5 fictional key settings that contribute to a challenging and \nengaging level storyline in a first-person shooter video game?\nOutput 1.\t **Abandoned\tMilitary\tBase**:\tA\tsprawling,\tpost-apocalyptic\tmilitary\tcomplex\t\ncrawling with mutated soldiers and rogue robots, ideal for challenging \nfirearm\tcombat.\n2.\t **Cyberpunk\tCity**:\tA\tneon-lit,\tfuturistic\turban\tenvironment\twith\ttowering\t\nskyscrapers and dense alleyways, featuring cybernetically enhanced enemies \nand\thacking\tmechanics.\n3.\t **Alien\tSpaceship**:\tA\tvast\talien\tvessel\tstranded\ton\tEarth,\twith\teerie\t\ncorridors,\tzero-gravity\tsections,\tand\textraterrestrial\tcreatures\tto\tencounter.\n4.\t **Zombie-Infested\tTown**:\tA\tdesolate\ttown\toverrun\tby\thordes\tof\taggressive\t\nzombies,\tfeaturing\tintense\tclose-quarters\tcombat\tand\tpuzzle-solving\tto\tfind\t\nsafe\tpassage.\n5.\t **Underwater\tResearch\tFacility**:\tA\tdeep-sea\tlaboratory\tflooded\twith\twater,\t\nfilled\twith\tmutated\taquatic\tcreatures,\tand\trequiring\tstealth\tand\tunderwater\t\nexploration\tskills\tto\tsurvive.\nTable 9. An example of prompting for self consistency\nYeah\tthose\ttopics\tseem\tlike\ta\tgood\tfit\tfor\ta\tfirst-person\tvideo\tgame.\tLet\u2019s\tgo\tback\tto\tthe\t\noriginal prompt, but this time we include the answer of the step back as context and see what \nit\twill\treturn.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1357, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6da64650-fd4c-4681-83ff-d0436ffbd743": {"__data__": {"id_": "6da64650-fd4c-4681-83ff-d0436ffbd743", "embedding": null, "metadata": {"page_label": "28", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c6440385-41ca-4d63-a640-c6b60ef118a3", "node_type": "4", "metadata": {"page_label": "28", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "ac1c079416e43c043411efebc818af27fa9f89b01fe6ae97f631c9c84a071a3d", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n28\nPrompt Context: 5 engaging themes for a first person shooter video game:\n1. **Abandoned Military Base**: A sprawling, post-apocalyptic \nmilitary complex crawling with mutated soldiers and rogue \nrobots, ideal for challenging firearm combat.\n2. **Cyberpunk City**: A neon-lit, futuristic urban environment \nwith towering skyscrapers and dense alleyways, featuring \ncybernetically enhanced enemies and hacking mechanics.\n3. **Alien Spaceship**: A vast alien vessel stranded on \nEarth, with eerie corridors, zero-gravity sections, and \nextraterrestrial creatures to encounter.\n4. **Zombie-Infested Town**: A desolate town overrun by hordes of \naggressive zombies, featuring intense close-quarters combat and \npuzzle-solving to find safe passage.\n5. **Underwater Research Facility**: A deep-sea laboratory flooded \nwith water, filled with mutated aquatic creatures, and requiring \nstealth and underwater exploration skills to survive.\nTake one of the themes and write a one paragraph storyline \nfor a new level of a first-person shooter video game that is \nchallenging and engaging.\nOutput In\tthe\theart\tof\ta\tmurky\tabyss,\tlies\ta\tdilapidated\tunderwater\tresearch\tfacility,\t\nstanding\tas\ta\ttestament\tto\thuman\tambition\tand\tits\tdisastrous\tconsequences.\t\nShrouded in darkness, pulsating with the hum of malfunctioning machinery, and \nhaunted by the echoes of drowned souls, the facility is now a breeding ground for \na\tnightmare\tborne\tfrom\tthe\tdeep\tsea.\tThe\tplayer,\tan\telite\tmarine\tequipped\twith\t\nadvanced diving gear and experimental weaponry, is tasked with venturing into \nthis\taquatic\trealm\tof\tterror.\tArmed\twith\tresilience\tand\tresourcefulness,\tthey\tmust\t\nnavigate treacherous corridors, solve cryptic puzzles, and confront gruesome sea \nmonstrosities\tthat\tlurk\tin\tthe\tdepths.\tFrom\tgrappling\twith\tthe\tcrushing\tpressure\t\nof\tthe\tdeep\tsea\tto\toutsmarting\tcunning\taquatic\tpredators,\tevery\tmoment\tin\tthis\t\nuncharted\tunderworld\ttests\tthe\tlimits\tof\thuman\tendurance\tand\tcourage.\nTable 10. An example of prompting for self consistency\nThat\tlooks\tlike\tan\tinteresting\tvideo\tgame!\tBy\tusing\tstep\tback\tprompting\ttechniques\tyou\tcan\t\nincrease\tthe\taccuracy\tof\tyour\tprompts.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2184, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81f0ef82-16e9-434e-913b-73e29492559f": {"__data__": {"id_": "81f0ef82-16e9-434e-913b-73e29492559f", "embedding": null, "metadata": {"page_label": "29", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "abfa6591-e1b9-49ba-86ec-d4a7353de27b", "node_type": "4", "metadata": {"page_label": "29", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "085d8773e600f78d7aa55eb3b86514a1f97c358b0b889b5fddf8e1f548edc657", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n29\nChain of Thought (CoT)\nChain of Thought (CoT) 9\tprompting\tis\ta\ttechnique\tfor\timproving\tthe\treasoning\tcapabilities\t\nof LLMs by generating intermediate reasoning steps.\tThis\thelps\tthe\tLLM\tgenerate\tmore\t\naccurate\tanswers.\tYou\tcan\tcombine\tit\twith\tfew-shot\tprompting\tto\tget\tbetter\tresults\ton\tmore\t\ncomplex\ttasks\tthat\trequire\treasoning\tbefore\tresponding\tas\tit\u2019s\ta\tchallenge\twith\ta\tzero-shot\t\nchain\tof\tthought.\nCoT\thas\ta\tlot\tof\tadvantages.\tFirst\tof\tall,\tit\u2019s\tlow-effort\twhile\tbeing\tvery\teffective\tand\tworks\t\nwell\twith\toff-the-shelf\tLLMs\t(so\tno\tneed\tto\tfinetune).\tYou\talso\tget\tinterpretability\twith\tCoT\t\nprompting,\tas\tyou\tcan\tlearn\tfrom\tthe\tLLM\u2019s\tresponses\tand\tsee\tthe\treasoning\tsteps\tthat\twere\t\nfollowed.\tIf\tthere\u2019s\ta\tmalfunction,\tyou\twill\tbe\table\tto\tidentify\tit.\tChain\tof\tthought\tappears\t\nto\timprove\trobustness\twhen\tmoving\tbetween\tdifferent\tLLM\tversions.\tWhich\tmeans\tthe\t\nperformance\tof\tyour\tprompt\tshould\tdrift\tless\tbetween\tdifferent\tLLMs\tthan\tif\tyour\tprompt\t\ndoes\tnot\tuse\treasoning\tchains.\tOf\tcourse\tthere\tare\talso\tdisadvantages,\tbut\tthey\tare\t\nsomewhat\tintuitive.\nThe LLM response includes the chain of thought reasoning, which means more output \ntokens,\twhich\tmeans\tpredictions\tcost\tmore\tmoney\tand\ttake\tlonger.\nTo\texplain\tthe\tfollowing\texample\tin\tTable\t11,\tlet\u2019s\tfirst\ttry\tto\tcreate\ta\tprompt\tthat\tis\tnot\tusing\t\nCoT\tprompting\tto\tshowcase\tthe\tflaws\tof\ta\tlarge\tlanguage\tmodel.\nPrompt When I was 3 years old, my partner was 3 times my age. Now, I \nam 20 years old. How old is my partner?\nOutput 63 years old\nTable 11. An example of a prompt which is trying to solve a mathematical problem", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1618, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4b8178c4-cbae-4e99-914e-4907886dbb8b": {"__data__": {"id_": "4b8178c4-cbae-4e99-914e-4907886dbb8b", "embedding": null, "metadata": {"page_label": "30", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88ca3a9a-c571-45ca-a2a0-2c871e74d60e", "node_type": "4", "metadata": {"page_label": "30", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "adeb1424857576190f188394f82817af4b082c90381fc5afdc2a13c4bd04637e", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n30\nYikes.\tThat\u2019s\tobviously\tthe\twrong\tanswer.\tAs\ta\tmatter\tof\tfact,\tLLMs\toften\tstruggle\twith\t\nmathematical tasks and can provide incorrect answers \u2013 even for a task as simple as \nmultiplying\ttwo\tnumbers.\tThis\tis\tbecause\tthey\tare\ttrained\ton\tlarge\tvolumes\tof\ttext\tand\tmath\t\nmay\trequire\ta\tdifferent\tapproach.\tSo\tlet\u2019s\tsee\tif\tintermediate\treasoning\tsteps\twill\timprove\t\nthe\toutput.\nPrompt When I was 3 years old, my partner was 3 times my age. Now, \nI am 20 years old. How old is my partner? Let's think step \nby step.\nOutput 1.\t Let\u2019s\tassume\tmy\tcurrent\tage\tis\t\u201cx\u201d\tyears.\n2.\t When\tI\twas\t3\tyears\told,\tmy\tage\twas\t3\tyears.\n3.\t My\tpartner\u2019s\tage\tat\tthat\ttime\twas\t3\ttimes\tmy\tage,\twhich\tmeans\tmy\tpartner\u2019s\t\nage\twas\t3\t*\t3\t=\t9\tyears.\n4.\t Now, I am 20 years old, which means my age has increased by 20 - 3 = 17 \nyears\tsince\tI\twas\t3\tyears\told.\n5.\t Since\tmy\tpartner\u2019s\tage\twas\t9\tyears\twhen\tI\twas\t3\tyears\told,\tand\tmy\tage\thas\t\nincreased\tby\t17\tyears,\tmy\tpartner\u2019s\tage\tmust\thave\talso\tincreased\tby\t17\tyears.\n6.\t Therefore,\tmy\tpartner\u2019s\tcurrent\tage\tis\t9\t+\t17\t=\t26\tyears.\nSo,\tmy\tpartner\tis\t26\tyears\told.\nTable 12. An example of Chain of Thought prompting\nAlright,\tnow\tthe\tfinal\tanswer\tis\tcorrect.\tThat\u2019s\tbecause\twe\tclearly\tinstructed\tthe\tLLM\tto\t\nexplain\teach\tstep\tinstead\tof\tjust\treturning\tan\tanswer.\tIt\u2019s\tinteresting\tto\tsee\tthat\tthe\tmodel\t\nadds\tup\tthe\t17\tincreased\tyears.\tIn\tmy\thead\tI\twould\ttake\tthe\tdifference\tof\tyears\tbetween\tmy\t\npartner\tand\tme\tand\tadd\tthose\tup.\t(20+(9-3)).\tLet\u2019s\thelp\tthe\tmodel\tto\tthink\ta\tlittle\tbit\tmore\t\nlike\tme.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1542, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3514d3f3-796f-437f-9dc9-12cc2ba36dee": {"__data__": {"id_": "3514d3f3-796f-437f-9dc9-12cc2ba36dee", "embedding": null, "metadata": {"page_label": "31", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "84e16337-50af-4ee1-85e3-7146a09029d8", "node_type": "4", "metadata": {"page_label": "31", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b038fe5b0438502c2b88a32df642e3df9165fc40987253d9071b326be9af6be4", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n31\nTable\t12\tis\tan\texample\tof\t\u2018zero-shot\u2019\tChain\tof\tthought.\tChain\tof\tthought\tprompting\tcan\tbe\t\nvery\tpowerful\twhen\tcombined\twith\ta\tsingle-shot\tor\tfew-shot,\tas\twhat\tyou\tcan\tsee\tin\tTable\t13:\nPrompt Q: When my brother was 2 years old, I was double his age. Now \nI am 40 years old. How old is my brother? Let's think step \nby step.\nA: When my brother was 2 years, I was 2 * 2 = 4 years old. \nThat's an age difference of 2 years and I am older. Now I am 40 \nyears old, so my brother is 40 - 2  = 38 years old. The answer \nis 38.\nQ: When I was 3 years old, my partner was 3 times my age. Now, \nI am 20 years old. How old is my partner? Let's think step \nby step.\nA:\nOutput When\tI\twas\t3\tyears\told,\tmy\tpartner\twas\t3\t*\t3\t=\t9\tyears\told.\tThat\u2019s\tan\tage\t\ndifference\tof\t6\tyears\tand\tmy\tpartner\tis\tolder.\tNow\tI\tam\t20\tyears\told,\tso\tmy\t\npartner\tis\t20\t+\t6\t=\t26\tyears\told.\tThe\tanswer\tis\t26.\nTable 13. An example of chain of thought prompting with a single-shot\nChain\tof\tthought\tcan\tbe\tuseful\tfor\tvarious\tuse-cases.\tThink\tof\tcode\tgeneration,\tfor\tbreaking\t\ndown\tthe\trequest\tinto\ta\tfew\tsteps,\tand\tmapping\tthose\tto\tspecific\tlines\tof\tcode.\tOr\tfor\t\ncreating synthetic data when you have some kind of seed like \u201cThe product is called XYZ, \nwrite a description guiding the model through the assumptions you would make based on \nthe product given title.\u201d\tGenerally,\tany\ttask\tthat\tcan\tbe\tsolved\tby\t\u2018talking\tthrough\tis\ta\tgood\t\ncandidate\tfor\ta\tchain\tof\tthought.\tIf\tyou\tcan\texplain\tthe\tsteps\tto\tsolve\tthe\tproblem,\ttry\tchain\t\nof\tthought.\nPlease refer to the notebook10\thosted\tin\tthe\tGoogleCloudPlatform\tGithub\trepository\twhich\t\nwill\tgo\tinto\tfurther\tdetail\ton\tCoT\tprompting:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1671, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2e284ebd-2776-416c-89ca-8951eb39b17c": {"__data__": {"id_": "2e284ebd-2776-416c-89ca-8951eb39b17c", "embedding": null, "metadata": {"page_label": "32", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "653a7c4b-8834-4b8c-b8d2-2dd60d663502", "node_type": "4", "metadata": {"page_label": "32", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b0a54dd5428f8f79486e0172322095b6ce125644ac30fc34b25705f91f194802", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n32\nIn\tthe\tbest\tpractices\tsection\tof\tthis\tchapter,\twe\twill\tlearn\tsome\tbest\tpractices\tspecific\tto\t\nChain\tof\tthought\tprompting.\nSelf-consistency\nWhile large language models have shown impressive success in various NLP tasks, their \nability\tto\treason\tis\toften\tseen\tas\ta\tlimitation\tthat\tcannot\tbe\tovercome\tsolely\tby\tincreasing\t\nmodel\tsize.\tAs\twe\tlearned\tin\tthe\tprevious\tChain\tof\tThought\tprompting\tsection,\tthe\tmodel\tcan\t\nbe\tprompted\tto\tgenerate\treasoning\tsteps\tlike\ta\thuman\tsolving\ta\tproblem.\tHowever\tCoT\tuses\t\na\tsimple\t\u2018greedy\tdecoding\u2019\tstrategy,\tlimiting\tits\teffectiveness.\tSelf-consistency11 combines \nsampling and majority voting to generate diverse reasoning paths and select the most \nconsistent\tanswer.\tIt\timproves\tthe\taccuracy\tand\tcoherence\tof\tresponses\tgenerated\tby\tLLMs.\nSelf-consistency gives a pseudo-probability likelihood of an answer being correct, but \nobviously\thas\thigh\tcosts.\nIt\tfollows\tthe\tfollowing\tsteps:\n1.\t Generating\tdiverse\treasoning\tpaths:\tThe\tLLM\tis\tprovided\twith\tthe\tsame\tprompt\tmultiple\t\ntimes.\tA\thigh\ttemperature\tsetting\tencourages\tthe\tmodel\tto\tgenerate\tdifferent\treasoning\t\npaths\tand\tperspectives\ton\tthe\tproblem.\n2.\tExtract\tthe\tanswer\tfrom\teach\tgenerated\tresponse.\n3.\tChoose\tthe\tmost\tcommon\tanswer.\nLet\u2019s\tlook\tinto\tan\texample\tof\tan\temail\tclassification\tsystem,\twhich\tclassifies\tan\temail\tas\t\nIMPORTANT\tor\tNOT\tIMPORTANT.\tA\tzero-shot\tchain\tof\tthought\tprompt\twill\tbe\tsent\tto\tthe\tLLM\t\nmultiple\ttimes,\tto\tsee\tif\tthe\tresponses\tdiffer\tafter\teach\tsubmit.\tNotice\tthe\tfriendly\ttone,\tthe\t\nword\tchoice\tand\tthe\tsarcasm\tthat\u2019s\tbeen\tused\tin\tthe\temail.\tAll\tthis\tcould\ttrick\tthe\tLLM.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1626, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "553575ea-36a1-4ff3-9d92-5b37856de303": {"__data__": {"id_": "553575ea-36a1-4ff3-9d92-5b37856de303", "embedding": null, "metadata": {"page_label": "33", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d6f8857a-1761-4121-b2ec-1860929989cc", "node_type": "4", "metadata": {"page_label": "33", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "693323cb5f9fadb1ec398cfff191962028dcab6a30fb7c3f0d9a6e3220623895", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n33\nPrompt EMAIL:\n```\nHi,\nI have seen you use Wordpress for your website. A great open \nsource content management system. I have used it in the past \ntoo. It comes with lots of great user plugins. And it's pretty \neasy to set up.\nI did notice a bug in the contact form, which happens when \nyou select the name field. See the attached screenshot of me \nentering text in the name field. Notice the JavaScript alert \nbox that I inv0k3d.\nBut for the rest it's a great website. I enjoy reading it. Feel \nfree to leave the bug in the website, because it gives me more \ninteresting things to read.\nCheers,\nHarry the Hacker.\n```\nClassify the above email as IMPORTANT or NOT IMPORTANT. Let's \nthink step by step and explain why.\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 775, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "302e38ef-c217-43d3-8277-2f05409fd9c4": {"__data__": {"id_": "302e38ef-c217-43d3-8277-2f05409fd9c4", "embedding": null, "metadata": {"page_label": "34", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "563894cf-9067-4c75-9966-f4ac117449f7", "node_type": "4", "metadata": {"page_label": "34", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "4a3493ed1848e8eca17a6e3459b1862a356722dc6e9871c0e762e25f7160846e", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n34\nOutput \nAttempt 1\n**Step\t1:\tIdentify\tthe\tpurpose\tof\tthe\temail.**\nThe purpose of the email is to inform the recipient of a bug in the contact form \non\ttheir\twebsite.\tThe\tsender\talso\tmentions\tthat\tthey\tenjoy\treading\tthe\twebsite\t\nand\tthat\tthey\tare\tleaving\tthe\tbug\tin\tplace\tfor\tthe\ttime\tbeing.\n**Step\t2:\tAssess\tthe\tpotential\timpact\tof\tthe\tbug.**\nThe\tbug\tin\tthe\tcontact\tform\tcould\tallow\tan\tattacker\tto\texecute\tarbitrary\t\nJavaScript\tcode\ton\tthe\twebsite.\tThis\tcould\tlead\tto\tthe\tattacker\tbeing\table\tto\ttake\t\ncontrol\tof\tthe\twebsite,\tsteal\tsensitive\tinformation,\tor\tdeface\tthe\twebsite.\n**Step\t3:\tConsider\tthe\tcredibility\tof\tthe\tsender.**\nThe\tsender\tof\tthe\temail\tclaims\tto\tbe\ta\thacker\tnamed\tHarry.\tHowever,\tthere\tis\tno\t\nway\tto\tverify\tthe\tsender\u2019s\tidentity.\tIt\tis\tpossible\tthat\tthe\tsender\tis\ta\tlegitimate\t\nhacker who is trying to help the recipient, but it is also possible that the sender \nis a malicious actor who is trying to trick the recipient into clicking on a malicious \nlink\tor\tdownloading\ta\tmalicious\tfile.\n**Conclusion:\tIMPORTANT**\nBased on the potential impact of the bug and the credibility of the sender, \nthe\temail\tshould\tbe\tclassified\tas\t**IMPORTANT**.\tThe\trecipient\tshould\ttake\t\nimmediate\taction\tto\tfix\tthe\tbug\tand\tprotect\ttheir\twebsite\tfrom\tattack.\nOutput \nAttempt 2\n**Explanation:**\n1.\t **Lack\tof\turgency:**\tThe\temail\tdoes\tnot\tconvey\tany\tsense\tof\turgency\tor\t\ntime-sensitivity.\tIt\tstarts\twith\ta\tcasual\tgreeting\tand\tpresents\tthe\tinformation\t\nin\ta\tmatter-of-fact\ttone.\n2.\t **Non-critical\tbug\treport:**\tThe\tbug\treported\tin\tthe\tcontact\tform\tis\t\ndescribed\tas\tinteresting\tbut\tnot\tcritical.\tThe\temail\tsender\teven\tsuggests\tthat\t\nthe\twebsite\towner\tcan\tleave\tthe\tbug\tin\tplace.\n3.\t **Lack\tof\tpersonal\timpact:**\tThe\temail\tdoes\tnot\tindicate\tany\tdirect\tor\t\npersonal\timpact\ton\tthe\twebsite\towner.\tIt\tsimply\tmentions\tthat\tthe\tsender\t\nenjoys\treading\tthe\twebsite.\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1910, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e7101447-b5e8-46c2-9b7c-37b6e86373f3": {"__data__": {"id_": "e7101447-b5e8-46c2-9b7c-37b6e86373f3", "embedding": null, "metadata": {"page_label": "35", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "35fdf474-c1b3-4c83-ba9f-bec0f96a7554", "node_type": "4", "metadata": {"page_label": "35", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "fc8f1b1226ddb342ad63bf17ce02be8406685e2b16b78acd3195bbdcc06e0280", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n35\nOutput \nAttempt 2\n4.\t **Absence\tof\taction\trequest:**\tThe\temail\tdoes\tnot\texplicitly\trequest\tany\t\naction\tfrom\tthe\twebsite\towner.\tIt\tdoes\tnot\task\tfor\tthe\tbug\tto\tbe\tfixed\tor\t\nprovide\tany\tspecific\tsuggestions\tfor\timprovement.\n5.\t **Sender\u2019s\tintent:**\tThe\tsender\u2019s\tintention\tseems\tto\tbe\tmore\tfocused\ton\t\nsharing an observation and expressing interest in the website rather than \nraising\ta\tserious\tconcern\tor\trequesting\tassistance.\n**Conclusion:\tNOT\tIMPORTANT**\nOutput \nAttempt 3\n**Step\t1:\tIdentify\tthe\tpurpose\tof\tthe\temail.**\nThe purpose of the email is to inform the recipient of a bug in the contact form on \ntheir\twebsite.\tThe\tsender\talso\tmentions\tthat\tthey\tenjoy\treading\tthe\twebsite\tand\t\nthat\tthey\tare\tleaving\tthe\tbug\tin\tplace\tfor\tthe\ttime\tbeing.\n**Step\t2:\tAssess\tthe\tpotential\timpact\tof\tthe\tbug.**\nThe\tbug\tin\tthe\tcontact\tform\tcould\tallow\tan\tattacker\tto\texecute\tarbitrary\t\nJavaScript\tcode\ton\tthe\twebsite.\tThis\tcould\tlead\tto\tthe\tattacker\tbeing\table\tto\ttake\t\ncontrol\tof\tthe\twebsite,\tsteal\tsensitive\tinformation,\tor\tdeface\tthe\twebsite.\n**Step\t3:\tConsider\tthe\tcredibility\tof\tthe\tsender.**\nThe\tsender\tof\tthe\temail\tclaims\tto\tbe\ta\thacker\tnamed\tHarry.\tHowever,\tthere\tis\tno\t\nway\tto\tverify\tthe\tsender\u2019s\tidentity.\tIt\tis\tpossible\tthat\tthe\tsender\tis\ta\tlegitimate\t\nhacker who is trying to help the recipient, but it is also possible that the sender is \na\tmalicious\tactor\twho\tis\ttrying\tto\texploit\tthe\tbug\tfor\ttheir\town\tgain.\n**Conclusion:**\nBased\ton\tthe\tabove\tfactors,\tthe\temail\tshould\tbe\tclassified\tas\t**IMPORTANT**.\t\nThe\tbug\tin\tthe\tcontact\tform\tis\ta\tserious\tsecurity\trisk,\tand\tthe\tsender\u2019s\tcredibility\t\nis\tunknown.\tThe\trecipient\tshould\ttake\timmediate\taction\tto\tfix\tthe\tbug\tand\t\ninvestigate\tthe\tsender\u2019s\tclaims.\nTable 14. An example of prompting for self consistency\nYou\tcan\tuse\tthe\tabove\tprompt\tand\ttry\tto\tsee\tif\tit\treturns\ta\tconsistent\tclassification.\t\nDepending\ton\tthe\tmodel\tthat\tyou\tare\tusing\tand\tthe\ttemperature\tconfiguration,\tit\tmight\t\nreturn\t\u201cIMPORTANT\u201d\tor\t\u201cNOT\tIMPORTANT\u201d.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2001, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd4f1cf9-3c56-4fec-8c8c-6121854f1cca": {"__data__": {"id_": "bd4f1cf9-3c56-4fec-8c8c-6121854f1cca", "embedding": null, "metadata": {"page_label": "36", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0527a179-f47d-4bb3-85cb-a8e55b6ddea4", "node_type": "4", "metadata": {"page_label": "36", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "9c408f8787d102d7b1416fb7bb5fa1c0a69372ab356ae031e2ea2e6cdad80d2c", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n36\nBy generating many Chains of Thoughts, and taking the most commonly occurring answer \n(\u201cIMPORTANT\u201d),\twe\tcan\tget\ta\tmore\tconsistently\tcorrect\tanswer\tfrom\tthe\tLLM.\nThis example shows how self-consistency prompting can be used to improve the accuracy \nof\tan\tLLM\u2019s\tresponse\tby\tconsidering\tmultiple\tperspectives\tand\tselecting\tthe\tmost\t\nconsistent\tanswer.\nTree of Thoughts (ToT)\nNow\tthat\twe\tare\tfamiliar\twith\tchain\tof\tthought\tand\tself-consistency\tprompting,\tlet\u2019s\treview\t\nTree\tof\tThoughts\t(ToT).12 It generalizes the concept of CoT prompting because it allows LLMs \nto\texplore\tmultiple\tdifferent\treasoning\tpaths\tsimultaneously,\trather\tthan\tjust\tfollowing\ta\t\nsingle\tlinear\tchain\tof\tthought.\tThis\tis\tdepicted\tin\tFigure\t1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 749, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "80cc60f1-205c-4670-a69b-d9f6a496c998": {"__data__": {"id_": "80cc60f1-205c-4670-a69b-d9f6a496c998", "embedding": null, "metadata": {"page_label": "37", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ae74c5b0-989e-4543-afcc-edff35ab5525", "node_type": "4", "metadata": {"page_label": "37", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "af0bdef841c7a9b9545d7b162fbf4fdb2d1eef1a940577e543e74047ff66a87b", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n37\nFigure 1. A visualization of chain of thought prompting on the left versus. Tree of Thoughts prompting on \nthe right\nThis\tapproach\tmakes\tToT\tparticularly\twell-suited\tfor\tcomplex\ttasks\tthat\trequire\texploration.\tIt\t\nworks by maintaining a tree of thoughts, where each thought represents a coherent language \nsequence\tthat\tserves\tas\tan\tintermediate\tstep\ttoward\tsolving\ta\tproblem.\tThe\tmodel\tcan\tthen\t\nexplore\tdifferent\treasoning\tpaths\tby\tbranching\tout\tfrom\tdifferent\tnodes\tin\tthe\ttree.\t\nThere\u2019s\ta\tgreat\tnotebook,\twhich\tgoes\tinto\ta\tbit\tmore\tdetail\tshowing\tThe\tTree\tof\tThought\t\n(ToT)\twhich\tis\tbased\ton\tthe\tpaper\t\u2018Large\tLanguage\tModel\tGuided\tTree-of-Thought\u2019.9\nReAct (reason & act)\nReason and act (ReAct) [10]13 prompting is a paradigm for enabling LLMs to solve complex \ntasks using natural language reasoning combined with external tools (search, code \ninterpreter\tetc.)\tallowing\tthe\tLLM\tto\tperform\tcertain\tactions,\tsuch\tas\tinteracting\twith\texternal\t\nAPIs\tto\tretrieve\tinformation\twhich\tis\ta\tfirst\tstep\ttowards\tagent\tmodeling.\nReAct mimics how humans operate in the real world, as we reason verbally and can \ntake\tactions\tto\tgain\tinformation.\tReAct\tperforms\twell\tagainst\tother\tprompt\tengineering\t\napproaches\tin\ta\tvariety\tof\tdomains.\nReAct\tprompting\tworks\tby\tcombining\treasoning\tand\tacting\tinto\ta\tthought-action\tloop.\tThe\t\nLLM\tfirst\treasons\tabout\tthe\tproblem\tand\tgenerates\ta\tplan\tof\taction.\tIt\tthen\tperforms\tthe\t\nactions\tin\tthe\tplan\tand\tobserves\tthe\tresults.\tThe\tLLM\tthen\tuses\tthe\tobservations\tto\tupdate\t\nits\treasoning\tand\tgenerate\ta\tnew\tplan\tof\taction.\tThis\tprocess\tcontinues\tuntil\tthe\tLLM\t\nreaches\ta\tsolution\tto\tthe\tproblem.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1656, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b8d1807-d985-4e8c-8d4e-fff35735c56c": {"__data__": {"id_": "5b8d1807-d985-4e8c-8d4e-fff35735c56c", "embedding": null, "metadata": {"page_label": "38", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c3107673-6add-4e2b-abf0-79ecf797b6ba", "node_type": "4", "metadata": {"page_label": "38", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "fabd83fc00fb6071220e28c325cf5b3546f49fefebb066b87d9003db5f1ace7c", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n38\nTo\tsee\tthis\tin\taction,\tyou\tneed\tto\twrite\tsome\tcode.\tIn\tcode\tSnippet\t1\tI\tam\tusing\tthe\tlangchain\t\nframework\tfor\tPython,\ttogether\twith\tVertexAI\t(google-cloud-aiplatform) and the \ngoogle-search-results pip packages.\nTo run this sample you must create a (free) SerpAPI key from https://serpapi.com/manage-\napi-key and set an environment variable SERPAPI_API_KEY.\nNext\tlet\u2019s\twrite\tsome\tPython\tcode,\twith\tthe\ttask\tfor\tthe\tLLM\tto\tfigure\tout:\tHow many children \nhave a famous dad that performs in the band Metallica.\nPython\nfrom langchain.agents import load_tools\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType\nfrom langchain.llms import VertexAI\nprompt = \"How many kids do the band members of Metallica have?\"\nllm = VertexAI(temperature=0.1)\ntools = load_tools([\"serpapi\"], llm=llm)\nagent = initialize_agent(tools, llm,  \nagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\nagent.run(prompt)\nSnippet 1. Creating a ReAct Agent with LangChain and VertexAI\nCode\tSnippet\t2\tshows\tthe\tresult.\tNotice\tthat\tReAct\tmakes\ta\tchain\tof\tfive\tsearches.\tIn\tfact,\t\nthe\tLLM\tis\tscraping\tGoogle\tsearch\tresults\tto\tfigure\tout\tthe\tband\tnames.\tThen,\tit\tlists\tthe\t\nresults\tas\tobservations\tand\tchains\tthe\tthought\tfor\tthe\tnext\tsearch.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1280, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d2f69065-94d9-4249-a848-714dc82afc06": {"__data__": {"id_": "d2f69065-94d9-4249-a848-714dc82afc06", "embedding": null, "metadata": {"page_label": "39", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "18dce106-3e5e-4262-8304-99a504a69248", "node_type": "4", "metadata": {"page_label": "39", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "c80f870f79c6ad1c0a392995956c407eb23b9b7ecc3b6a3fdf897af91937baaa", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n39\nUnset\n> Entering new AgentExecutor chain...\nMetallica has 4 members. \nAction: Search\nAction Input: How many kids does James Hetfield have?\nObservation: three children\nThought: 1/4 Metallica band members have 3 children\nAction: Search\nAction Input: How many kids does Lars Ulrich have?\nObservation: 3\nThought: 2/4 Metallica band members have 6 children\nAction: Search\nAction Input: How many kids does Kirk Hammett have?\nObservation: Hammett has been married to his second wife Lani since 1998. \nThey have two sons, Angel (b. September 29, 2006) and Vincenzo (b. June \n28, 2008).\nThought: 3/4 Metallica band members have 8 children\nAction: Search\nAction Input: How many kids does Robert Trujillo have?\nObservation: 2\nThought: 4/4 Metallica band members have 10 children\nFinal Answer: 10\n Snippet 2. Executing ReAct Agent in the terminal\nCode\tSnippet\t2\tfigures\tout\tthat\tthe\tband\tMetallica\thas\tfour\tband\tmembers.\tThen\tit\tsearches\t\neach\tband\tmember\tto\trequest\tthe\ttotal\tof\tchildren\tand\tadd\tup\tthe\ttotal.\tFinally,\tit\treturns\tthe\t\ntotal\tnumber\tof\tchildren\tas\tthe\tfinal\tanswer.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1106, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3560ea93-ec88-4e2c-975a-2130f019766d": {"__data__": {"id_": "3560ea93-ec88-4e2c-975a-2130f019766d", "embedding": null, "metadata": {"page_label": "40", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9942236c-3fd4-4e84-b6db-ecf3dbe1db3c", "node_type": "4", "metadata": {"page_label": "40", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "ad29688ebab93fd5490d80cc9fbdc926c0fc63124cd951d0940923630ddb14ea", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n40\nReAct\tprompting\tin\tpractice\trequires\tunderstanding\tthat\tyou\tcontinually\thave\tto\tresend\tthe\t\nprevious prompts/responses (and do trimming of the extra generated content) as well as set \nup\tthe\tmodel\twith\tappropriate\texamples/instructions.\tPlease\trefer\tto\tthe\tnotebook14 hosted \nin\tthe\tGoogleCloudPlatform\tGithub\trepository,\twhich\tgoes\tinto\ta\tbit\tmore\tdetail\tshowing\tthe\t\nactual LLM inputs and outputs with a more elaborate example\nAutomatic Prompt Engineering\nAt\tthis\tpoint\tyou\tmight\trealize\tthat\twriting\ta\tprompt\tcan\tbe\tcomplex.\tWouldn\u2019t\tit\tbe\tnice\tto\t\nautomate\tthis\t(write\ta\tprompt\tto\twrite\tprompts)?\tWell,\tthere\u2019s\ta\tmethod:\tAutomatic\tPrompt\t\nEngineering\t(APE).\tThis\tmethod15 not only alleviates the need for human input but also \nenhances\tthe\tmodel\u2019s\tperformance\tin\tvarious\ttasks.\nYou\twill\tprompt\ta\tmodel\tto\tgenerate\tmore\tprompts.\tEvaluate\tthem,\tpossibly\talter\tthe\tgood\t\nones.\tAnd\trepeat.\nFor example, you can use automatic prompt engineering that will help with training a chatbot \nfor\ta\tmerchandise\tt-shirt\twebshop.\tWe\twant\tto\tfigure\tout\tall\tthe\tvarious\tways\tcustomers\t\ncould\tphrase\ttheir\torder\tfor\tbuying\ta\tband\tmerchandise\tt-shirt.\n1.\t Write\tthe\tprompt\twhich\twill\tgenerate\tthe\toutput\tvariants.\tIn\tthis\texample,\tI\tam\tusing\t\ngemini-pro\tto\tgenerate\t10\tinstructions.\tSee\tTable\t15:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1318, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5ba21c4b-ae2f-4173-96a1-c7e9fab395c0": {"__data__": {"id_": "5ba21c4b-ae2f-4173-96a1-c7e9fab395c0", "embedding": null, "metadata": {"page_label": "41", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "32270606-7c44-4d50-b287-0d70cc208afe", "node_type": "4", "metadata": {"page_label": "41", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "58d76abb24fd83fd7387a7b7d22305103e3e23ebac4fa4849d0f2230422137b0", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n41\nPrompt We have a band merchandise t-shirt webshop, and to train a \nchatbot we need various ways to order: \"One Metallica t-shirt \nsize S\". Generate 10 variants, with the same semantics but keep \nthe same meaning.\nOutput 1.\t I\u2019d\tlike\tto\tpurchase\ta\tMetallica\tt-shirt\tin\tsize\tsmall.\n2.\t Can\tI\torder\ta\tsmall-sized\tMetallica\tt-shirt?\n3.\t I\u2019d\tlike\tto\tbuy\tone\tMetallica\tt-shirt\tin\tsmall.\n4.\t One\tMetallica\tshirt,\tsize\tsmall,\tplease.\n5.\t I\twant\tone\tMetallica\tt-shirt\tin\tsize\tsmall.\n6.\t I\u2019d\tlike\tto\tplace\tan\torder\tfor\tone\tMetallica\tt-shirt\tin\tsmall.\n7.\t Small\tMetallica\tt-shirt,\tone\tplease.\n8.\t I\u2019m\tlooking\tfor\tone\tMetallica\tt-shirt\tin\tsmall.\n9.\t Can\tyou\tget\tme\tone\tMetallica\tt-shirt\tin\tsmall?\n10.\tOne\tMetallica\tsmall\tt-shirt,\tplease.\nTable 15. Use an LLM to generate prompts\n2.\tEvaluate all of the instruction candidates by scoring the candidates based on a chosen \nmetric,\tFor\texample,\tyou\tcan\tuse.\tBLEU\t(Bilingual\tEvaluation\tUnderstudy)\tor\tROUGE\t\n(Recall-Oriented\tUnderstudy\tfor\tGisting\tEvaluation).\n3.\tSelect\tthe\tinstruction\tcandidate\twith\tthe\thighest\tevaluation\tscore.\tThis\tcandidate\twill\tbe\t\nthe\tfinal\tprompt\tyou\tcan\tuse\tin\tyour\tsoftware\tapplication\tor\tchatbot.\tYou\tcan\talso\ttweak\t\nthe\tselect\tprompt\tand\tevaluate\tagain.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1253, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5a29c815-5e81-41b3-882d-f0961150f993": {"__data__": {"id_": "5a29c815-5e81-41b3-882d-f0961150f993", "embedding": null, "metadata": {"page_label": "42", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "453fdf1c-db20-4a2c-bf71-822e09417986", "node_type": "4", "metadata": {"page_label": "42", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "71aac01a3fac4d596cea5656dfdea06df513e284e03fddd09c39222379011c38", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n42\nCode prompting\nGemini focuses primarily on text-based prompts, which also includes writing prompts for \nreturning\tcode.\tLet\u2019s\tgo\tto\tthe\tVertex\tAI\tStudio\tand\ttest\tthese\tprompts\tto\tlook\tat\tsome\t\ncoding\texamples.\nPrompts for writing code\nGemini can also be a developer and help you with writing code in any programming language \nof\tchoice.\tAs\ta\tdeveloper\tthis\tcan\thelp\tyou\tspeed\tup\tthe\tprocess\tof\twriting\tcode.\nImagine\ta\tfolder\ton\tyour\tmachine\twith\thundreds\tof\tfiles\tthat\tneeds\tto\tbe\trenamed.\t\nRenaming\teach\tfile\twould\ttake\tyou\ta\tlot\tof\ttime.\tYou\tknow\ta\tlittle\tBash,\tand\tcould\twrite\t\na\tscript\tto\tautomate\tthis,\tbut\tthat\tmay\talso\ttake\tawhile.\tSo\tlet\u2019s\twrite\ta\tprompt.\tYou\tcan\t\nwrite the prompt in the public consumer chatbot Gemini, or if you are more concerned \nabout\tconfidentiality,\tyou\tcan\twrite\tthese\tprompts\twithin\tyour\tGoogle\tCloud\taccount\tand\t\nopen\tVertex\tAI\tStudio.\tThe\tadvantage\tof\tVertex\tAI\tStudio\tis\tthat\tyou\tcan\tconfigure\tthe\t\ntemperature\tetc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 989, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b25d1ac-d7b4-44f1-bb5b-d7477c5d4f84": {"__data__": {"id_": "6b25d1ac-d7b4-44f1-bb5b-d7477c5d4f84", "embedding": null, "metadata": {"page_label": "43", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "124fef4a-5350-4725-907a-d8d7b4ff6932", "node_type": "4", "metadata": {"page_label": "43", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "a8d81a388686c0064d744619518ddbf69f48f327d9cf41f85d11f43ca86e5851", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n43\nName 1_bash_rename_files_in_folder\nGoal Write\ta\tprompt\tto\twrite\tcode\tin\tBash\tto\trename\tfiles\tin\ta\tfolder.\nModel gemini-pro\nTemperature 0.1 Token Limit 1024\nTop-K N/A Top-P 1\nPrompt Write a code snippet in Bash, which asks for a folder name. \nThen it takes the contents of the folder and renames all the \nfiles inside by prepending the name draft to the file name.\nOutput ```bash\n#!/bin/bash\n# Ask for the folder name\necho \"Enter the folder name: \"\nread folder_name\n# Check if the folder exists\nif [ ! -d \"$folder_name\" ]; then\necho \"Folder does not exist.\"\nexit 1\nfi\n# Get the list of files in the folder\nfiles=( \"$folder_name\"/* )\n# Rename each file by prepending \"draft\" to the file name\nfor file in \"${files[@]}\"; do\nnew_file_name=\"draft_$(basename \"$file\")\"\nmv \"$file\" \"$new_file_name\"\ndone\necho \"Files renamed successfully.\"\n```\nTable 16. Using Gemini to program code\nThat\tseems\tlike\tgood\tcode\tto\tme\t-\tit\u2019s\teven\tdocumented!\tHowever,\tsince\tLLMs\tcan\u2019t\treason,\t\nand\trepeat\ttraining\tdata,\tit\u2019s\tessential\tto\tread\tand\ttest\tyour\tcode\tfirst.\t\nThe moment we are all waiting for, does it really work?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1132, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4e2b289-0531-4f3f-8d21-9ec4f0302343": {"__data__": {"id_": "b4e2b289-0531-4f3f-8d21-9ec4f0302343", "embedding": null, "metadata": {"page_label": "44", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4eb8754f-2aba-4ab0-9765-bb7277f949a4", "node_type": "4", "metadata": {"page_label": "44", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "101d0eec19959bfe5fe573aa7018db84775e52ed9037556da28f1adb99e5bf4b", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n44\nLet\u2019s\ttry\tit\tfirst\twith\ta\ttest\tfolder\twith\tonly\ta\tfew\tfiles\tin\tit,\twhich\twill\tneed\tto\tbe\trenamed\tfrom\t\nfilename.txt\tto\tdraft_filename.txt.\t\n1.\t Copy the output from Table 16 (without the ```bash ``` text wrapper), and paste it in a new \nfile\tcalled:\t\u201crename_files.sh\u201d.\t\n2.\tOpen\ta\tterminal\twindow\tand\ttype:\t. rename_files.sh.\tIt\twill\task\tto\tenter\ta\tfolder\tname,\te.g.\t\ntest.\tand\thit\tenter.\t\n3.\tThe\tscript\tseems\tto\trun\tfine.\tYou\twill\tsee\tthe\tmessage:\tFiles renamed successfully. \nWhen\tyou\tlook\tinto\tthe\ttest\tfolder,\tnotice\tthat\tall\tthe\tfiles\twere\tperfectly\trenamed\tto\t\ndraft_filename.txt. \nIt\tworked!\nPrompts for explaining code\nAs\ta\tdeveloper\twhen\tyou\twork\tin\tteams\tyou\thave\tto\tread\tsomeone\telse\u2019s\tcode.\tGemini\tcan\t\nhelp\tyou\twith\tthis\tas\twell.\tLet\u2019s\ttake\tthe\tcode\toutput\tfrom\tTable\t16,\tremove\tthe\tcomments\t\nand\task\tthe\tlarge\tlanguage\tmodel\tto\texplain\twhat\u2019s\thappening,\tSee\tTable\t17:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 917, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "62fe4755-42a9-45aa-b821-3b0b49f273b6": {"__data__": {"id_": "62fe4755-42a9-45aa-b821-3b0b49f273b6", "embedding": null, "metadata": {"page_label": "45", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f2313df1-79a0-40c5-9819-8c2f7003456f", "node_type": "4", "metadata": {"page_label": "45", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "ddc747c93c0cc65c1745352a98e6f8d75a97bac98be753f169438123441597bb", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n45\nName 1_bash_explain_the_code\nGoal Write a prompt to explain Bash code\nModel gemini-pro\nTemperature 0.1 Token Limit 1024\nTop-K N/A Top-P 1\nPrompt Explain to me the below Bash code:\n```\n#!/bin/bash\necho \"Enter the folder name: \"\nread folder_name\nif [ ! -d \"$folder_name\" ]; then\necho \"Folder does not exist.\"\nexit 1\nfi\nfiles=( \"$folder_name\"/* )\nfor file in \"${files[@]}\"; do\nnew_file_name=\"draft_$(basename \"$file\")\"\nmv \"$file\" \"$new_file_name\"\ndone\necho \"Files renamed successfully.\"\n```\nOutput This\tBash\tscript\tperforms\tthe\tfollowing\ttasks:\n1.\t **User\tInput**: \n- It prompts the user to enter a folder name using the `echo` and `read` \ncommands.\tThe\tentered\tfolder\tname\tis\tstored\tin\tthe\t`folder_name`\tvariable.\n2.\t **Folder\tExistence\tCheck**: \n-\tIt\tchecks\tif\tthe\tfolder\twith\tthe\tspecified\tname\texists\tusing\tthe\t`[\t!\t-d\t\n\u201c$folder_name\u201d\t]`\tcondition.\tIf\tthe\tfolder\tdoes\tnot\texist,\tit\tdisplays\tan\terror\t\nmessage\t(\u201cFolder\tdoes\tnot\texist.\u201d)\tand\texits\tthe\tscript\twith\tan\texit\tcode\tof\t1.\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1041, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad6f5758-4f48-4473-af7d-c0efde3e8559": {"__data__": {"id_": "ad6f5758-4f48-4473-af7d-c0efde3e8559", "embedding": null, "metadata": {"page_label": "46", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0a53e5ad-b647-446e-ad34-1deb0a7a6442", "node_type": "4", "metadata": {"page_label": "46", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "7c4f5c079ab0f94f68fd19b73a63ce65c0350f05245e8b463da3ace3ad14ab3e", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n46\nOutput 3.\t **File\tListing**: \n-\tIt\tlists\tall\tthe\tfiles\tinside\tthe\tspecified\tfolder\tusing\tthe\t`files=(\t\u201c$folder_\nname\u201d/*\t)`\tcommand.\tThis\tcreates\tan\tarray\tcalled\t`files`\tcontaining\tthe\tpaths\t\nto\tall\tthe\tfiles\tin\tthe\tfolder.\n4.\t **File\tRenaming**: \n-\tIt\titerates\tthrough\teach\tfile\tin\tthe\t`files`\tarray\tusing\ta\t`for`\tloop. \n-\tFor\teach\tfile,\tit\tgenerates\ta\tnew\tfile\tname\tusing\tthe\t`new_file_\nname=\u201ddraft_$(basename\t\u201c$file\u201d)\u201d\t`\tcommand.\tThis\tnew\tfile\tname\tis\tcreated\t\nby\tprefixing\tthe\toriginal\tfile\tname\twith\tthe\tstring\t\u201cdraft_\u201d. \n-\tIt\tthen\trenames\tthe\tfile\tusing\tthe\t`mv\t\u201c$file\u201d\t\u201c$new_file_name\u201d`\tcommand,\t\nwhich\tmoves\tthe\tfile\tto\tthe\tnew\tfile\tname.\n5.\t **Success\tMessage**: \n-\tAfter\trenaming\tall\tthe\tfiles,\tit\tdisplays\ta\tsuccess\tmessage\t(\u201cFiles\trenamed\t\nsuccessfully.\u201d)\tto\tindicate\tthat\tthe\trenaming\toperation\twas\tsuccessful\nTable 17. A prompt for explaining code\nPrompts for translating code\nThe\tbash\tcode\tfrom\tTable\t16\tseems\tto\twork\tfine.\tHowever\tthis\tscript\tcould\treally\tbe\treusable\t\nwhen\tit\twould\tprompt\tme\tfor\tfile\tnames,\tideally\tit\tshould\twork\tas\ta\tseparate\tapplication\twith\t\nan\tUI.\tAs\ta\tstarting\tpoint,\tPython\twould\tbe\ta\tbetter\tlanguage\tfor\ta\t(web)\tapplication\tthan\t\nBash.\tLLMs\tcan\thelp\twith\ttranslating\tcode\tfrom\tone\tlanguage\tto\tanother.\tSee\tthe\texample\tin\t\nTable\t18:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1309, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e1fbd916-e652-4308-b1b0-674be967ae34": {"__data__": {"id_": "e1fbd916-e652-4308-b1b0-674be967ae34", "embedding": null, "metadata": {"page_label": "47", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ba338796-570e-4ad8-a295-c8bf1d7d3c21", "node_type": "4", "metadata": {"page_label": "47", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "cc884a3c7b30df7a00c20d00ee59f2e50093578971061dfd01db916a64db894f", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n47\nName 1_python_rename_files\nGoal Write a prompt to translate Bash code to Python\nModel gemini-pro\nTemperature 0.1 Token Limit 1024\nTop-K N/A Top-P 1\nPrompt Translate the below Bash code to a Python snippet.\n```bash\n#!/bin/bash\necho \"Enter the folder name: \"\nread folder_name\nif [ ! -d \"$folder_name\" ]; then\necho \"Folder does not exist.\"\nexit 1\nfi\nfiles=( \"$folder_name\"/* )\nfor file in \"${files[@]}\"; do\nnew_file_name=\"draft_$(basename \"$file\")\"\nmv \"$file\" \"$new_file_name\"\ndone\necho \"Files renamed successfully.\"\n```\nOutput ```python\nimport os\nimport shutil\n# Get the folder name from the user\nfolder_name = input(\"Enter the folder name: \")\n# Check if the folder exists\nif not os.path.isdir(folder_name):\nprint(\"Folder does not exist.\")\n    exit(1)\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 809, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cd599e33-eb64-4538-a89b-62a95610cc0f": {"__data__": {"id_": "cd599e33-eb64-4538-a89b-62a95610cc0f", "embedding": null, "metadata": {"page_label": "48", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "949af885-3af7-4e96-8f8a-6ce50b9ff03c", "node_type": "4", "metadata": {"page_label": "48", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "5a383fa3e9a702870d60381e9df499f345a3864dbf0b94cd1b4a4b2544da84b6", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n48\nOutput # Get a list of all files in the folder\nfiles = os.listdir(folder_name)\n# Iterate over the files\nfor file in files:\n    # Create a new file name with the prefix \"draft_\"\n    new_file_name = f\"draft_{file}\"\n# Move the file to the new name\nshutil.move(os.path.join(folder_name, file), \nos.path.join(folder_name, new_file_name))\n# Print a success message\nprint(\"Files renamed successfully.\")\n```\nTable 18. A prompt for translating code from Bash to Python\nRead\tand\treview\tthe\tcode.\tCopy\tthe\toutput\tfrom\tthe\tprompt\tand\tpaste\tit\tinto\ta\tnew\tfile:\t\nfile_renamer.py.\tTest\tthe\tcode\tby\topening\ta\tTerminal\twindow,\tand\texecute\tthe\tfollowing\t\ncommand python file_renamer.py. \nNOTE:\tWhen\tprompting\tfor\t(Python)\tcode\tin\tthe\tLanguage\tStudio\tin\tVertex\tAI,\tyou\twill\thave\t\nto\tclick\ton\tthe\t\u2018Markdown\u2019\tbutton.\tOtherwise\tyou\twill\treceive\tplain\ttext\twhich\tis\tmissing\tthe\t\nproper\tindenting\tof\tlines,\twhich\tis\timportant\tfor\trunning\tPython\tcode.\nPrompts for debugging and reviewing code\nLet\u2019s\tmanually\twrite\tsome\tedits\tto\tthe\tcode\tof\tTable\t18.\tIt\tshould\tprompt\tthe\tuser\tfor\tthe\t\nfilename\tprefix,\tand\twrite\tthis\tprefix\tin\tupper\tcase\tcharacters.\tSee\tthe\texample\tcode\tin\t\nSnippet\t*3,\tbut\twhat\ta\tbummer.\tIt\tnow\treturns\tPython\terrors!", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1247, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b707e542-6dd8-4f6c-910c-d91f93b5d0a0": {"__data__": {"id_": "b707e542-6dd8-4f6c-910c-d91f93b5d0a0", "embedding": null, "metadata": {"page_label": "49", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "133c1fa9-d6d2-4a31-8a6c-bd35e63b0acf", "node_type": "4", "metadata": {"page_label": "49", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "1b6c7ca6df6dd759420aa56158a6a1e4fc8ce02e368696c37482aa54bbe8bdc7", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n49\nPython\nimport os\nimport shutil\nfolder_name = input(\"Enter the folder name: \")\nprefix = input(\"Enter the string to prepend to the filename: \")\ntext = toUpperCase(prefix)\nif not os.path.isdir(folder_name):\n    print(\"Folder does not exist.\")\n    exit(1)\nfiles = os.listdir(folder_name)\nfor file in files:\n    new_filename = f\"{text}_{file}\"\nshutil.move(os.path.join(folder_name, file), \nos.path.join(folder_name, new_file_name))\nprint(\"Files renamed successfully.\")\nSnippet 3. A broken Python script\nDoh!\tThat\tlooks\tlike\ta\tbug:\nUnset\nThe below Python code gives an error:\nTraceback (most recent call last):\n  File \u201c/Users/leeboonstra/Documents/test_folder/rename_files.py\u201d, line 7, \nin <module>\n    text = toUpperCase(prefix)\nNameError: name \u2018toUpperCase\u2019 is not defined\nSnippet 4. I broke the Python code", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 840, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "58cb32d4-a18c-433f-aea5-94464ecf3d1d": {"__data__": {"id_": "58cb32d4-a18c-433f-aea5-94464ecf3d1d", "embedding": null, "metadata": {"page_label": "50", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bbfbd202-71d6-4988-bcf6-454a96b8552a", "node_type": "4", "metadata": {"page_label": "50", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "d91a3a72510ac520665585340dac7ed3181f9a417bc239c5f37c8f9b5f21db27", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n50\nLet\u2019s\tsee\tif\twe\tcan\task\tthe\tlarge\tlanguage\tmodel\tto\tdebug\tand\treview\tcode.\tHave\ta\tlook\tinto\t\nTable\t19:\nName 1_python_debug_code\nGoal Write\ta\tprompt\tto\tdebug\tand\treview\tPython\tcode.\nModel gemini-pro\nTemperature 0.1 Token Limit 1024\nTop-K N/A Top-P 1\nPrompt The below Python code gives an error:\nTraceback (most recent call last):\n                                                   File \"/\nUsers/leeboonstra/Documents/test_folder/rename_files.py\", line \n7, in <module>\n    text = toUpperCase(prefix)\nNameError: name 'toUpperCase' is not defined\nDebug what's wrong and explain how I can improve the code.\n```python\nimport os\nimport shutil\n# Get the folder name from the user\nfolder_name = input(\"Enter the folder name: \")\nprefix = input(\"Enter the string to prepend to the filename: \")\ntext = toUpperCase(prefix)\n# Check if the folder exists\nif not os.path.isdir(folder_name):\n    print(\"Folder does not exist.\")\n    exit(1)\n# Get a list of all files in the folder\nfiles = os.listdir(folder_name)\n# Iterate over the files\nfor file in files:\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1097, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fb6f596b-8601-4b3b-8006-76a10f19424a": {"__data__": {"id_": "fb6f596b-8601-4b3b-8006-76a10f19424a", "embedding": null, "metadata": {"page_label": "51", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8e7a0086-b83f-478a-b717-b2835be58071", "node_type": "4", "metadata": {"page_label": "51", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "78ab9ac307b16aecc992a3f4a9e430fc418f64e8c27796f3020a52c89a2524cc", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n51\nPrompt # Create a new file name with the prefix \"draft_\"\n    new_filename = f\"{text}_{file}\"\n# Move the file to the new name\nshutil.move(os.path.join(folder_name, file), \nos.path.join(folder_name, new_file_name))\n# Print a success message\nprint(\"Files renamed successfully.\")\n```\nOutput The\tcode\tcalls\tthe\t`toUpperCase`\tfunction\tto\tconvert\t`prefix`\tto\tuppercase,\tbut\t\nthat\tfunction\tis\tnot\tdefined.\tTo\tfix\tthis\tissue,\tyou\tcan\tuse\tthe\t`upper()`\tmethod\tof\t\nthe\tstring\tclass\twhich\tconverts\ta\tgiven\tstring\tinto\tuppercase.\tThe\tmodified\tcode\t\nis\tshown\tbelow:\n```python\nimport os\nimport shutil\n# Get the folder name from the user\nfolder_name = input(\"Enter the folder name: \")\nprefix = input(\"Enter the string to prepend to the filename: \")\ntext = prefix.upper()\n# Check if the folder exists\nif not os.path.isdir(folder_name):\n    print(\"Folder does not exist.\")\n    exit(1)\n# Get a list of all files in the folder\nfiles = os.listdir(folder_name)\n# Iterate over the files\nfor file in files:\n    # Create a new file name with the prefix \"draft_\"\n    new_filename = f\"{text}_{file}\"\n# Move the file to the new name\nshutil.move(os.path.join(folder_name, file),\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1209, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b1001afd-20c5-440f-bb36-7ff94cb5339e": {"__data__": {"id_": "b1001afd-20c5-440f-bb36-7ff94cb5339e", "embedding": null, "metadata": {"page_label": "52", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "228fd0bd-68c2-40be-bba0-8187b36ac2d8", "node_type": "4", "metadata": {"page_label": "52", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "bcc456d3567c19acf0b9462d093c1509552ed2826e2dfa20856fa7f5eb4884af", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n52\nOutput os.path.join(folder_name, new_filename))\n# Print a success message\nprint(\"Files renamed successfully.\")\n```\nAdditionally,\tthere\tare\ta\tfew\tother\timprovements\tthat\tcan\tbe\tmade\tto\tthe\tcode:\n1.\t The\tfile\textension\tof\tthe\tnew\tfilenames\tis\tnot\tkept.\tIt\u2019s\tbetter\tto\textract\tthe\t\nextension\tfrom\tthe\toriginal\tfilename\tand\tappend\tit\tto\tthe\tnew\tfilename.\n2.\t The\tcode\tassumes\tthat\tthere\tare\tno\tspaces\tin\tthe\tfolder\tname.\tHowever,\t\nit is a good practice to handle spaces gracefully by replacing them with \nunderscores\tor\thyphens.\n3.\t Using the `f` string syntax for string interpolation is more readable and \nconcise\tthan\tthe\ttraditional\t`+`\toperator.\n4.\t The\tcode\tdoesn\u2019t\thandle\terrors\tthat\tmight\toccur\tduring\tthe\trenaming\tprocess.\t\nIt\twould\tbe\tbetter\tto\twrap\tthe\t`shutil.move`\tcall\tin\ta\t`try...except`\tblock\tto\t\ncatch\tany\tpotential\terrors.\nHere\tis\tthe\timproved\tcode\twith\tthese\tsuggestions:\n```python\nimport os\nimport shutil\n# Get the folder name from the user\nfolder_name = input(\"Enter the folder name: \")\nprefix = input(\"Enter the string to prepend to the filename: \")\n# Check if the folder exists\nif not os.path.isdir(folder_name):\n    print(\"Folder does not exist.\")\n    exit(1)\n# Get a list of all files in the folder\nfiles = os.listdir(folder_name)\n# Iterate over the files\nfor file in files:\nContinues next page...", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1355, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3dac615-d68b-40bd-880f-479c6a91367d": {"__data__": {"id_": "f3dac615-d68b-40bd-880f-479c6a91367d", "embedding": null, "metadata": {"page_label": "53", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "733c6af7-9920-4e06-9d17-bdae1ea700ef", "node_type": "4", "metadata": {"page_label": "53", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "4d52f8d7f95fe6fd77e98c22e3d93d71d092e134948ece119e53560751a9dcab", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n53\nOutput     # Get the file extension\n    ext = os.path.splitext(file)[1]\n# Create a new file name with the prefix and the file extension\n    new_filename = f\"{prefix}_{os.path.splitext(file)[0]}{ext}\"\n# Build the full paths for the original and new files\n    old_path = os.path.join(folder_name, file)\n    new_path = os.path.join(folder_name, new_filename)\n# Try to move the file\n    try:\n        shutil.move(old_path, new_path)\nexcept Exception as e:\n        print(f\"An error occurred while moving the file \n{file}: {e}\")\n# Print a success message\nprint(\"Files renamed successfully.\")\n```\nThese\timprovements\tmake\tthe\tcode\tmore\trobust\tand\tflexible\twhile\talso\tmaking\t\nit\teasier\tto\tread\tand\tunderstand...\t(The\tresponse\twas\ttruncated\tbecause\t\nit\thas\treached\tthe\ttoken\tlimit.\tTry\tto\tincrease\tthe\ttoken\tlimit\tif\tyou\tneed\ta\t\nlonger\tresponse.)\nTable 19. A prompt for debugging and reviewing Python code\nThat\u2019s\tgreat.\tNot\tonly\tdid\tit\ttell\tme\thow\tto\tsolve\tthe\tproblem,\tit\talso\tfigured\tout\tthat\tmy\tcode\t\nhad\tmore\tbugs\tand\thow\tto\tsolve\tthem,\ttoo.\tThe\tlast\tpart\tof\tthe\tprompt\tgave\tsuggestions\tto\t\nimprove\tthe\tcode\tin\tgeneral.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1149, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c2ae2556-d60d-4611-bade-a4f09ee4ec1a": {"__data__": {"id_": "c2ae2556-d60d-4611-bade-a4f09ee4ec1a", "embedding": null, "metadata": {"page_label": "54", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4226151-ccac-4430-92ec-d1353b10f961", "node_type": "4", "metadata": {"page_label": "54", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "f6642e0779ca584f3246c6ea4ffbf43676328848f7427b4b82e4a2d472172e41", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n54\nWhat about multimodal prompting?\nPrompting\tfor\tcode\tstill\tuses\tthe\tsame\tregular\tlarge\tlanguage\tmodel.\tMultimodal\tprompting\t\nis\ta\tseparate\tconcern,\tit\trefers\tto\ta\ttechnique\twhere\tyou\tuse\tmultiple\tinput\tformats\tto\tguide\t\na\tlarge\tlanguage\tmodel,\tinstead\tof\tjust\trelying\ton\ttext.\tThis\tcan\tinclude\tcombinations\tof\ttext,\t\nimages,\taudio,\tcode,\tor\teven\tother\tformats,\tdepending\ton\tthe\tmodel\u2019s\tcapabilities\tand\tthe\t\ntask\tat\thand.\t\nBest Practices\nFinding\tthe\tright\tprompt\trequires\ttinkering.\tLanguage\tStudio\tin\tVertex\tAI\tis\ta\tperfect\tplace\tto\t\nplay\taround\twith\tyour\tprompts,\twith\tthe\tability\tto\ttest\tagainst\tthe\tvarious\tmodels.\nUse\tthe\tfollowing\tbest\tpractices\tto\tbecome\ta\tpro\tin\tprompt\tengineering.\nProvide examples\nThe\tmost\timportant\tbest\tpractice\tis\tto\tprovide\t(one\tshot\t/\tfew\tshot)\texamples\twithin\ta\t\nprompt.\tThis\tis\thighly\teffective\tbecause\tit\tacts\tas\ta\tpowerful\tteaching\ttool.\tThese\texamples\t\nshowcase desired outputs or similar responses, allowing the model to learn from them \nand\ttailor\tits\town\tgeneration\taccordingly.\tIt\u2019s\tlike\tgiving\tthe\tmodel\ta\treference\tpoint\tor\t\ntarget\tto\taim\tfor,\timproving\tthe\taccuracy,\tstyle,\tand\ttone\tof\tits\tresponse\tto\tbetter\tmatch\t\nyour\texpectations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1214, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "18c26386-daf8-4470-b964-c879a4afb034": {"__data__": {"id_": "18c26386-daf8-4470-b964-c879a4afb034", "embedding": null, "metadata": {"page_label": "55", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "687a0f25-daf1-4a99-95da-bb9cefab34ee", "node_type": "4", "metadata": {"page_label": "55", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e90d91c385b3d74a3b23b06e5cd66f635d585029cddd75ea1301ec53d1ab89ac", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n55\nDesign with simplicity\nPrompts\tshould\tbe\tconcise,\tclear,\tand\teasy\tto\tunderstand\tfor\tboth\tyou\tand\tthe\tmodel.\tAs\ta\t\nrule\tof\tthumb,\tif\tit\u2019s\talready\tconfusing\tfor\tyou\tit\twill\tlikely\tbe\talso\tconfusing\tfor\tthe\tmodel.\tTry\t\nnot\tto\tuse\tcomplex\tlanguage\tand\tdon\u2019t\tprovide\tunnecessary\tinformation.\t\nExamples:\nBEFORE:\nI am visiting New York right now, and I'd like to hear more about great \nlocations. I am with two 3 year old kids. Where should we go during \nour vacation?\nAFTER\tREWRITE:\nAct as a travel guide for tourists. Describe great places to visit in \nNew York Manhattan with a 3 year old.\nTry\tusing\tverbs\tthat\tdescribe\tthe\taction.\tHere\u2019s\ta\tset\tof\texamples:\nAct, Analyze, Categorize, Classify, Contrast, Compare, Create, Describe, Define, \nEvaluate, Extract, Find, Generate, Identify, List, Measure, Organize, Parse, Pick, \nPredict, Provide, Rank, Recommend, Return, Retrieve, Rewrite, Select, Show, Sort, \nSummarize, Translate, Write.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 968, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "887c4a6f-d76d-49db-a234-c0877a87bfd8": {"__data__": {"id_": "887c4a6f-d76d-49db-a234-c0877a87bfd8", "embedding": null, "metadata": {"page_label": "56", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec92cdee-f64f-4881-baac-03c7f83a856b", "node_type": "4", "metadata": {"page_label": "56", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "463d7bf8b0091f1840979a3b134bdbce4e5cb371777eb32c5172fde979cce5ab", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n56\nBe specific about the output\nBe\tspecific\tabout\tthe\tdesired\toutput.\tA\tconcise\tinstruction\tmight\tnot\tguide\tthe\tLLM\tenough\t\nor\tcould\tbe\ttoo\tgeneric.\tProviding\tspecific\tdetails\tin\tthe\tprompt\t(through\tsystem\tor\tcontext\t\nprompting)\tcan\thelp\tthe\tmodel\tto\tfocus\ton\twhat\u2019s\trelevant,\timproving\tthe\toverall\taccuracy.\nExamples:\nDO:\t\nGenerate a 3 paragraph blog post about the top 5 video game consoles. \nThe blog post should be informative and engaging, and it should be \nwritten in a conversational style.\nDO\tNOT:\t\nGenerate a blog post about video game consoles.\nUse Instructions over Constraints\nInstructions\tand\tconstraints\tare\tused\tin\tprompting\tto\tguide\tthe\toutput\tof\ta\tLLM.\t\n\u2022 An instruction provides explicit instructions on the desired format, style, or content of the \nresponse.\tIt\tguides\tthe\tmodel\ton\twhat\tthe\tmodel\tshould\tdo\tor\tproduce.\n\u2022 A constraint\tis\ta\tset\tof\tlimitations\tor\tboundaries\ton\tthe\tresponse.\tIt\tlimits\twhat\tthe\tmodel\t\nshould\tnot\tdo\tor\tavoid.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 991, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bccd66e7-31be-4e29-9730-028d07dfe988": {"__data__": {"id_": "bccd66e7-31be-4e29-9730-028d07dfe988", "embedding": null, "metadata": {"page_label": "57", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3d85146d-db46-4b7b-9502-29fad17afd22", "node_type": "4", "metadata": {"page_label": "57", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "72052baf0c2df557443f789a370e5c866ae3f8dce147d78742aa902e810a4036", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n57\nGrowing research suggests that focusing on positive instructions in prompting can be more \neffective\tthan\trelying\theavily\ton\tconstraints.\tThis\tapproach\taligns\twith\thow\thumans\tprefer\t\npositive\tinstructions\tover\tlists\tof\twhat\tnot\tto\tdo.\t\nInstructions directly communicate the desired outcome, whereas constraints might leave the \nmodel\tguessing\tabout\twhat\tis\tallowed.\tIt\tgives\tflexibility\tand\tencourages\tcreativity\twithin\tthe\t\ndefined\tboundaries,\twhile\tconstraints\tcan\tlimit\tthe\tmodel\u2019s\tpotential.\tAlso\ta\tlist\tof\tconstraints\t\ncan\tclash\twith\teach\tother.\nConstraints\tare\tstill\tvaluable\tbut\tin\tcertain\tsituations.\tTo\tprevent\tthe\tmodel\tfrom\tgenerating\t\nharmful\tor\tbiased\tcontent\tor\twhen\ta\tstrict\toutput\tformat\tor\tstyle\tis\tneeded.\nIf\tpossible,\tuse\tpositive\tinstructions:\tinstead\tof\ttelling\tthe\tmodel\twhat\tnot\tto\tdo,\ttell\tit\twhat\tto\t\ndo\tinstead.\tThis\tcan\tavoid\tconfusion\tand\timprove\tthe\taccuracy\tof\tthe\toutput.\t\nDO:\t\nGenerate a 1 paragraph blog post about the top 5 video game consoles. \nOnly discuss the console, the company who made it, the year, and total \nsales. \nDO\tNOT:\t\nGenerate a 1 paragraph blog post about the top 5 video game consoles. \nDo not list video game names.\nAs\ta\tbest\tpractice,\tstart\tby\tprioritizing\tinstructions,\tclearly\tstating\twhat\tyou\twant\tthe\tmodel\t\nto\tdo\tand\tonly\tuse\tconstraints\twhen\tnecessary\tfor\tsafety,\tclarity\tor\tspecific\trequirements.\t\nExperiment\tand\titerate\tto\ttest\tdifferent\tcombinations\tof\tinstructions\tand\tconstraints\tto\tfind\t\nwhat\tworks\tbest\tfor\tyour\tspecific\ttasks,\tand\tdocument\tthese.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1552, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e874627c-855e-42d7-af75-8bf33146e88e": {"__data__": {"id_": "e874627c-855e-42d7-af75-8bf33146e88e", "embedding": null, "metadata": {"page_label": "58", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "795d23c5-75e9-43e8-88cb-bceeae772581", "node_type": "4", "metadata": {"page_label": "58", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b6feda3fb258ecbea533978ebb6e7fe858344f7a0ae6a2b4527270502d2336b5", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n58\nControl the max token length\nTo control the length of a generated LLM response, you can either set a max token limit in the \nconfiguration\tor\texplicitly\trequest\ta\tspecific\tlength\tin\tyour\tprompt.\tFor\texample:\n\"Explain quantum physics in a tweet length message.\"\nUse variables in prompts\nTo reuse prompts and make it more dynamic use variables in the prompt, which can be \nchanged\tfor\tdifferent\tinputs.\tE.g.\tas\tshown\tin\tTable\t20,\ta\tprompt\twhich\tgives\tfacts\tabout\ta\t\ncity.\tInstead\tof\thardcoding\tthe\tcity\tname\tin\tthe\tprompt,\tuse\ta\tvariable.\tVariables\tcan\tsave\t\nyou\ttime\tand\teffort\tby\tallowing\tyou\tto\tavoid\trepeating\tyourself.\tIf\tyou\tneed\tto\tuse\tthe\tsame\t\npiece of information in multiple prompts, you can store it in a variable and then reference \nthat\tvariable\tin\teach\tprompt.\tThis\tmakes\ta\tlot\tof\tsense\twhen\tintegrating\tprompts\tinto\tyour\t\nown\tapplications.\nPrompt VARIABLES\n{city} = \"Amsterdam\"\nPROMPT\nYou are a travel guide. Tell me a fact about the city: {city}\nOutput Amsterdam\tis\ta\tbeautiful\tcity\tfull\tof\tcanals,\tbridges,\tand\tnarrow\tstreets.\tIt\u2019s\ta\t\ngreat\tplace\tto\tvisit\tfor\tits\trich\thistory,\tculture,\tand\tnightlife.\nTable 20. Using variables in prompts", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1191, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e1394980-daac-4429-8188-a37c0bbb2651": {"__data__": {"id_": "e1394980-daac-4429-8188-a37c0bbb2651", "embedding": null, "metadata": {"page_label": "59", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a6f5d9be-66b8-45e1-9e7a-e2ffcc32b444", "node_type": "4", "metadata": {"page_label": "59", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "82e00e52dad26643ed5a900dab340a9213ce44df25c95a16635b6c5246969b83", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n59\nExperiment with input formats and writing styles\nDifferent\tmodels,\tmodel\tconfigurations,\tprompt\tformats,\tword\tchoices,\tand\tsubmits\tcan\tyield\t\ndifferent\tresults.\tTherefore,\tit\u2019s\timportant\tto\texperiment\twith\tprompt\tattributes\tlike\tthe\tstyle,\t\nthe\tword\tchoice,\tand\tthe\ttype\tprompt\t(zero\tshot,\tfew\tshot,\tsystem\tprompt).\nFor example a prompt with the goal to generate text about the revolutionary video game \nconsole Sega Dreamcast, can be formulated as a question, a statement or an instruction, \nresulting\tin\tdifferent\toutputs:\n\u2022 Question: What was the Sega Dreamcast and why was it such a revolutionary console?\n\u2022 Statement: The Sega Dreamcast was a sixth-generation video game console released by \nSega\tin\t1999.\tIt...\n\u2022 Instruction: Write a single paragraph that describes the Sega Dreamcast console and \nexplains\twhy\tit\twas\tso\trevolutionary.\nFor few-shot prompting with classification tasks, mix up \nthe classes\nGenerally\tspeaking,\tthe\torder\tof\tyour\tfew-shots\texamples\tshould\tnot\tmatter\tmuch.\tHowever,\t\nwhen\tdoing\tclassification\ttasks,\tmake\tsure\tyou\tmix\tup\tthe\tpossible\tresponse\tclasses\tin\tthe\t\nfew\tshot\texamples.\tThis\tis\tbecause\tyou\tmight\totherwise\tbe\toverfitting\tto\tthe\tspecific\torder\tof\t\nthe\texamples.\tBy\tmixing\tup\tthe\tpossible\tresponse\tclasses,\tyou\tcan\tensure\tthat\tthe\tmodel\tis\t\nlearning to identify the key features of each class, rather than simply memorizing the order of \nthe\texamples.\tThis\twill\tlead\tto\tmore\trobust\tand\tgeneralizable\tperformance\ton\tunseen\tdata.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1506, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "48cc582d-b4e1-4b18-a9ea-811789602309": {"__data__": {"id_": "48cc582d-b4e1-4b18-a9ea-811789602309", "embedding": null, "metadata": {"page_label": "60", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "50f1a77d-2e40-41d9-8ca7-a8e97bd07d99", "node_type": "4", "metadata": {"page_label": "60", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "613d0f8ec60d78af8af2eeaff043911b1e5e7e6f7c8516ac7378cf6d6dff6e07", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n60\nA\tgood\trule\tof\tthumb\tis\tto\tstart\twith\t6\tfew\tshot\texamples\tand\tstart\ttesting\tthe\taccuracy\t\nfrom\tthere.\nAdapt to model updates\nIt\u2019s\timportant\tfor\tyou\tto\tstay\ton\ttop\tof\tmodel\tarchitecture\tchanges,\tadded\tdata,\tand\t\ncapabilities.\tTry\tout\tnewer\tmodel\tversions\tand\tadjust\tyour\tprompts\tto\tbetter\tleverage\tnew\t\nmodel\tfeatures.\tTools\tlike\tVertex\tAI\tStudio\tare\tgreat\tto\tstore,\ttest,\tand\tdocument\tthe\tvarious\t\nversions\tof\tyour\tprompt.\nExperiment with output formats\nBesides\tthe\tprompt\tinput\tformat,\tconsider\texperimenting\twith\tthe\toutput\tformat.\tFor\tnon-\ncreative tasks like extracting, selecting, parsing, ordering, ranking, or categorizing data try \nhaving\tyour\toutput\treturned\tin\ta\tstructured\tformat\tlike\tJSON\tor\tXML.\t\nThere\tare\tsome\tbenefits\tin\treturning\tJSON\tobjects\tfrom\ta\tprompt\tthat\textracts\tdata.\tIn\t\na\treal-world\tapplication\tI\tdon\u2019t\tneed\tto\tmanually\tcreate\tthis\tJSON\tformat,\tI\tcan\talready\t\nreturn\tthe\tdata\tin\ta\tsorted\torder\t(very\thandy\twhen\tworking\twith\tdatetime\tobjects),\tbut\tmost\t\nimportantly,\tby\tprompting\tfor\ta\tJSON\tformat\tit\tforces\tthe\tmodel\tto\tcreate\ta\tstructure\tand\t\nlimit\thallucinations.\nTable 4 in the few-shot prompting section shows an example on how to return \nstructured\toutput.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1226, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a2e2e9a-4ac1-4fe3-9bba-b9e0a0e1aaac": {"__data__": {"id_": "1a2e2e9a-4ac1-4fe3-9bba-b9e0a0e1aaac", "embedding": null, "metadata": {"page_label": "61", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a6a3de2d-4e6a-4453-9a55-0168b24bd5a5", "node_type": "4", "metadata": {"page_label": "61", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "20b489b1a5b5fa79bf3c11688b50aa4ee28f6799b343816e6b7628e18e644965", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n61\nExperiment together with other prompt engineers\nIf you are in a situation where you have to try to come up with a good prompt, you might \nwant\tto\tfind\tmultiple\tpeople\tto\tmake\tan\tattempt.\tWhen\teveryone\tfollows\tthe\tbest\tpractices\t\n(as\tlisted\tin\tthis\tchapter)\tyou\tare\tgoing\tto\tsee\ta\tvariance\tin\tperformance\tbetween\tall\tthe\t\ndifferent\tprompt\tattempts.\nCoT Best practices\nFor\tCoT\tprompting,\tputting\tthe\tanswer\tafter\tthe\treasoning\tis\trequired\tbecause\tthe\t\ngeneration of the reasoning changes the tokens that the model gets when it predicts the \nfinal\tanswer.\nWith\tCoT\tand\tself-consistency\tyou\tneed\tto\tbe\table\tto\textract\tthe\tfinal\tanswer\tfrom\tyour\t\nprompt,\tseparated\tfrom\tthe\treasoning.\t\nFor\tCoT\tprompting,\tset\tthe\ttemperature\tto\t0.\nChain of thought prompting is based on greedy decoding, predicting the next word in a \nsequence\tbased\ton\tthe\thighest\tprobability\tassigned\tby\tthe\tlanguage\tmodel.\tGenerally\t\nspeaking,\twhen\tusing\treasoning,\tto\tcome\tup\twith\tthe\tfinal\tanswer,\tthere\u2019s\tlikely\tone\tsingle\t\ncorrect\tanswer.\tTherefore\tthe\ttemperature\tshould\talways\tset\tto\t0.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1093, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "521524fd-282d-4c20-ba6f-6a8ba8aca209": {"__data__": {"id_": "521524fd-282d-4c20-ba6f-6a8ba8aca209", "embedding": null, "metadata": {"page_label": "62", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8f1f6ad8-8a20-4841-9509-a71bce32c69b", "node_type": "4", "metadata": {"page_label": "62", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "b4dcfb2e2a4c26371d93df4d657a665f91fa80d712c08e1654aeb80c2c36f504", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n62\nDocument the various prompt attempts\nThe\tlast\ttip\twas\tmentioned\tbefore\tin\tthis\tchapter,\tbut\twe\tcan\u2019t\tstress\tenough\thow\timportant\t\nit\tis:\tdocument\tyour\tprompt\tattempts\tin\tfull\tdetail\tso\tyou\tcan\tlearn\tover\ttime\twhat\twent\twell\t\nand\twhat\tdid\tnot.\t\nPrompt\toutputs\tcan\tdiffer\tacross\tmodels,\tacross\tsampling\tsettings,\tand\teven\tacross\tdifferent\t\nversions\tof\tthe\tsame\tmodel.\tMoreover,\teven\tacross\tidentical\tprompts\tto\tthe\tsame\tmodel,\t\nsmall\tdifferences\tin\toutput\tsentence\tformatting\tand\tword\tchoice\tcan\toccur.\t(For\texample,\tas\t\nmentioned previously, if two tokens have the same predicted probability, ties may be broken \nrandomly.\tThis\tcan\tthen\timpact\tsubsequent\tpredicted\ttokens.).\nWe\trecommend\tcreating\ta\tGoogle\tSheet\twith\tTable\t21\tas\ta\ttemplate.\tThe\tadvantages\tof\t\nthis approach are that you have a complete record when you inevitably have to revisit your \nprompting\twork\u2013either\tto\tpick\tit\tup\tin\tthe\tfuture\t(you\u2019d\tbe\tsurprised\thow\tmuch\tyou\tcan\t\nforget\tafter\tjust\ta\tshort\tbreak),\tto\ttest\tprompt\tperformance\ton\tdifferent\tversions\tof\ta\tmodel,\t\nand\tto\thelp\tdebug\tfuture\terrors.\nBeyond\tthe\tfields\tin\tthis\ttable,\tit\u2019s\talso\thelpful\tto\ttrack\tthe\tversion\tof\tthe\tprompt\t(iteration),\t\na\tfield\tto\tcapture\tif\tthe\tresult\twas\tOK/NOT\tOK/SOMETIMES\tOK,\tand\ta\tfield\tto\tcapture\t\nfeedback.\tIf\tyou\u2019re\tlucky\tenough\tto\tbe\tusing\tVertex\tAI\tStudio,\tsave\tyour\tprompts\t(using\tthe\t\nsame name and version as listed in your documentation) and track the hyperlink to the saved \nprompt\tin\tthe\ttable.\tThis\tway,\tyou\u2019re\talways\tone\tclick\taway\tfrom\tre-running\tyour\tprompts.\nWhen working on a retrieval augmented generation system, you should also capture the \nspecific\taspects\tof\tthe\tRAG\tsystem\tthat\timpact\twhat\tcontent\twas\tinserted\tinto\tthe\tprompt,\t\nincluding\tthe\tquery,\tchunk\tsettings,\tchunk\toutput,\tand\tother\tinformation.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1816, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "acfba396-1b31-46b0-9c1a-7e194b122d6a": {"__data__": {"id_": "acfba396-1b31-46b0-9c1a-7e194b122d6a", "embedding": null, "metadata": {"page_label": "63", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1d1fe977-cf56-4c87-a133-7aa37b9b634f", "node_type": "4", "metadata": {"page_label": "63", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "87563f1aafeeab034f70221ea9b7f75fefc360f365f75618a849b9da4ce2086d", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n63\nOnce\tyou\tfeel\tthe\tprompt\tis\tclose\tto\tperfect,\ttake\tit\tto\tyour\tproject\tcodebase.\tAnd\tin\tthe\t\ncodebase,\tsave\tprompts\tin\ta\tseparate\tfile\tfrom\tcode,\tso\tit\u2019s\teasier\tto\tmaintain.\tFinally,\tideally\t\nyour\tprompts\tare\tpart\tof\tan\toperationalized\tsystem,\tand\tas\ta\tprompt\tengineer\tyou\tshould\t\nrely on automated tests and evaluation procedures to understand how well your prompt \ngeneralizes\tto\ta\ttask.\nPrompt\tengineering\tis\tan\titerative\tprocess.\tCraft\tand\ttest\tdifferent\tprompts,\tanalyze,\t\nand\tdocument\tthe\tresults.\tRefine\tyour\tprompt\tbased\ton\tthe\tmodel\u2019s\tperformance.\tKeep\t\nexperimenting\tuntil\tyou\tachieve\tthe\tdesired\toutput.\tWhen\tyou\tchange\ta\tmodel\tor\tmodel\t\nconfiguration,\tgo\tback\tand\tkeep\texperimenting\twith\tthe\tpreviously\tused\tprompts.\nName [name and version of your prompt]\nGoal [One\tsentence\texplanation\tof\tthe\tgoal\tof\tthis\tattempt]\nModel [name and version of the used model]\nTemperature [value between 0 - 1] Token Limit [number]\nTop-K [number] Top-P [number]\nPrompt [Write all the full prompt]\nOutput [Write out the output or multiple outputs]\nTable 21. A template for documenting prompts\nSummary\nThis\twhitepaper\tdiscusses\tprompt\tengineering.\tWe\tlearned\tvarious\tprompting\ttechniques,\t\nsuch\tas:\n\u2022 Zero prompting\n\u2022 Few shot prompting", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1264, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "402e400b-bdd5-4d53-9ab7-66faced28f78": {"__data__": {"id_": "402e400b-bdd5-4d53-9ab7-66faced28f78", "embedding": null, "metadata": {"page_label": "64", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c882a693-aed9-4ef3-b57d-2fc07270bb57", "node_type": "4", "metadata": {"page_label": "64", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "f05c9b765a8a278f187b629176d2889f9aabbb2c7961395515eced801cfae689", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n64\n\u2022 System prompting\n\u2022 Role prompting\n\u2022 Contextual prompting\n\u2022 Step-back prompting\n\u2022 Chain of thought\n\u2022 Self consistency\n\u2022 Tree of thoughts\n\u2022 ReAct\nWe\teven\tlooked\tinto\tways\thow\tyou\tcan\tautomate\tyour\tprompts.\t\nThe whitepaper then discusses the challenges of gen AI like the problems that can happen \nwhen\tyour\tprompts\tare\tinsufficient.\tWe\tclosed\twith\tbest\tpractices\ton\thow\tto\tbecome\ta\tbetter\t\nprompt\tengineer.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 443, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "895f7caa-7ba5-47db-8ddf-88da25ce1d10": {"__data__": {"id_": "895f7caa-7ba5-47db-8ddf-88da25ce1d10", "embedding": null, "metadata": {"page_label": "65", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f84a97ca-9388-490e-9c4e-ef6046b8231f", "node_type": "4", "metadata": {"page_label": "65", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "e7bc34399879f95a32e09572637387c114224050ef4897c774be29d57a5b6b95", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Engineering\nSeptember 2024\n65\nEndnotes\n1.\t Google,\t2023,\tGemini\tby\tGoogle.\tAvailable\tat:\thttps://gemini.google.com .\n2.\t Google,\t2024,\tGemini\tfor\tGoogle\tWorkspace\tPrompt\tGuide.\tAvailable\tat:\t \nhttps://inthecloud.withgoogle.com/gemini-for-google-workspace-prompt-guide/dl-cd.html .\n3.\t Google\tCloud,\t2023,\tIntroduction\tto\tPrompting.\tAvailable\tat:\t \nhttps://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design .\n4.\t Google\tCloud,\t2023,\tText\tModel\tRequest\tBody:\tTop-P\t&\ttop-K\tsampling\tmethods.\tAvailable\tat:\t \nhttps://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text#request_body .\n5.\t Wei,\tJ.,\tet\tal.,\t2023,\tZero\tShot\t-\tFine\tTuned\tlanguage\tmodels\tare\tzero\tshot\tlearners.\tAvailable\tat:\t \nhttps://arxiv.org/pdf/2109.01652.pdf .\n6.\t Google\tCloud,\t2023,\tGoogle\tCloud\tModel\tGarden.\tAvailable\tat:\thttps://cloud.google.com/model-garden .\n7.\t Brown,\tT.,\tet\tal.,\t2023,\tFew\tShot\t-\tLanguage\tModels\tare\tFew\tShot\tlearners.\tAvailable\tat:\t \nhttps://arxiv.org/pdf/2005.14165.pdf.\n8.\t Zheng,\tL.,\tet\tal.,\t2023,\tTake\ta\tStep\tBack:\tEvoking\tReasoning\tvia\tAbstraction\tin\tLarge\tLanguage\tModels.\t\nAvailable\tat:\thttps://openreview.net/pdf?id=3bq3jsvcQ1\n9.\t Wei,\tJ.,\tet\tal.,\t2023,\tChain\tof\tThought\tPrompting.\tAvailable\tat:\thttps://arxiv.org/pdf/2201.11903.pdf.\n10.\tGoogle\tCloud\tPlatform,\t2023,\tChain\tof\tThought\tand\tReact.\tAvailable\tat:\thttps://github.com/ \nGoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/chain_of_thought_react.ipynb .\t\n11.\t Wang,\tX.,\tet\tal.,\t2023,\tSelf\tConsistency\tImproves\tChain\tof\tThought\treasoning\tin\tlanguage\tmodels.\t \nAvailable\tat:\thttps://arxiv.org/pdf/2203.11171.pdf .\n12.\t Yao,\tS.,\tet\tal.,\t2023,\tTree\tof\tThoughts:\tDeliberate\tProblem\tSolving\twith\tLarge\tLanguage\tModels.\t \nAvailable\tat:\thttps://arxiv.org/pdf/2305.10601.pdf .\n13.\tYao,\tS.,\tet\tal.,\t2023,\tReAct:\tSynergizing\tReasoning\tand\tActing\tin\tLanguage\tModels.\tAvailable\tat:\t \nhttps://arxiv.org/pdf/2210.03629.pdf.\n14.\tGoogle\tCloud\tPlatform,\t2023,\tAdvance\tPrompting:\tChain\tof\tThought\tand\tReact.\tAvailable\tat: \nhttps://github.com/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/genai-  \non-vertex-ai/advanced_prompting_training/cot_react.ipynb .\n15.\tZhou,\tC.,\tet\tal.,\t2023,\tAutomatic\tPrompt\tEngineering\t-\tLarge\tLanguage\tModels\tare\tHuman-Level\tPrompt\t\nEngineers.\tAvailable\tat:\thttps://arxiv.org/pdf/2211.01910.pdf .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2355, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "58a41b1f-3320-4d20-9988-d849ea4208f3": {"__data__": {"id_": "58a41b1f-3320-4d20-9988-d849ea4208f3", "embedding": null, "metadata": {"page_label": "1", "file_name": "Profile.pdf", "file_path": "data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c5014c6b-ec97-492d-b74c-fd25db85d719", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Profile.pdf", "file_path": "data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}, "hash": "23e286bc8a5e45c129dfa6c2d7b48f055baaa25fd4e844b17a3bd9dd5b073c4e", "class_name": "RelatedNodeInfo"}}, "text": "Contact\n2330 N Oliver Ave, Wichita, KS\n67220\n+1 3165597502 (Mobile)\nchitrakumarsai@gmail.com\nwww.linkedin.com/in/\nchitrakumarsai (LinkedIn)\nTop Skills\nAmazon Web Services (AWS)\nData Analysis\nStatistics\nLanguages\nHindi (Native or Bilingual)\nEnglish (Native or Bilingual)\nTelugu (Native or Bilingual)\nCertifications\nMicrosoft Certified Azure\nAdministrator Associate\nNeo4j Fundamentals\nMicrosoft Certified: Azure Data\nEngineer Associate.\nChitra Kumar Sai Chenuri\nVenkata\nData Scientist\nWichita, Kansas, United States\nSummary\nChitra Kumar Sai has graduated from Wichita State University, with\na degree emphasis in Computer Science. He is working as a Data\nScientist at Koch Industries (INVISTA).\nHe is an individual with 4 years of experience in Data Science,\nEngineering and Analytics in Manufacturing, Technology, Consulting,\nRetail and Supply Chain industries. He is well versed with tools\nand techniques essential for ETL, optimization, Machine Learning\nand Deep Learning along with an ability to tie the data together to\nexecute streamline operations effectively. \nDuring his professional career, he designed high performance\nETL, Machine Learning and Computer Vision solutions using\nexisting technique and packages, also enabled the real time\nsolutions focusing on performance and accuracy. He ensured\nstakeholders\u2019 success and aligned the team with his project goals\nby maintaining communication through quarterly presentations and\nquality visualizations using BI tools to help executives, reporters/\nanalysts. He also developed solutions by identifying underperforming\nproducts with the help of customer feedback eventually boosting the\nsales performance while ensuring customers satisfaction.  \nHe has positively impacted the customer experience by leveraging\nthe data/information from various sources and developed automated\nscripts to maintain a constant flow of data focusing on its accuracy\n& reliability. He worked in building a strong team that is focused on\nresolving manual tasks consuming large amount of man hours using\nautomation techniques through tools like Alteryx, Python, R, AWS\nand Azure. \nHe is passionate about exploring data science projects in\nTechnology, Manufacturing, Consulting, Software, Marketing &\n\u00a0 Page 1 of 3", "mimetype": "text/plain", "start_char_idx": 4, "end_char_idx": 2248, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"3213ff5c-8c24-4f2d-a974-af52bc835c43": {"node_ids": ["01c05495-adfd-4316-b2ce-21e05a24f70b"], "metadata": {"page_label": "1", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "b700f50c-1139-45c9-8927-43c5dc436c2c": {"node_ids": ["8aeafac7-9e2c-464a-b214-9ba2ae36fd80"], "metadata": {"page_label": "2", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "5f87f6aa-d840-4b07-94cb-b6450e13782f": {"node_ids": ["1ebe3d61-3d0b-4cc1-94ea-993080934e8a"], "metadata": {"page_label": "3", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "142f0ade-146a-4229-a099-b6a9f0adc1bc": {"node_ids": ["b59825bd-b723-41e7-8537-7781a9e15391"], "metadata": {"page_label": "4", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "03607783-5262-489c-a800-9624e7bfa7d4": {"node_ids": ["1fa93bab-ff3d-4a36-a4e7-9675a2d0aefb"], "metadata": {"page_label": "5", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ba3d7135-07f0-40b4-bb99-52fbc3688d3b": {"node_ids": ["5c66ea5a-c497-4946-b957-5aed34ab4531"], "metadata": {"page_label": "6", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "908a4100-2a8c-49e2-bb19-04716070d338": {"node_ids": ["b989c3da-91f1-47a6-97cd-3d4a75903f75"], "metadata": {"page_label": "7", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "74eb1c3d-ca2f-403f-9165-ba146f98147a": {"node_ids": ["c49e5693-d851-4cb3-8d57-bd85dec7f0a2"], "metadata": {"page_label": "8", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "0afe5736-70b7-40e4-ae41-8c8d549d826c": {"node_ids": ["73439f44-5cc3-4938-bca5-f226ef367283"], "metadata": {"page_label": "9", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "d73def69-ba4d-4e9e-b401-b11be4b82416": {"node_ids": ["664e8cbe-9ef3-4309-86ad-6935567a1b60"], "metadata": {"page_label": "10", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "255b6a1f-6214-44d0-b8c3-143a79e6d69f": {"node_ids": ["ae4b564a-d66f-44db-b04c-a328009cd3d5"], "metadata": {"page_label": "11", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3f202208-b3c5-4af0-a1f6-9de0c4eca794": {"node_ids": ["0fa1efec-9424-4847-ad18-ad8fa899aa29"], "metadata": {"page_label": "12", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "516c00dc-8f35-43fd-a713-a4062b3e69d4": {"node_ids": ["03e97897-da03-48a4-8794-a80f3bacb5a1"], "metadata": {"page_label": "13", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "b015510a-98a0-44ad-a087-2dec8ab133b3": {"node_ids": ["08e0947b-5fcb-4ab5-ae52-d302872f43ec"], "metadata": {"page_label": "14", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ac659523-7346-40d2-9bd0-b1f1af71134e": {"node_ids": ["f6eb5175-cfc3-458a-a5a2-e2e2a50b4cb8"], "metadata": {"page_label": "15", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "e07d6102-a855-434c-a27a-fa6351667458": {"node_ids": ["58038040-1eb2-4cb6-990b-75a418d07783"], "metadata": {"page_label": "16", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a0805e4c-5453-4975-afae-5a8b8e6f94f7": {"node_ids": ["0f0fe4d4-74ae-4dae-af76-2df2150979a5"], "metadata": {"page_label": "17", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "84402524-b756-4bbe-af30-1bc6c088de1f": {"node_ids": ["582ea820-9b83-49b3-b861-e31f24500685"], "metadata": {"page_label": "18", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3cd33769-a765-4bb0-b415-a4fecbf9faf7": {"node_ids": ["b069d57d-86d2-4070-aa8e-b6e1d788622c"], "metadata": {"page_label": "19", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "c54cd93d-86fb-4cda-b685-45f87aef1ed0": {"node_ids": ["ae1e9bc8-44a3-4210-996d-0a6b0d1f4459"], "metadata": {"page_label": "20", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f4ccc425-43dd-4444-8d53-ebc57808c268": {"node_ids": ["dd968119-91dd-496e-beab-48eedfc44612"], "metadata": {"page_label": "21", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "0ef40838-49a3-4387-9b5b-b629b863bc59": {"node_ids": ["bdd1deb3-38d8-4356-a2bf-fcf12e4d6ca2"], "metadata": {"page_label": "22", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "88be3ac9-e0e0-42dd-9321-be28d3d93014": {"node_ids": ["006973cd-936c-44b3-8cc3-b2ad1a3aa1ba"], "metadata": {"page_label": "23", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a81c7340-e0df-4108-90b5-2f7bf33cd219": {"node_ids": ["bbd40ded-1082-4e46-85e2-c899938debb1"], "metadata": {"page_label": "24", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "10bc31b9-3e74-4656-9192-4fd76a336d0b": {"node_ids": ["711091c8-7551-4ef6-8796-910f1d7b8d7a"], "metadata": {"page_label": "25", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "c93fcecb-672e-4e21-a3c6-3933c291b2f0": {"node_ids": ["f9eaf67c-26b5-43b9-89a8-d130743afbf9"], "metadata": {"page_label": "26", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "b566ef62-2afe-4e87-abd0-85899b9051c4": {"node_ids": ["7920b910-679c-4333-89e8-497f857726df"], "metadata": {"page_label": "27", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "11d7f8b9-9033-47b4-aad4-ecd5751a266b": {"node_ids": ["60610e1f-b039-4b9c-b8f1-7f7ef79c1b28"], "metadata": {"page_label": "28", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3630a184-666e-4a10-9ada-96416b58572a": {"node_ids": ["f9c39f70-cd3b-43d6-89cf-db214ffc7838"], "metadata": {"page_label": "29", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "52c3f5e3-3196-411b-a1cc-7aa8137549c2": {"node_ids": ["b5da0c19-7530-4809-ba60-0f340ab78674"], "metadata": {"page_label": "30", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "8193005d-6228-42ba-a51c-3fd5be310802": {"node_ids": ["db7bee45-925c-4103-a72b-c6f6c7093253"], "metadata": {"page_label": "31", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "59d416bc-59ec-4715-81d0-a4a6e2731daf": {"node_ids": ["d24dae32-74a5-4c98-9831-f8751b5c079e"], "metadata": {"page_label": "32", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ce7aeee7-643c-4775-b071-9f78d78693a8": {"node_ids": ["4e835b84-892f-490e-af73-a7f4475cf64b"], "metadata": {"page_label": "33", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "fba2d7d4-ea40-4ab5-99bc-5cf227c352f3": {"node_ids": ["a08c638c-23a9-4e05-a7ca-ce99eeb66994"], "metadata": {"page_label": "34", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "87348c05-dd56-419d-b3e5-d2759f1f9544": {"node_ids": ["55f3fff1-41f8-4fe7-ac45-92d575a7469a"], "metadata": {"page_label": "35", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "bb253272-2931-4385-a6d7-fb46f508a42e": {"node_ids": ["b3c82c8d-78bf-4280-b0ca-ce5f7a385060"], "metadata": {"page_label": "36", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "0e2c83ca-206a-4eb3-83a9-95ff1305fc14": {"node_ids": ["2bc27c9d-608f-442e-b2ee-2d64444e3c24"], "metadata": {"page_label": "37", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a4e87799-7d1e-4c72-a051-8cd02591474d": {"node_ids": ["65ff2806-b724-451f-a5a0-812362ee79d9"], "metadata": {"page_label": "38", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "eed7d48e-b661-422c-ba1b-fd1625f3e606": {"node_ids": ["799acb1a-88dd-46b0-816c-d028b16ce76b"], "metadata": {"page_label": "39", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "cbd6c2c6-300c-43a3-9474-284b4e8f0fcd": {"node_ids": ["44fbd4dd-c6c9-410e-b96e-66d63ac62be9"], "metadata": {"page_label": "40", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "268147d0-ec9e-4386-ae6a-00b0b17d496c": {"node_ids": ["570fda88-9932-4ad4-9684-6ff3896eb9bc"], "metadata": {"page_label": "41", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "9fc72680-8426-45e3-a91e-4bbb734c308c": {"node_ids": ["d9f0af45-b744-4007-aeee-98eead94cd35"], "metadata": {"page_label": "42", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "33616cbf-7045-48cb-ad07-8f4a5949ccf9": {"node_ids": ["2b826e2b-bbbb-4393-808a-e6c57d66dbc3"], "metadata": {"page_label": "43", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "8f47c2f0-f803-4e2f-af8c-d1599f44c456": {"node_ids": ["85d707b4-493c-4959-bb30-c47a37540424"], "metadata": {"page_label": "44", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "155745fa-3404-4d32-8c79-ecbc77ab8797": {"node_ids": ["5bce91c1-ad4a-4750-aa75-4a40014b88d7"], "metadata": {"page_label": "45", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "9b3c8654-1be7-43bb-b1b6-a69cdfafe24d": {"node_ids": ["4bcf327f-1b76-419c-8d60-f0370e332dcd"], "metadata": {"page_label": "46", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "2f9dbfb7-a77a-4704-b997-c6d6ababc8e4": {"node_ids": ["a7e0d2dc-c095-4e72-b26d-c9b4d7abf43b"], "metadata": {"page_label": "47", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "1ec3eed3-cbbd-4123-ab88-02a69dfe6b40": {"node_ids": ["1b89c9e5-8cd9-480e-b49e-a7171c91f4ab"], "metadata": {"page_label": "48", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "7129473f-8679-4d1a-bdf2-9ce2450a28c7": {"node_ids": ["2b0fea0d-63e0-4931-bba9-bfc3e5f73b22"], "metadata": {"page_label": "49", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "7a8caf13-deac-43b9-b6cf-59ae67e088fa": {"node_ids": ["8edd0f1f-4431-4ea4-aeb6-2d114a5f098a"], "metadata": {"page_label": "50", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3124aaeb-ddb0-4e2f-aec9-a575c267029f": {"node_ids": ["a0734d7d-9b46-43ce-884a-5377f07af948"], "metadata": {"page_label": "51", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "9ad1b552-06a1-4bcf-b641-c17c4995b3db": {"node_ids": ["e6bf13d4-8d19-44a2-ad6a-36e4f5aa3e0b"], "metadata": {"page_label": "52", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "93b01571-6a44-4819-96f7-d84f3de12661": {"node_ids": ["649bbc92-dc02-40a6-aa85-aac0aef9de61"], "metadata": {"page_label": "53", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "960b3455-de29-40f9-bec4-fe285ff0e3a8": {"node_ids": ["2630ac98-8b4a-4cf4-9752-f9296f4dad22"], "metadata": {"page_label": "54", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "cd9511fd-4575-4787-849b-d5114ca1238b": {"node_ids": ["1b158531-5e1c-4084-b0bd-9c0046a5c9e8"], "metadata": {"page_label": "55", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "707e85d0-463c-4259-81b7-634665797bed": {"node_ids": ["24953547-4889-4cb7-8ab1-85f7cb1b9faf"], "metadata": {"page_label": "56", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "7af93020-9572-4c3e-a9eb-524373653695": {"node_ids": ["4fe8a12d-74c8-42a5-9c77-c3bb49b30cd4"], "metadata": {"page_label": "57", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "7a201452-0449-4ee4-af26-a8050dac730a": {"node_ids": ["e8e704d1-0ec2-45ed-bcb2-e2909ef7b71a"], "metadata": {"page_label": "58", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "608e44ad-b3dc-4fd5-b28d-84231d51fe6a": {"node_ids": ["090b31c6-2494-484c-a962-ee006cc21ffb"], "metadata": {"page_label": "59", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "8c9287b8-2123-4df3-a65d-c0f08ec9bfea": {"node_ids": ["ed2479c3-543c-475a-9b60-a0f2874bdf9a"], "metadata": {"page_label": "60", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "e1dd6a7b-de97-4fc4-b189-82d3542fe82e": {"node_ids": ["66e8f045-9da8-4b46-9274-894d73311c35"], "metadata": {"page_label": "61", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "d3567dbe-48fa-486b-bdd7-9e8068e1394b": {"node_ids": ["e3a8a419-759f-4fb1-b7b2-583c11a7cd3c"], "metadata": {"page_label": "62", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "e2d4a939-df28-47d2-a0a9-19e5e75878e8": {"node_ids": ["c420230c-42e4-4ebc-ba2e-613da876a762"], "metadata": {"page_label": "63", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "bba70202-ee19-4a9e-a90a-ce784c75e75f": {"node_ids": ["e10f41c0-d908-4d5d-88e7-85a320b9b893"], "metadata": {"page_label": "64", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "bf8be6ab-1925-4318-bd95-8b59cc86e06d": {"node_ids": ["4c4e489c-de2c-4721-9b92-48206b8a92a4"], "metadata": {"page_label": "65", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3f9ca9a4-f53e-4604-9a81-ca6f1170d8fd": {"node_ids": ["080e6c27-223d-4020-95f1-e426c23eb52e"], "metadata": {"page_label": "66", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "30132288-07bb-430b-aab5-876ee7ec5820": {"node_ids": ["5dbe7476-03cd-4c71-91e5-3e74625ffbb2"], "metadata": {"page_label": "67", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "0f84254f-7c00-4dad-aec8-286d2eb8b928": {"node_ids": ["1c5f693d-0707-4c34-85b2-9c0cdb28ae98"], "metadata": {"page_label": "68", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "358dfe1f-2289-48c4-9700-dc9410f1f9e7": {"node_ids": ["fa0b5bdb-ed2f-40a2-b2f3-0bcdc38a28de"], "metadata": {"page_label": "69", "file_name": "Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Operationalizing Generative AI on Vertex AI.pdf", "file_type": "application/pdf", "file_size": 3860600, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "be290469-6ccf-4772-822e-cdb73f85f798": {"node_ids": ["1a7a29a4-3324-4a81-8b64-2f60bdc44dca"], "metadata": {"page_label": "1", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "9104a78a-b065-431e-aed9-dcc8d5c56ef6": {"node_ids": ["b6859c2a-1eb0-40ca-b2b4-6d4aa51adcc5"], "metadata": {"page_label": "2", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "2494b4a7-6242-48d8-b648-ae0c0e761b08": {"node_ids": ["73f351ee-347f-4fe0-81dd-e29889cac465"], "metadata": {"page_label": "3", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ddc539bb-70b5-4830-bb31-ddfaeee6bb00": {"node_ids": ["bd9f3cdc-c05b-4433-ab7f-4af5f9ea5d5d"], "metadata": {"page_label": "4", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "1e018e8d-7f33-45c8-a97f-0c270e86a69d": {"node_ids": ["d76b5cc0-fc89-4323-a48b-b0cd49b7ae72"], "metadata": {"page_label": "5", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "5b12ffcf-f432-462b-a81f-fede63e40862": {"node_ids": ["3db29c44-d8fe-4791-864c-21d55ffdf44c"], "metadata": {"page_label": "6", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "723eca7e-9228-4bd0-9f8d-6d9d40ba18f3": {"node_ids": ["f3b8882e-8254-4d71-89fd-75062b41a559"], "metadata": {"page_label": "7", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "8b267e18-0194-4ebe-8f97-6ff008e0ab3d": {"node_ids": ["631815f3-6f55-4ff3-a987-c7025719bd13"], "metadata": {"page_label": "8", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "de46e4c9-fbca-470d-bb91-19df4c033cac": {"node_ids": ["debff26c-0158-41e1-a3f2-c0e189690213"], "metadata": {"page_label": "9", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "45d23f52-e91d-4ff2-b915-372bd68bd59a": {"node_ids": ["88370bfd-88a4-4ff9-94e7-6f69da65932b"], "metadata": {"page_label": "10", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "9d8c91ec-64e7-429d-8d0f-c4285a280d7c": {"node_ids": ["e0c48c32-d613-4722-b2b4-0808f821788e"], "metadata": {"page_label": "11", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a6946c91-28e2-4802-a826-dd8d5f9a0bd5": {"node_ids": ["ae104ce2-6e4a-4c55-ab7e-24a9d31e074e"], "metadata": {"page_label": "12", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "c32ea6cc-0e53-4775-ae62-fe94952e1e8c": {"node_ids": ["0ab177ab-0e2d-425f-93f1-b176a6854972"], "metadata": {"page_label": "13", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f3eec094-2c81-49b2-af38-1405c8711455": {"node_ids": ["4a007407-e225-47bf-aba1-2d39c8722779"], "metadata": {"page_label": "14", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a1f06841-cabd-4417-99d8-39e9af0c7946": {"node_ids": ["e380fc18-9380-45d3-87e8-a6596a2dd173"], "metadata": {"page_label": "15", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "353282f2-6e8c-41db-ba7c-8d2a120d9a6c": {"node_ids": ["ee076983-e37e-4007-889b-4da07f01b33c"], "metadata": {"page_label": "16", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "81c46c2f-f5b8-488f-94b9-04c8b701e91f": {"node_ids": ["d7f5b0f3-f113-489c-8325-61d624761d96"], "metadata": {"page_label": "17", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4ba529ee-24ce-4d40-a383-4abe570a17fd": {"node_ids": ["928f7407-bcb2-419c-a06e-2dd430273c12"], "metadata": {"page_label": "18", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "92837e06-1311-4cba-be99-892076ce9e63": {"node_ids": ["1ab090f7-ad53-45ea-b23b-40e876d583cd"], "metadata": {"page_label": "19", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f26af394-5cc0-4b30-83f0-20505833574c": {"node_ids": ["f5619b14-2502-43d4-a51d-d9cbd49540f8"], "metadata": {"page_label": "20", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "494f3bca-2271-4319-a456-0fdf6d8065ce": {"node_ids": ["976ececb-a1f9-42e8-aae4-3aec9990b821"], "metadata": {"page_label": "21", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "d3520f5f-7631-46f0-9ef7-5b6c9d3345a9": {"node_ids": ["cf14914a-fff7-412e-8393-809dc5fafc35"], "metadata": {"page_label": "22", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "cd075503-d9cf-4bb3-9481-09583649bff6": {"node_ids": ["fe64ef1c-efba-4215-80d5-deb91c59771c"], "metadata": {"page_label": "23", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "16bddd60-924b-49be-ac4e-47ed1ec16c5a": {"node_ids": ["2f882c53-92f7-48ac-85d6-b0995d56540b"], "metadata": {"page_label": "24", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "5bb42c1b-8453-4511-a1ea-479edece2791": {"node_ids": ["78d46af4-260e-4f29-a892-ca71e980f634"], "metadata": {"page_label": "25", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "2bfa2de4-ecc3-4695-ad6f-0263ed955b84": {"node_ids": ["1c179165-43e4-4912-a59e-60f74cecf229"], "metadata": {"page_label": "26", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "143dcd88-cbf4-4d68-87ce-219de80d9741": {"node_ids": ["04eb4a04-bd62-452e-8177-b224c82ecbf3"], "metadata": {"page_label": "27", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "950e1797-d9e2-406c-a9fd-336c75ad5cd3": {"node_ids": ["a54640b2-1f16-4f9f-8242-35f2c617dbc9"], "metadata": {"page_label": "28", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "691ba04c-059c-41f0-bef2-857f44adf8d8": {"node_ids": ["99f31f3f-c413-44d0-a886-a4d2496e01b3"], "metadata": {"page_label": "29", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4ce7e8f1-985a-40a3-8dd1-892821f504a1": {"node_ids": ["ab692d28-8b81-4925-8edc-4f8b0de8d685"], "metadata": {"page_label": "30", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "e9bca7a9-04c5-47c2-8287-8b47847248b5": {"node_ids": ["2d4163dd-dbba-4057-82eb-b34cfc879fa8"], "metadata": {"page_label": "31", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a858d197-a34b-4921-ab04-b8065b850724": {"node_ids": ["67f7504a-949f-4f0f-b6bf-c26743aa5840"], "metadata": {"page_label": "32", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a4111851-778f-4692-895e-a133d155d37c": {"node_ids": ["74ab4b74-a611-472d-9cb6-4900cbde2238"], "metadata": {"page_label": "33", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "1967f30a-098b-4cdf-a0ae-4d54a8ac90c9": {"node_ids": ["60b90252-bf56-4632-8a14-93a4f5da636b"], "metadata": {"page_label": "34", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "852099c6-fea0-43d7-b14a-6e336894fcb8": {"node_ids": ["159a5968-49b6-4e7c-a4ae-5787380c9568"], "metadata": {"page_label": "35", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4cef32fc-428c-47d9-ae3e-61e06e3d1729": {"node_ids": ["aa13aa1b-d84c-4f4f-ae84-7a3c5fe1da2b"], "metadata": {"page_label": "36", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "11317e73-6fbd-46f3-a5fa-da02b1275f86": {"node_ids": ["4fa0f180-fb53-4b27-a505-517d28e90be8"], "metadata": {"page_label": "37", "file_name": "Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Newwhitepaper_Solving Domain-Specific problems using LLMs.pdf", "file_type": "application/pdf", "file_size": 3377424, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "2d3fe42c-4570-48e8-b9b7-c5203dcc2e21": {"node_ids": ["bcd27c76-2798-4930-a81b-935decd072d9"], "metadata": {"page_label": "1", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3f6a6434-e5ff-4f29-acc3-643a67dee185": {"node_ids": ["94c7d40f-86d9-411c-b875-61b5889256b8"], "metadata": {"page_label": "2", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "7d9ee3fa-d4f9-4298-a82d-1ee5fdab5153": {"node_ids": ["f5475c96-3faf-4689-8172-c7aaad81bb56"], "metadata": {"page_label": "3", "file_name": "Profile.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "674d6cf1-f41e-4203-b758-047caa4c2fd6": {"node_ids": ["e6371bc5-f3cb-4919-952f-f4c84a1e33b4"], "metadata": {"page_label": "1", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "e0c0164e-9d5d-4999-b1f9-f60343af5a1e": {"node_ids": ["174feabd-3013-4cc3-a6ad-01c1144c5630"], "metadata": {"page_label": "2", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "5d9b0070-aa7e-46b1-bf9d-56e017d16512": {"node_ids": ["af78b862-d67c-4924-9dbf-2d0e8aa5c49a"], "metadata": {"page_label": "3", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "a5a96faa-8bbf-47db-93c2-01d2e1bce5f3": {"node_ids": ["323febd0-76a1-4912-a1f3-f1c5584f168c"], "metadata": {"page_label": "4", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "0bcaa809-efb2-4f19-a812-43f62fbcc4b6": {"node_ids": ["af435f87-179f-4c96-bd8d-952c3ec12b6f"], "metadata": {"page_label": "5", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "014ec0a8-4bb1-46e6-a5ef-3381fd4030e6": {"node_ids": ["f930600d-145b-4d00-9ad7-410e427becd9"], "metadata": {"page_label": "6", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "e1a2dac7-95cc-4a92-9de2-df35ab84b71b": {"node_ids": ["89ecb132-9ff1-4375-b187-c16d48599f6f"], "metadata": {"page_label": "7", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "92b2b6cc-f932-4a78-8138-b0af129cdaae": {"node_ids": ["085549ec-de43-4a7e-a24b-31e80ba97577"], "metadata": {"page_label": "8", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "4e68365f-068c-471c-8fa6-07aeca9c570a": {"node_ids": ["24bef584-e2e9-4e62-99ec-f3ef82a17555"], "metadata": {"page_label": "9", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "6a06bdfb-3fe3-4b04-b4ec-9b1f1f2078ce": {"node_ids": ["2f062d25-af44-481e-9560-24681269fadc"], "metadata": {"page_label": "10", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "848878d3-767e-4bd5-8f81-c6e24d94454b": {"node_ids": ["1f05b534-502c-4805-a7c2-b229dc6888a1"], "metadata": {"page_label": "11", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "d3a2303d-f8b7-4b94-a948-e8620f8df25e": {"node_ids": ["7eb01d40-6090-4f66-8428-c962e9b9e438"], "metadata": {"page_label": "12", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "7b966e51-a0fb-4d86-b725-c295c01d8805": {"node_ids": ["81f6823d-ffd1-4dd0-be23-269209cff20d"], "metadata": {"page_label": "13", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "f649d7cb-da8e-4430-8f01-b07785cb5b59": {"node_ids": ["b7b25335-3fac-43e5-932d-d2b3eddf3ffe"], "metadata": {"page_label": "14", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "47ec847a-d874-422f-9290-5a75a11ead92": {"node_ids": ["d4dbde06-721c-47e0-8351-ddde51925f92"], "metadata": {"page_label": "15", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "3cd1d469-0aa5-4360-921a-6e163e88ecd3": {"node_ids": ["bf8782af-c80f-4cff-8189-80e6df5d311a"], "metadata": {"page_label": "16", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "943b2ac0-1402-4f8d-bc3e-d097667f2c12": {"node_ids": ["b5349a12-718a-468e-aca0-40d4da55262b"], "metadata": {"page_label": "17", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "0772d767-1d71-42e1-bd43-ec2a8be42c10": {"node_ids": ["ec2e131b-f548-4d2d-b377-57ccd972b590"], "metadata": {"page_label": "18", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "dbcf648e-d7e7-4d21-b83b-594b1bfc3f5c": {"node_ids": ["26829735-c188-489e-8fdf-7611e06d40eb"], "metadata": {"page_label": "19", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "343e85f1-500a-40b2-9d47-a2beacc38e58": {"node_ids": ["f3603433-f187-4fcf-a983-387e6ef35919"], "metadata": {"page_label": "20", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "c623fa36-2d98-4505-9e25-58df2db3a6ba": {"node_ids": ["31423d9a-efa1-426f-a259-9720da5af2de"], "metadata": {"page_label": "21", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "8da02310-cb83-45b9-a3d9-42cf63fe3d0b": {"node_ids": ["c61dc562-96a2-4acc-8eca-054479699c8c"], "metadata": {"page_label": "22", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "37f6d1a1-eec4-46a4-9d61-a8377fe3e77e": {"node_ids": ["f0b8676e-eb5a-412d-9a4c-c91bec885880"], "metadata": {"page_label": "23", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "ae706473-fef6-4555-b941-b301c04bb3cf": {"node_ids": ["cccee87d-679a-42ed-aaef-4bb452468758"], "metadata": {"page_label": "24", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "1c735c43-6bf2-4679-a6ae-6c96dd34e388": {"node_ids": ["4141ad60-f6ee-4f8e-8fd9-52bbc307bbf7"], "metadata": {"page_label": "25", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "c980619e-9217-49e1-8fe9-366ddc34bc5d": {"node_ids": ["0479e479-642c-4587-ac7f-0af920a96e3e"], "metadata": {"page_label": "26", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "6ebac492-01b5-4265-9a44-e4f1fb18a19e": {"node_ids": ["5aded843-1d04-47ba-aef4-d6e94839f559"], "metadata": {"page_label": "27", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "152c7edd-f75a-40fe-a572-aae9a00deda7": {"node_ids": ["ba5f0e82-8652-48c8-92b6-4e3a356c2e27"], "metadata": {"page_label": "28", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "440c1cdf-de46-459d-9473-49ddabfaac93": {"node_ids": ["69cd4dae-7747-44d6-9f27-fe6f9c9c072e"], "metadata": {"page_label": "29", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "17e56c55-41f6-47b4-a1a8-6b954de62e61": {"node_ids": ["de28a565-020b-493f-99e1-97070e50e70f"], "metadata": {"page_label": "30", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "eb32c2d7-3c92-4b4f-8b74-b9630fcfecce": {"node_ids": ["d03e0ecb-0433-40f7-b9ad-f5bdb564a731"], "metadata": {"page_label": "31", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "e6ed7066-287c-475c-b311-ef53fa8237fb": {"node_ids": ["b7044f93-370f-4c57-a5e1-ce12ffaaca8f"], "metadata": {"page_label": "32", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "1bb37ad9-bbac-4507-b8cc-db3520831e02": {"node_ids": ["9743d0dc-80e4-40a5-ab96-edde0a4bc09a"], "metadata": {"page_label": "33", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "6efa7c17-ec93-4947-8bda-ff857bb1a138": {"node_ids": ["dfc46287-0e58-4728-a84d-6ccc624edda5"], "metadata": {"page_label": "34", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "a057ce88-4814-48ba-8a36-e0ab1ef478c1": {"node_ids": ["43757b94-79ff-4dd2-9c31-bd81e9059af8"], "metadata": {"page_label": "35", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "74b7fd9d-655a-4263-9710-0d52284273b6": {"node_ids": ["1ebf39cc-38be-4d21-a657-16b7ceb5b364"], "metadata": {"page_label": "36", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "24646fbf-2a6e-492e-b019-5ed08b7f03b6": {"node_ids": ["0a8dbd8a-c8e1-4d3c-abb8-6b20ab56b234"], "metadata": {"page_label": "37", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "a6e2c600-cd3a-47ad-8744-69a6e6185316": {"node_ids": ["6b3fd87d-63cd-4590-be2f-60cf7b58116d"], "metadata": {"page_label": "38", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "fe0b76b5-f71c-467a-8397-9a9b34d0f71a": {"node_ids": ["d8ef6725-a6ef-4fb7-b692-c941e95bf3f4"], "metadata": {"page_label": "39", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "5258a212-690a-4c23-8440-7e008902d260": {"node_ids": ["565787b4-713f-4dee-984e-e7bbf4176654"], "metadata": {"page_label": "40", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "26761a96-e5a1-47ea-95a6-4373f37f48a1": {"node_ids": ["8a7ddbad-e933-4020-88e2-6df80559d856"], "metadata": {"page_label": "41", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "449bee29-05b6-4d00-ac43-bfc7df81cbc4": {"node_ids": ["f323ee4e-084a-4c1c-9570-a76eec72dc6f"], "metadata": {"page_label": "42", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "9570b23a-0a7d-416f-85be-58fd624dd6f6": {"node_ids": ["0b62fff5-73de-463a-9365-e084ad09afe5"], "metadata": {"page_label": "43", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "d1d7d505-320b-4596-a384-e0e1ccc66db7": {"node_ids": ["17a065ce-af25-40d8-b3b5-1178a09eddb3"], "metadata": {"page_label": "44", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "58de7747-74f4-4cc4-a446-fba876ddc04a": {"node_ids": ["dd99c6e4-5759-4baa-8378-a9927d1f0d80"], "metadata": {"page_label": "45", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "485a1c3e-c2da-44f4-b9ec-ccd26efe7238": {"node_ids": ["ba66c8f2-b8d7-4a08-9e53-ff11ffab077c"], "metadata": {"page_label": "46", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "ed5996f2-250e-4290-9b86-c404faf8dccc": {"node_ids": ["a9039537-9d94-4dbc-bafc-8c694044db96"], "metadata": {"page_label": "47", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "c797e5cf-5ca0-430c-9e3f-20eb20f77bc6": {"node_ids": ["d64d6fe8-1747-40b0-9801-951447f3a1a8"], "metadata": {"page_label": "48", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "ea525757-0554-4628-bc77-af600cf1060f": {"node_ids": ["1a5d213a-18d9-42be-a17c-74d921a27a27"], "metadata": {"page_label": "49", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "5b2a82d7-049d-4fe9-9e15-746007572c5c": {"node_ids": ["ca1f1b7c-06aa-46a8-bc44-5cf72e9cb6ae"], "metadata": {"page_label": "50", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "9e1c6472-477c-4ddd-b8c6-dd0cb4c479cf": {"node_ids": ["4f37191e-4501-4961-b72a-b961669f35c9"], "metadata": {"page_label": "51", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "6204f493-5854-4ec8-8c9f-7220c13a9ee3": {"node_ids": ["85c83eac-9df7-44aa-a7a1-9ad71871e3e3"], "metadata": {"page_label": "52", "file_name": "whitepaper_Embeddings & vector stores.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Embeddings & vector stores.pdf", "file_type": "application/pdf", "file_size": 3371689, "creation_date": "2024-11-20", "last_modified_date": "2024-11-11"}}, "77075225-d6d6-4ce2-9107-9213391c2e3d": {"node_ids": ["c4136728-f4ba-465a-a72d-a2ba7c8aff7e"], "metadata": {"page_label": "1", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f5742773-a6bc-43e0-940d-f1cc692c5e82": {"node_ids": ["a5d73010-2d71-4c0c-9e0b-f7419094280a"], "metadata": {"page_label": "2", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "be0eaefc-bde6-4b96-875b-c032380a80d3": {"node_ids": ["1b269087-4255-4b34-bb34-5d371e01299c"], "metadata": {"page_label": "3", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "1b341c41-8162-49b6-bb91-89080b046945": {"node_ids": ["d1ada68f-95d7-4b3e-b5ea-fc3efbfc1df4"], "metadata": {"page_label": "4", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "18dd8080-215e-4d38-8937-b297a5dabd88": {"node_ids": ["6067c9fb-c9a6-4df4-8268-2dfb4c88763e"], "metadata": {"page_label": "5", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f97bd38b-afa2-4c1f-b2cd-d49ed72e0c56": {"node_ids": ["76fdfdf2-2125-4af5-a215-1c3dae2743fc"], "metadata": {"page_label": "6", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "83d5360b-4c21-4330-88f3-c5ef9f35e0a0": {"node_ids": ["5531cc32-2957-4a35-867d-b5efc7fab502"], "metadata": {"page_label": "7", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4a090aff-483e-4bbc-a9d0-2f06057c4eec": {"node_ids": ["154bca11-700c-4ffc-ab70-67b0544d8682"], "metadata": {"page_label": "8", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "6ec7cbe1-c7e6-4a25-8505-1b335d39ede5": {"node_ids": ["4fcf1194-00fa-4bbb-831d-1819f78cb4a6"], "metadata": {"page_label": "9", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "375a6d45-5b96-4066-a609-92976da74def": {"node_ids": ["47bcd8b2-dd97-4072-b697-1a96c68e5dc6"], "metadata": {"page_label": "10", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "1206487c-318d-4d86-a9cd-d6639a5dcae3": {"node_ids": ["4963ebfd-de92-462d-9203-4c4a73794664"], "metadata": {"page_label": "11", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3aff15c2-2562-4613-b2e1-a29fd648478e": {"node_ids": ["79bd6d4e-fa9d-41a3-8bed-7061e2ac91e3"], "metadata": {"page_label": "12", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "276b72d1-6bb7-4aed-b700-142bd8735d56": {"node_ids": ["40722910-fb12-43bd-86e6-3e719711c768"], "metadata": {"page_label": "13", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "96d63c4e-0d89-46c8-a619-3418499348c9": {"node_ids": ["26d5a4fe-46c8-41ca-8da3-4a50a7a07c56"], "metadata": {"page_label": "14", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4d388dfe-1dfd-4445-b93b-e2a95a14d509": {"node_ids": ["1cd596e0-ebd4-432b-9ca9-77f256e5f26d"], "metadata": {"page_label": "15", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3c03b062-1584-4976-9197-1faf18348058": {"node_ids": ["a00020be-4c1f-4104-b86f-8186299ac107"], "metadata": {"page_label": "16", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "1a898361-f9d1-4490-9b85-8a00517d1782": {"node_ids": ["30aa6e91-4e74-41c3-89e1-f8455a315724"], "metadata": {"page_label": "17", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "74d0cfd6-b76f-4d8e-970e-ef68500db9dc": {"node_ids": ["fe5984f7-142c-4c80-b2bf-3f5b3fbeb19a"], "metadata": {"page_label": "18", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4beae257-2931-4d2c-82fd-a0e1fb7c98e2": {"node_ids": ["74bdef06-52b8-4dcf-9d55-444369bf721d"], "metadata": {"page_label": "19", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f6e0cf90-f622-4d21-9032-76d36547960b": {"node_ids": ["c8257479-3ce0-458a-a54c-8afc2f26a054"], "metadata": {"page_label": "20", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4935ca81-a397-4d14-adb2-222fd7176b32": {"node_ids": ["abd3507a-5e6e-4165-b85d-fe87c49cebd2"], "metadata": {"page_label": "21", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "34891eee-e5d1-4275-8315-ade359a397c3": {"node_ids": ["bfa5b301-04ec-462e-82e0-01d939d3f853"], "metadata": {"page_label": "22", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4cebcabb-0c24-41f6-8a4c-ebede2fcb238": {"node_ids": ["dce1451d-2b18-4e98-b25a-509adb1e6ea1"], "metadata": {"page_label": "23", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ef54843c-ea66-4ddd-97f8-534fb50ac9d1": {"node_ids": ["50f5be85-cd2c-41c0-9a4c-62f739e1a42a"], "metadata": {"page_label": "24", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "309bbfa1-ddc0-4501-9141-12672a740c34": {"node_ids": ["90f42fcb-fd97-4c74-b83f-761787286af4"], "metadata": {"page_label": "25", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "44d3029b-b91d-44e4-b396-d067e6490867": {"node_ids": ["00724d84-2417-4fb1-b955-f3df9571f688"], "metadata": {"page_label": "26", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3bd14228-a814-406b-a2c4-0e2b1653bfa0": {"node_ids": ["8fb613ab-0561-4e66-be81-7b9aa95828d3"], "metadata": {"page_label": "27", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "c6440385-41ca-4d63-a640-c6b60ef118a3": {"node_ids": ["6da64650-fd4c-4681-83ff-d0436ffbd743"], "metadata": {"page_label": "28", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "abfa6591-e1b9-49ba-86ec-d4a7353de27b": {"node_ids": ["81f0ef82-16e9-434e-913b-73e29492559f"], "metadata": {"page_label": "29", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "88ca3a9a-c571-45ca-a2a0-2c871e74d60e": {"node_ids": ["4b8178c4-cbae-4e99-914e-4907886dbb8b"], "metadata": {"page_label": "30", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "84e16337-50af-4ee1-85e3-7146a09029d8": {"node_ids": ["3514d3f3-796f-437f-9dc9-12cc2ba36dee"], "metadata": {"page_label": "31", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "653a7c4b-8834-4b8c-b8d2-2dd60d663502": {"node_ids": ["2e284ebd-2776-416c-89ca-8951eb39b17c"], "metadata": {"page_label": "32", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "d6f8857a-1761-4121-b2ec-1860929989cc": {"node_ids": ["553575ea-36a1-4ff3-9d92-5b37856de303"], "metadata": {"page_label": "33", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "563894cf-9067-4c75-9966-f4ac117449f7": {"node_ids": ["302e38ef-c217-43d3-8277-2f05409fd9c4"], "metadata": {"page_label": "34", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "35fdf474-c1b3-4c83-ba9f-bec0f96a7554": {"node_ids": ["e7101447-b5e8-46c2-9b7c-37b6e86373f3"], "metadata": {"page_label": "35", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "0527a179-f47d-4bb3-85cb-a8e55b6ddea4": {"node_ids": ["bd4f1cf9-3c56-4fec-8c8c-6121854f1cca"], "metadata": {"page_label": "36", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ae74c5b0-989e-4543-afcc-edff35ab5525": {"node_ids": ["80cc60f1-205c-4670-a69b-d9f6a496c998"], "metadata": {"page_label": "37", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "c3107673-6add-4e2b-abf0-79ecf797b6ba": {"node_ids": ["5b8d1807-d985-4e8c-8d4e-fff35735c56c"], "metadata": {"page_label": "38", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "18dce106-3e5e-4262-8304-99a504a69248": {"node_ids": ["d2f69065-94d9-4249-a848-714dc82afc06"], "metadata": {"page_label": "39", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "9942236c-3fd4-4e84-b6db-ecf3dbe1db3c": {"node_ids": ["3560ea93-ec88-4e2c-975a-2130f019766d"], "metadata": {"page_label": "40", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "32270606-7c44-4d50-b287-0d70cc208afe": {"node_ids": ["5ba21c4b-ae2f-4173-96a1-c7e9fab395c0"], "metadata": {"page_label": "41", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "453fdf1c-db20-4a2c-bf71-822e09417986": {"node_ids": ["5a29c815-5e81-41b3-882d-f0961150f993"], "metadata": {"page_label": "42", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "124fef4a-5350-4725-907a-d8d7b4ff6932": {"node_ids": ["6b25d1ac-d7b4-44f1-bb5b-d7477c5d4f84"], "metadata": {"page_label": "43", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "4eb8754f-2aba-4ab0-9765-bb7277f949a4": {"node_ids": ["b4e2b289-0531-4f3f-8d21-9ec4f0302343"], "metadata": {"page_label": "44", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f2313df1-79a0-40c5-9819-8c2f7003456f": {"node_ids": ["62fe4755-42a9-45aa-b821-3b0b49f273b6"], "metadata": {"page_label": "45", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "0a53e5ad-b647-446e-ad34-1deb0a7a6442": {"node_ids": ["ad6f5758-4f48-4473-af7d-c0efde3e8559"], "metadata": {"page_label": "46", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ba338796-570e-4ad8-a295-c8bf1d7d3c21": {"node_ids": ["e1fbd916-e652-4308-b1b0-674be967ae34"], "metadata": {"page_label": "47", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "949af885-3af7-4e96-8f8a-6ce50b9ff03c": {"node_ids": ["cd599e33-eb64-4538-a89b-62a95610cc0f"], "metadata": {"page_label": "48", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "133c1fa9-d6d2-4a31-8a6c-bd35e63b0acf": {"node_ids": ["b707e542-6dd8-4f6c-910c-d91f93b5d0a0"], "metadata": {"page_label": "49", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "bbfbd202-71d6-4988-bcf6-454a96b8552a": {"node_ids": ["58cb32d4-a18c-433f-aea5-94464ecf3d1d"], "metadata": {"page_label": "50", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "8e7a0086-b83f-478a-b717-b2835be58071": {"node_ids": ["fb6f596b-8601-4b3b-8006-76a10f19424a"], "metadata": {"page_label": "51", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "228fd0bd-68c2-40be-bba0-8187b36ac2d8": {"node_ids": ["b1001afd-20c5-440f-bb36-7ff94cb5339e"], "metadata": {"page_label": "52", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "733c6af7-9920-4e06-9d17-bdae1ea700ef": {"node_ids": ["f3dac615-d68b-40bd-880f-479c6a91367d"], "metadata": {"page_label": "53", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "d4226151-ccac-4430-92ec-d1353b10f961": {"node_ids": ["c2ae2556-d60d-4611-bade-a4f09ee4ec1a"], "metadata": {"page_label": "54", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "687a0f25-daf1-4a99-95da-bb9cefab34ee": {"node_ids": ["18c26386-daf8-4470-b964-c879a4afb034"], "metadata": {"page_label": "55", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "ec92cdee-f64f-4881-baac-03c7f83a856b": {"node_ids": ["887c4a6f-d76d-49db-a234-c0877a87bfd8"], "metadata": {"page_label": "56", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "3d85146d-db46-4b7b-9502-29fad17afd22": {"node_ids": ["bccd66e7-31be-4e29-9730-028d07dfe988"], "metadata": {"page_label": "57", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "795d23c5-75e9-43e8-88cb-bceeae772581": {"node_ids": ["e874627c-855e-42d7-af75-8bf33146e88e"], "metadata": {"page_label": "58", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a6f5d9be-66b8-45e1-9e7a-e2ffcc32b444": {"node_ids": ["e1394980-daac-4429-8188-a37c0bbb2651"], "metadata": {"page_label": "59", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "50f1a77d-2e40-41d9-8ca7-a8e97bd07d99": {"node_ids": ["48cc582d-b4e1-4b18-a9ea-811789602309"], "metadata": {"page_label": "60", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "a6a3de2d-4e6a-4453-9a55-0168b24bd5a5": {"node_ids": ["1a2e2e9a-4ac1-4fe3-9bba-b9e0a0e1aaac"], "metadata": {"page_label": "61", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "8f1f6ad8-8a20-4841-9509-a71bce32c69b": {"node_ids": ["521524fd-282d-4c20-ba6f-6a8ba8aca209"], "metadata": {"page_label": "62", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "1d1fe977-cf56-4c87-a133-7aa37b9b634f": {"node_ids": ["acfba396-1b31-46b0-9c1a-7e194b122d6a"], "metadata": {"page_label": "63", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "c882a693-aed9-4ef3-b57d-2fc07270bb57": {"node_ids": ["402e400b-bdd5-4d53-9ab7-66faced28f78"], "metadata": {"page_label": "64", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "f84a97ca-9388-490e-9c4e-ef6046b8231f": {"node_ids": ["895f7caa-7ba5-47db-8ddf-88da25ce1d10"], "metadata": {"page_label": "65", "file_name": "whitepaper_Prompt Engineering_v4.pdf", "file_path": "/Users/chitrakumarsai/Desktop/Personal/projects/LLM_CKS_RAG/RAG_APP/data/whitepaper_Prompt Engineering_v4.pdf", "file_type": "application/pdf", "file_size": 6817075, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}, "c5014c6b-ec97-492d-b74c-fd25db85d719": {"node_ids": ["58a41b1f-3320-4d20-9988-d849ea4208f3"], "metadata": {"page_label": "1", "file_name": "Profile.pdf", "file_path": "data/Profile.pdf", "file_type": "application/pdf", "file_size": 54531, "creation_date": "2024-11-20", "last_modified_date": "2024-11-20"}}}}